{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps for Building Network\n",
    "[Step 1](#step1): Unzip image dataset and check out train, validation and test files.\n",
    "\n",
    "[Step 2](#step2): Show image and json files in train & validation dataset.\n",
    "\n",
    "[Step 3](#step3): Initialize features(input) and labels(output) from images and json list.\n",
    "\n",
    "- read images from train/validation/test path.\n",
    "- read labels from train/validation json file.\n",
    "- resize and normalize images.\n",
    "- get batch and return feature_batch and label_batch.\n",
    "\n",
    "[Step 4](#step4): Build convolutional network, return training accuracy and training loss.\n",
    "\n",
    "[Step 5](#step5): Train on steps = 20000.\n",
    "\n",
    "[Step 6](#step6): Train on full dataset.\n",
    "- epoch x, batch x, training loss, validation accuracy, evluation accuracy\n",
    "\n",
    "[Step 7](#step7): Test and write json submit file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step1'></a>\n",
    "## Step 1: Unzip image dataset and check out train, validation and test files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found extraced dataset\n"
     ]
    }
   ],
   "source": [
    "import os, zipfile\n",
    "\n",
    "train_path = 'E:/ai_challenger/scene classification/dataset/ai_challenger_scene_train_20170904.zip'\n",
    "validation_path = 'E:/ai_challenger/scene classification/dataset/ai_challenger_scene_validation_20170908.zip'\n",
    "test_a_path = 'E:/ai_challenger/scene classification/dataset/ai_challenger_scene_test_a_20170922.zip'\n",
    "extract_path = 'E:/ai_challenger/scene classification/dataset'\n",
    "\n",
    "def unzip(zipfile_path, extract_path, zipfile_name):\n",
    "    zipfile = zipfile.ZipFile(zipfile_path, 'r')\n",
    "    print('Extracting {} ...'.format(zipfile_name))\n",
    "    zipfile.extractall()\n",
    "    zipfile.close()\n",
    "    print('{} has been extracted.'.format(zipfle_name))\n",
    "\n",
    "if os.path.exists(extract_path):\n",
    "    print('Found extraced dataset')\n",
    "else:\n",
    "    unzip(train_path, extract_path, 'training dataset')\n",
    "    unzip(validation_path, extract_path, 'validation dataset')\n",
    "    unzip(test_a_path, extract_path, 'test dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='step2'></a>\n",
    "## Step 2: Show image and json files in train & validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label_id': '66', 'image_id': '79f993ae0858ae238b22968c5934d1ddba585ae4.jpg', 'image_url': 'https://n1-q.mafengwo.net/s1/M00/6B/72/wKgBm04Wc5WzFXU0AAHf09bdpiY84.jpeg?imageView2%2F2%2Fw%2F600%2Fq%2F90'}, {'label_id': '61', 'image_id': 'e963208fe9e90df0c385f7367bcdb6d0d5d0b165.jpg', 'image_url': 'http://news.sogou.com/'}, {'label_id': '64', 'image_id': '02df5ecbf7c749ccc9d833f129bbd5d9837940ce.jpg', 'image_url': 'http://img2.fawan.com/2016/12/30/e967f93e7713c57cd2b00b832dd6091a_500x-_90.jpg'}, {'label_id': '31', 'image_id': '5620eb385b7567fb087813cf5233b5ceecdeeca3.jpg', 'image_url': 'https://b1-q.mafengwo.net/s1/M00/F2/C9/wKgBm04Wx3a-gk2FAAKbPKX7E9w91.jpeg?imageView2%2F2%2Fw%2F600%2Fq%2F90'}, {'label_id': '19', 'image_id': 'f8b4d42001a562fc63b9b39c02531661c0e236ca.jpg', 'image_url': 'http://news.sogou.com/'}, {'label_id': '11', 'image_id': '57e7eb438670a4519041dab1482f2594a92f8a09.jpg', 'image_url': 'http://www.user2.jqw.com/2014/01/06/1347666/product/b201401072000291460.JPG'}, {'label_id': '22', 'image_id': 'addb2ef7e4aa1a160093e32ceec19bf900c05d2e.jpg', 'image_url': 'http://s16.sinaimg.cn/middle/67bde22dx929ff224e80f&690'}, {'label_id': '11', 'image_id': '84a5b79a7f8fe3ddb43355eaf010a3a432e457b4.jpg', 'image_url': 'http://imgsrc.baidu.com/imgad/pic/item/a686c9177f3e6709f65104d631c79f3df8dc5541.jpg'}, {'label_id': '47', 'image_id': '48f690ba20db3e6a0a0f7ab5b59480f7558b18fa.jpg', 'image_url': 'http://news.sogou.com/'}, {'label_id': '3', 'image_id': '3c53b82532f132da2727fad84ade044f364a1dba.jpg', 'image_url': 'http://news.sogou.com/'}]\n",
      "\n",
      "\n",
      "53879\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import glob\n",
    "from scipy.misc import imread, imresize, imsave\n",
    "import numpy as np\n",
    "\n",
    "train_features_path = r'E:\\ai_challenger\\scene classification\\dataset\\ai_challenger_scene_train_20170904\\scene_train_images_20170904'\n",
    "train_labels_path = r'E:\\ai_challenger\\scene classification\\dataset\\ai_challenger_scene_train_20170904\\scene_train_annotations_20170904.json'\n",
    "validation_features_path =r'E:\\ai_challenger\\scene classification\\dataset\\ai_challenger_scene_validation_20170908\\scene_validation_images_20170908'\n",
    "validation_labels_path =r'E:\\ai_challenger\\scene classification\\dataset\\ai_challenger_scene_validation_20170908\\scene_validation_images_20170908\\scene_validation_annotations_20170908.json'\n",
    "test_a_features_path = r'E:\\ai_challenger\\scene classification\\dataset\\ai_challenger_scene_test_a_20170922\\scene_test_a_images_20170922'\n",
    "\n",
    "# Show train label list\n",
    "with open(train_labels_path, 'r') as f:\n",
    "    train_label_list = json.load(f)\n",
    "    print(train_label_list[:10])\n",
    "    train_dict = {}\n",
    "    for image in train_label_list:\n",
    "        train_dict[image['image_id']] = int(image['label_id'])\n",
    "    print('\\n')\n",
    "    print(len(train_dict))     \n",
    "\n",
    "# Show train features list resulting out of memory..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='step3'></a>\n",
    "## Step 3: Initialize features(input) and labels(output) from images and json list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from scipy.misc import imread, imresize\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class initialize(object):\n",
    "    # Get image-label list for train and validation\n",
    "    def __init__(self, feature_path, label_path):\n",
    "        self.image_label_dict = {}\n",
    "        with open(label_path, 'r') as f:\n",
    "            label_list = json.load(f)\n",
    "        for image in label_list:\n",
    "            self.image_label_dict[image['image_id']] = int(image['label_id'])\n",
    "        self.start = 0\n",
    "        self.end = 0\n",
    "        self.length = len(self.image_label_dict) # number of feature images\n",
    "        self.image_name = list(self.image_label_dict.keys())\n",
    "        self.feature_path = feature_path\n",
    "    \n",
    "    # Read image in feature path, resize and normalize to [-1, 1]\n",
    "    def get_image(self, image_path, image_size):\n",
    "        image = imread(image_path)\n",
    "        image = imresize(image, [image_size, image_size])       \n",
    "        image = np.array(image).astype(np.float32)\n",
    "        image = 2 * (image - np.min(image)) / np.ptp(image) - 1\n",
    "        return image\n",
    "    \n",
    "    # Get feature and label batch\n",
    "    def get_batch(self, batch_size, image_size):\n",
    "        self.start = self.end\n",
    "        if self.start >= self.length:\n",
    "            self.start = 0\n",
    "        batch_feature = []\n",
    "        batch_label = []\n",
    "        index = self.start\n",
    "        while len(batch_feature) < batch_size:\n",
    "            if index >= self.length:\n",
    "                index = 0\n",
    "            i_image_path = os.path.join(self.feature_path, self.image_name[index])\n",
    "            i_image = self.get_image(i_image_path, image_size)\n",
    "            i_label = self.image_label_dict[self.image_name[index]]\n",
    "            batch_feature.append(i_image)\n",
    "            batch_label.append(i_label)\n",
    "            index += 1\n",
    "        self.end = index\n",
    "        return batch_feature, batch_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='step4'></a>\n",
    "## Step 4: 16 convolutional layers with batch normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def conv_layer(input_layer, filters, strides, is_training):\n",
    "    layer = tf.layers.conv2d(\n",
    "        inputs=input_layer, \n",
    "        filters=filters, \n",
    "        kernel_size=3,\n",
    "        strides=strides, \n",
    "        padding='same', \n",
    "        activation=None,\n",
    "        kernel_initializer=tf.truncated_normal_initializer()\n",
    "    )\n",
    "    \n",
    "    layer = tf.layers.batch_normalization(\n",
    "        inputs=layer, \n",
    "        axis=-1,\n",
    "        momentum=0.9,\n",
    "        epsilon=0.001,\n",
    "        center=True,\n",
    "        scale=True,\n",
    "        training=is_training\n",
    "    )\n",
    "    \n",
    "    layer = tf.nn.relu(layer)\n",
    "    return layer\n",
    "\n",
    "def fully_connected(input_layer, num_units, is_training):\n",
    "    layer = tf.layers.dense(input_layer, num_units, use_bias=False, activation=None)\n",
    "    layer = tf.layers.batch_normalization(layer, training=is_training)\n",
    "    layer = tf.nn.relu(layer)\n",
    "    return layer\n",
    "\n",
    "def conv_network(feature, label, num_class, image_size, keep_prob, is_training):\n",
    "    input_layer = tf.reshape(feature, [-1, image_size, image_size, 3])\n",
    "    \n",
    "    # 16 conv layers with 64, 128, 256, 512 filters.\n",
    "    layer = conv_layer(input_layer, 64, 1, is_training)\n",
    "    layer = conv_layer(layer, 64, 1, is_training)\n",
    "    layer = tf.layers.max_pooling2d(layer, pool_size=[2, 2], strides=2, padding='same')\n",
    "    \n",
    "    layer = conv_layer(layer, 128, 1, is_training)\n",
    "    layer = conv_layer(layer, 128, 1, is_training)\n",
    "    layer = tf.layers.max_pooling2d(layer, pool_size=[2, 2], strides=2, padding='same')\n",
    "    \n",
    "    layer = conv_layer(layer, 256, 2, is_training)\n",
    "    layer = conv_layer(layer, 256, 2, is_training)\n",
    "    layer = conv_layer(layer, 256, 2, is_training)\n",
    "    layer = conv_layer(layer, 256, 2, is_training)\n",
    "    layer = tf.layers.max_pooling2d(layer, pool_size=[2, 2], strides=2, padding='same')\n",
    "    \n",
    "    layer = conv_layer(layer, 512, 2, is_training)\n",
    "    layer = conv_layer(layer, 512, 2, is_training)\n",
    "    layer = conv_layer(layer, 512, 2, is_training)\n",
    "    layer = conv_layer(layer, 512, 2, is_training)\n",
    "    layer = tf.layers.max_pooling2d(layer, pool_size=[2, 2], strides=2, padding='same')\n",
    "    \n",
    "    layer = conv_layer(layer, 512, 2, is_training)\n",
    "    layer = conv_layer(layer, 512, 2, is_training)\n",
    "    layer = conv_layer(layer, 512, 2, is_training)\n",
    "    layer = conv_layer(layer, 512, 2, is_training)\n",
    "    layer = tf.layers.max_pooling2d(layer, pool_size=[2, 2], strides=2, padding='same')\n",
    "    \n",
    "    shape = layer.get_shape().as_list()\n",
    "    layer = tf.reshape(layer, shape=[-1, shape[1]*shape[2]*shape[3]])\n",
    "    layer = fully_connected(layer, 800, is_training)\n",
    "    layer = tf.nn.dropout(layer, keep_prob)\n",
    "    logits = tf.layers.dense(layer, 80)\n",
    "    output = tf.sigmoid(logits)\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=label))\n",
    "    \n",
    "    return logits, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training from new start.\n",
      "Step 0 Training Accuracy 0.047... Training Loss 989718720.000...\n",
      "Writing checkpoint at step 0\n",
      "Step 10 Training Accuracy 0.016... Training Loss 456.297...\n",
      "Step 20 Training Accuracy 0.016... Training Loss 22.131...\n",
      "Step 30 Training Accuracy 0.000... Training Loss 7.393...\n",
      "Step 40 Training Accuracy 0.000... Training Loss 5.078...\n",
      "Step 50 Training Accuracy 0.016... Training Loss 4.716...\n",
      "Step 60 Training Accuracy 0.047... Training Loss 5.275...\n",
      "Step 70 Training Accuracy 0.016... Training Loss 4.825...\n",
      "Step 80 Training Accuracy 0.047... Training Loss 4.834...\n",
      "Step 90 Training Accuracy 0.016... Training Loss 4.944...\n",
      "Step 100 Training Accuracy 0.031... Training Loss 5.004...\n",
      "Step 110 Training Accuracy 0.031... Training Loss 4.616...\n",
      "Step 120 Training Accuracy 0.047... Training Loss 5.456...\n",
      "Step 130 Training Accuracy 0.016... Training Loss 5.189...\n",
      "Step 140 Training Accuracy 0.000... Training Loss 4.922...\n",
      "Step 150 Training Accuracy 0.000... Training Loss 4.803...\n",
      "Step 160 Training Accuracy 0.000... Training Loss 5.009...\n",
      "Step 170 Training Accuracy 0.062... Training Loss 4.358...\n",
      "Step 180 Training Accuracy 0.016... Training Loss 4.667...\n",
      "Step 190 Training Accuracy 0.016... Training Loss 4.545...\n",
      "Step 200 Training Accuracy 0.016... Training Loss 4.223...\n",
      "Step 210 Training Accuracy 0.078... Training Loss 4.273...\n",
      "Step 220 Training Accuracy 0.047... Training Loss 4.314...\n",
      "Step 230 Training Accuracy 0.016... Training Loss 4.668...\n",
      "Step 240 Training Accuracy 0.062... Training Loss 4.225...\n",
      "Step 250 Training Accuracy 0.109... Training Loss 4.430...\n",
      "Step 260 Training Accuracy 0.016... Training Loss 4.385...\n",
      "Step 270 Training Accuracy 0.094... Training Loss 4.075...\n",
      "Step 280 Training Accuracy 0.016... Training Loss 4.675...\n",
      "Step 290 Training Accuracy 0.062... Training Loss 4.250...\n",
      "Step 300 Training Accuracy 0.078... Training Loss 4.298...\n",
      "Step 310 Training Accuracy 0.047... Training Loss 4.481...\n",
      "Step 320 Training Accuracy 0.031... Training Loss 4.107...\n",
      "Step 330 Training Accuracy 0.047... Training Loss 4.005...\n",
      "Step 340 Training Accuracy 0.016... Training Loss 4.728...\n",
      "Step 350 Training Accuracy 0.062... Training Loss 4.339...\n",
      "Step 360 Training Accuracy 0.094... Training Loss 4.221...\n",
      "Step 370 Training Accuracy 0.047... Training Loss 4.289...\n",
      "Step 380 Training Accuracy 0.016... Training Loss 4.708...\n",
      "Step 390 Training Accuracy 0.062... Training Loss 4.200...\n",
      "Step 400 Training Accuracy 0.062... Training Loss 4.122...\n",
      "Step 410 Training Accuracy 0.078... Training Loss 3.918...\n",
      "Step 420 Training Accuracy 0.047... Training Loss 3.995...\n",
      "Step 430 Training Accuracy 0.062... Training Loss 4.410...\n",
      "Step 440 Training Accuracy 0.078... Training Loss 4.597...\n",
      "Step 450 Training Accuracy 0.031... Training Loss 4.055...\n",
      "Step 460 Training Accuracy 0.047... Training Loss 4.276...\n",
      "Step 470 Training Accuracy 0.109... Training Loss 3.831...\n",
      "Step 480 Training Accuracy 0.062... Training Loss 3.961...\n",
      "Step 490 Training Accuracy 0.062... Training Loss 4.031...\n",
      "Step 500 Training Accuracy 0.062... Training Loss 3.897...\n",
      "Step 510 Training Accuracy 0.125... Training Loss 3.910...\n",
      "Step 520 Training Accuracy 0.031... Training Loss 4.287...\n",
      "Step 530 Training Accuracy 0.078... Training Loss 4.053...\n",
      "Step 540 Training Accuracy 0.078... Training Loss 3.756...\n",
      "Step 550 Training Accuracy 0.078... Training Loss 3.889...\n",
      "Step 560 Training Accuracy 0.156... Training Loss 3.663...\n",
      "Step 570 Training Accuracy 0.094... Training Loss 4.023...\n",
      "Step 580 Training Accuracy 0.047... Training Loss 3.942...\n",
      "Step 590 Training Accuracy 0.078... Training Loss 3.945...\n",
      "Step 600 Training Accuracy 0.141... Training Loss 3.463...\n",
      "Step 610 Training Accuracy 0.078... Training Loss 3.856...\n",
      "Step 620 Training Accuracy 0.047... Training Loss 3.850...\n",
      "Step 630 Training Accuracy 0.109... Training Loss 4.205...\n",
      "Step 640 Training Accuracy 0.031... Training Loss 3.949...\n",
      "Step 650 Training Accuracy 0.078... Training Loss 3.819...\n",
      "Step 660 Training Accuracy 0.109... Training Loss 3.897...\n",
      "Step 670 Training Accuracy 0.125... Training Loss 3.792...\n",
      "Step 680 Training Accuracy 0.094... Training Loss 3.746...\n",
      "Step 690 Training Accuracy 0.094... Training Loss 3.930...\n",
      "Step 700 Training Accuracy 0.172... Training Loss 3.724...\n",
      "Step 710 Training Accuracy 0.078... Training Loss 3.872...\n",
      "Step 720 Training Accuracy 0.125... Training Loss 3.609...\n",
      "Step 730 Training Accuracy 0.078... Training Loss 3.855...\n",
      "Step 740 Training Accuracy 0.188... Training Loss 3.558...\n",
      "Step 750 Training Accuracy 0.156... Training Loss 3.499...\n",
      "Step 760 Training Accuracy 0.125... Training Loss 3.724...\n",
      "Step 770 Training Accuracy 0.094... Training Loss 3.675...\n",
      "Step 780 Training Accuracy 0.094... Training Loss 3.756...\n",
      "Step 790 Training Accuracy 0.141... Training Loss 3.891...\n",
      "Step 800 Training Accuracy 0.062... Training Loss 3.976...\n",
      "Step 810 Training Accuracy 0.094... Training Loss 3.835...\n",
      "Step 820 Training Accuracy 0.062... Training Loss 3.651...\n",
      "Step 830 Training Accuracy 0.078... Training Loss 3.873...\n",
      "Step 840 Training Accuracy 0.094... Training Loss 3.595...\n",
      "Step 850 Training Accuracy 0.156... Training Loss 3.411...\n",
      "Step 860 Training Accuracy 0.125... Training Loss 3.275...\n",
      "Step 870 Training Accuracy 0.094... Training Loss 3.677...\n",
      "Step 880 Training Accuracy 0.125... Training Loss 3.767...\n",
      "Step 890 Training Accuracy 0.109... Training Loss 3.447...\n",
      "Step 900 Training Accuracy 0.109... Training Loss 3.558...\n",
      "Step 910 Training Accuracy 0.109... Training Loss 3.718...\n",
      "Step 920 Training Accuracy 0.047... Training Loss 3.766...\n",
      "Step 930 Training Accuracy 0.125... Training Loss 3.695...\n",
      "Step 940 Training Accuracy 0.125... Training Loss 3.636...\n",
      "Step 950 Training Accuracy 0.094... Training Loss 3.679...\n",
      "Step 960 Training Accuracy 0.094... Training Loss 3.829...\n",
      "Step 970 Training Accuracy 0.094... Training Loss 3.620...\n",
      "Step 980 Training Accuracy 0.094... Training Loss 3.788...\n",
      "Step 990 Training Accuracy 0.141... Training Loss 3.680...\n",
      "Step 1000 Training Accuracy 0.078... Training Loss 3.594...\n",
      "Writing checkpoint at step 1000\n",
      "Step 1010 Training Accuracy 0.094... Training Loss 3.589...\n",
      "Step 1020 Training Accuracy 0.109... Training Loss 3.467...\n",
      "Step 1030 Training Accuracy 0.188... Training Loss 3.294...\n",
      "Step 1040 Training Accuracy 0.094... Training Loss 3.650...\n",
      "Step 1050 Training Accuracy 0.156... Training Loss 3.517...\n",
      "Step 1060 Training Accuracy 0.109... Training Loss 3.309...\n",
      "Step 1070 Training Accuracy 0.078... Training Loss 3.796...\n",
      "Step 1080 Training Accuracy 0.188... Training Loss 3.365...\n",
      "Step 1090 Training Accuracy 0.094... Training Loss 3.555...\n",
      "Step 1100 Training Accuracy 0.094... Training Loss 3.580...\n",
      "Step 1110 Training Accuracy 0.188... Training Loss 3.619...\n",
      "Step 1120 Training Accuracy 0.172... Training Loss 3.547...\n",
      "Step 1130 Training Accuracy 0.172... Training Loss 3.310...\n",
      "Step 1140 Training Accuracy 0.031... Training Loss 3.582...\n",
      "Step 1150 Training Accuracy 0.250... Training Loss 3.352...\n",
      "Step 1160 Training Accuracy 0.188... Training Loss 3.610...\n",
      "Step 1170 Training Accuracy 0.125... Training Loss 3.565...\n",
      "Step 1180 Training Accuracy 0.141... Training Loss 3.664...\n",
      "Step 1190 Training Accuracy 0.094... Training Loss 3.523...\n",
      "Step 1200 Training Accuracy 0.172... Training Loss 3.601...\n",
      "Step 1210 Training Accuracy 0.234... Training Loss 3.517...\n",
      "Step 1220 Training Accuracy 0.094... Training Loss 3.570...\n",
      "Step 1230 Training Accuracy 0.141... Training Loss 3.311...\n",
      "Step 1240 Training Accuracy 0.250... Training Loss 3.010...\n",
      "Step 1250 Training Accuracy 0.156... Training Loss 3.478...\n",
      "Step 1260 Training Accuracy 0.141... Training Loss 3.741...\n",
      "Step 1270 Training Accuracy 0.141... Training Loss 3.565...\n",
      "Step 1280 Training Accuracy 0.078... Training Loss 3.635...\n",
      "Step 1290 Training Accuracy 0.250... Training Loss 3.141...\n",
      "Step 1300 Training Accuracy 0.062... Training Loss 3.605...\n",
      "Step 1310 Training Accuracy 0.141... Training Loss 3.334...\n",
      "Step 1320 Training Accuracy 0.141... Training Loss 3.350...\n",
      "Step 1330 Training Accuracy 0.234... Training Loss 3.339...\n",
      "Step 1340 Training Accuracy 0.125... Training Loss 3.532...\n",
      "Step 1350 Training Accuracy 0.109... Training Loss 3.583...\n",
      "Step 1360 Training Accuracy 0.203... Training Loss 3.368...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1370 Training Accuracy 0.188... Training Loss 3.108...\n",
      "Step 1380 Training Accuracy 0.125... Training Loss 3.513...\n",
      "Step 1390 Training Accuracy 0.172... Training Loss 3.225...\n",
      "Step 1400 Training Accuracy 0.125... Training Loss 3.338...\n",
      "Step 1410 Training Accuracy 0.078... Training Loss 3.756...\n",
      "Step 1420 Training Accuracy 0.109... Training Loss 3.407...\n",
      "Step 1430 Training Accuracy 0.219... Training Loss 3.397...\n",
      "Step 1440 Training Accuracy 0.203... Training Loss 3.245...\n",
      "Step 1450 Training Accuracy 0.203... Training Loss 3.260...\n",
      "Step 1460 Training Accuracy 0.234... Training Loss 3.130...\n",
      "Step 1470 Training Accuracy 0.141... Training Loss 3.099...\n",
      "Step 1480 Training Accuracy 0.141... Training Loss 3.527...\n",
      "Step 1490 Training Accuracy 0.172... Training Loss 3.617...\n",
      "Step 1500 Training Accuracy 0.172... Training Loss 3.376...\n",
      "Step 1510 Training Accuracy 0.172... Training Loss 3.254...\n",
      "Step 1520 Training Accuracy 0.219... Training Loss 3.102...\n",
      "Step 1530 Training Accuracy 0.125... Training Loss 3.464...\n",
      "Step 1540 Training Accuracy 0.234... Training Loss 3.083...\n",
      "Step 1550 Training Accuracy 0.125... Training Loss 3.399...\n",
      "Step 1560 Training Accuracy 0.188... Training Loss 3.381...\n",
      "Step 1570 Training Accuracy 0.156... Training Loss 3.662...\n",
      "Step 1580 Training Accuracy 0.234... Training Loss 3.181...\n",
      "Step 1590 Training Accuracy 0.203... Training Loss 3.539...\n",
      "Step 1600 Training Accuracy 0.156... Training Loss 3.277...\n",
      "Step 1610 Training Accuracy 0.219... Training Loss 3.307...\n",
      "Step 1620 Training Accuracy 0.219... Training Loss 3.526...\n",
      "Step 1630 Training Accuracy 0.172... Training Loss 3.340...\n",
      "Step 1640 Training Accuracy 0.219... Training Loss 3.201...\n",
      "Step 1650 Training Accuracy 0.188... Training Loss 3.723...\n",
      "Step 1660 Training Accuracy 0.078... Training Loss 3.597...\n",
      "Step 1670 Training Accuracy 0.188... Training Loss 3.341...\n",
      "Step 1680 Training Accuracy 0.188... Training Loss 3.284...\n",
      "Step 1690 Training Accuracy 0.203... Training Loss 3.266...\n",
      "Step 1700 Training Accuracy 0.156... Training Loss 3.422...\n",
      "Step 1710 Training Accuracy 0.203... Training Loss 3.105...\n",
      "Step 1720 Training Accuracy 0.281... Training Loss 2.896...\n",
      "Step 1730 Training Accuracy 0.203... Training Loss 3.138...\n",
      "Step 1740 Training Accuracy 0.141... Training Loss 3.624...\n",
      "Step 1750 Training Accuracy 0.141... Training Loss 3.363...\n",
      "Step 1760 Training Accuracy 0.188... Training Loss 2.952...\n",
      "Step 1770 Training Accuracy 0.219... Training Loss 2.757...\n",
      "Step 1780 Training Accuracy 0.141... Training Loss 2.927...\n",
      "Step 1790 Training Accuracy 0.188... Training Loss 3.336...\n",
      "Step 1800 Training Accuracy 0.234... Training Loss 3.151...\n",
      "Step 1810 Training Accuracy 0.250... Training Loss 3.033...\n",
      "Step 1820 Training Accuracy 0.219... Training Loss 3.266...\n",
      "Step 1830 Training Accuracy 0.156... Training Loss 3.142...\n",
      "Step 1840 Training Accuracy 0.219... Training Loss 3.130...\n",
      "Step 1850 Training Accuracy 0.203... Training Loss 3.301...\n",
      "Step 1860 Training Accuracy 0.234... Training Loss 3.081...\n",
      "Step 1870 Training Accuracy 0.141... Training Loss 3.106...\n",
      "Step 1880 Training Accuracy 0.203... Training Loss 3.350...\n",
      "Step 1890 Training Accuracy 0.188... Training Loss 3.142...\n",
      "Step 1900 Training Accuracy 0.203... Training Loss 3.364...\n",
      "Step 1910 Training Accuracy 0.172... Training Loss 3.414...\n",
      "Step 1920 Training Accuracy 0.156... Training Loss 3.276...\n",
      "Step 1930 Training Accuracy 0.141... Training Loss 3.322...\n",
      "Step 1940 Training Accuracy 0.172... Training Loss 3.553...\n",
      "Step 1950 Training Accuracy 0.203... Training Loss 3.659...\n",
      "Step 1960 Training Accuracy 0.078... Training Loss 3.232...\n",
      "Step 1970 Training Accuracy 0.250... Training Loss 2.991...\n",
      "Step 1980 Training Accuracy 0.094... Training Loss 3.537...\n",
      "Step 1990 Training Accuracy 0.203... Training Loss 3.128...\n",
      "Step 2000 Training Accuracy 0.156... Training Loss 3.364...\n",
      "Writing checkpoint at step 2000\n",
      "Step 2010 Training Accuracy 0.266... Training Loss 2.947...\n",
      "Step 2020 Training Accuracy 0.203... Training Loss 3.118...\n",
      "Step 2030 Training Accuracy 0.328... Training Loss 2.857...\n",
      "Step 2040 Training Accuracy 0.188... Training Loss 3.191...\n",
      "Step 2050 Training Accuracy 0.219... Training Loss 3.201...\n",
      "Step 2060 Training Accuracy 0.234... Training Loss 3.044...\n",
      "Step 2070 Training Accuracy 0.172... Training Loss 3.210...\n",
      "Step 2080 Training Accuracy 0.188... Training Loss 3.434...\n",
      "Step 2090 Training Accuracy 0.266... Training Loss 2.771...\n",
      "Step 2100 Training Accuracy 0.188... Training Loss 3.350...\n",
      "Step 2110 Training Accuracy 0.250... Training Loss 3.006...\n",
      "Step 2120 Training Accuracy 0.328... Training Loss 2.939...\n",
      "Step 2130 Training Accuracy 0.266... Training Loss 3.142...\n",
      "Step 2140 Training Accuracy 0.250... Training Loss 3.226...\n",
      "Step 2150 Training Accuracy 0.219... Training Loss 3.139...\n",
      "Step 2160 Training Accuracy 0.188... Training Loss 2.804...\n",
      "Step 2170 Training Accuracy 0.250... Training Loss 3.094...\n",
      "Step 2180 Training Accuracy 0.156... Training Loss 3.333...\n",
      "Step 2190 Training Accuracy 0.234... Training Loss 3.219...\n",
      "Step 2200 Training Accuracy 0.219... Training Loss 3.051...\n",
      "Step 2210 Training Accuracy 0.172... Training Loss 3.133...\n",
      "Step 2220 Training Accuracy 0.266... Training Loss 3.055...\n",
      "Step 2230 Training Accuracy 0.328... Training Loss 2.886...\n",
      "Step 2240 Training Accuracy 0.156... Training Loss 2.975...\n",
      "Step 2250 Training Accuracy 0.172... Training Loss 3.170...\n",
      "Step 2260 Training Accuracy 0.172... Training Loss 3.150...\n",
      "Step 2270 Training Accuracy 0.234... Training Loss 3.054...\n",
      "Step 2280 Training Accuracy 0.219... Training Loss 2.909...\n",
      "Step 2290 Training Accuracy 0.188... Training Loss 3.275...\n",
      "Step 2300 Training Accuracy 0.266... Training Loss 2.916...\n",
      "Step 2310 Training Accuracy 0.141... Training Loss 3.309...\n",
      "Step 2320 Training Accuracy 0.219... Training Loss 3.339...\n",
      "Step 2330 Training Accuracy 0.141... Training Loss 3.341...\n",
      "Step 2340 Training Accuracy 0.281... Training Loss 2.943...\n",
      "Step 2350 Training Accuracy 0.219... Training Loss 2.810...\n",
      "Step 2360 Training Accuracy 0.172... Training Loss 3.207...\n",
      "Step 2370 Training Accuracy 0.250... Training Loss 2.879...\n",
      "Step 2380 Training Accuracy 0.312... Training Loss 2.790...\n",
      "Step 2390 Training Accuracy 0.234... Training Loss 3.024...\n",
      "Step 2400 Training Accuracy 0.156... Training Loss 3.234...\n",
      "Step 2410 Training Accuracy 0.281... Training Loss 2.846...\n",
      "Step 2420 Training Accuracy 0.250... Training Loss 2.965...\n",
      "Step 2430 Training Accuracy 0.219... Training Loss 2.985...\n",
      "Step 2440 Training Accuracy 0.203... Training Loss 3.006...\n",
      "Step 2450 Training Accuracy 0.266... Training Loss 3.109...\n",
      "Step 2460 Training Accuracy 0.234... Training Loss 3.100...\n",
      "Step 2470 Training Accuracy 0.266... Training Loss 2.986...\n",
      "Step 2480 Training Accuracy 0.172... Training Loss 3.281...\n",
      "Step 2490 Training Accuracy 0.266... Training Loss 2.842...\n",
      "Step 2500 Training Accuracy 0.250... Training Loss 2.922...\n",
      "Step 2510 Training Accuracy 0.203... Training Loss 3.317...\n",
      "Step 2520 Training Accuracy 0.266... Training Loss 2.963...\n",
      "Step 2530 Training Accuracy 0.391... Training Loss 2.589...\n",
      "Step 2540 Training Accuracy 0.219... Training Loss 3.077...\n",
      "Step 2550 Training Accuracy 0.250... Training Loss 2.860...\n",
      "Step 2560 Training Accuracy 0.266... Training Loss 2.797...\n",
      "Step 2570 Training Accuracy 0.312... Training Loss 2.806...\n",
      "Step 2580 Training Accuracy 0.234... Training Loss 3.081...\n",
      "Step 2590 Training Accuracy 0.234... Training Loss 3.232...\n",
      "Step 2600 Training Accuracy 0.266... Training Loss 2.798...\n",
      "Step 2610 Training Accuracy 0.188... Training Loss 3.026...\n",
      "Step 2620 Training Accuracy 0.203... Training Loss 3.126...\n",
      "Step 2630 Training Accuracy 0.266... Training Loss 3.159...\n",
      "Step 2640 Training Accuracy 0.266... Training Loss 2.870...\n",
      "Step 2650 Training Accuracy 0.250... Training Loss 3.004...\n",
      "Step 2660 Training Accuracy 0.266... Training Loss 3.100...\n",
      "Step 2670 Training Accuracy 0.234... Training Loss 3.186...\n",
      "Step 2680 Training Accuracy 0.281... Training Loss 2.945...\n",
      "Step 2690 Training Accuracy 0.156... Training Loss 3.239...\n",
      "Step 2700 Training Accuracy 0.250... Training Loss 3.103...\n",
      "Step 2710 Training Accuracy 0.219... Training Loss 2.802...\n",
      "Step 2720 Training Accuracy 0.250... Training Loss 3.101...\n",
      "Step 2730 Training Accuracy 0.203... Training Loss 3.154...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2740 Training Accuracy 0.188... Training Loss 3.120...\n",
      "Step 2750 Training Accuracy 0.172... Training Loss 3.282...\n",
      "Step 2760 Training Accuracy 0.328... Training Loss 2.552...\n",
      "Step 2770 Training Accuracy 0.219... Training Loss 2.770...\n",
      "Step 2780 Training Accuracy 0.266... Training Loss 2.837...\n",
      "Step 2790 Training Accuracy 0.141... Training Loss 3.078...\n",
      "Step 2800 Training Accuracy 0.391... Training Loss 2.527...\n",
      "Step 2810 Training Accuracy 0.234... Training Loss 2.778...\n",
      "Step 2820 Training Accuracy 0.266... Training Loss 2.931...\n",
      "Step 2830 Training Accuracy 0.234... Training Loss 3.101...\n",
      "Step 2840 Training Accuracy 0.312... Training Loss 2.725...\n",
      "Step 2850 Training Accuracy 0.266... Training Loss 2.817...\n",
      "Step 2860 Training Accuracy 0.234... Training Loss 2.905...\n",
      "Step 2870 Training Accuracy 0.234... Training Loss 2.706...\n",
      "Step 2880 Training Accuracy 0.250... Training Loss 2.804...\n",
      "Step 2890 Training Accuracy 0.344... Training Loss 2.793...\n",
      "Step 2900 Training Accuracy 0.172... Training Loss 3.023...\n",
      "Step 2910 Training Accuracy 0.234... Training Loss 2.759...\n",
      "Step 2920 Training Accuracy 0.141... Training Loss 3.077...\n",
      "Step 2930 Training Accuracy 0.188... Training Loss 2.896...\n",
      "Step 2940 Training Accuracy 0.188... Training Loss 3.220...\n",
      "Step 2950 Training Accuracy 0.266... Training Loss 3.069...\n",
      "Step 2960 Training Accuracy 0.234... Training Loss 2.975...\n",
      "Step 2970 Training Accuracy 0.203... Training Loss 3.012...\n",
      "Step 2980 Training Accuracy 0.188... Training Loss 3.021...\n",
      "Step 2990 Training Accuracy 0.250... Training Loss 3.164...\n",
      "Step 3000 Training Accuracy 0.250... Training Loss 2.995...\n",
      "Writing checkpoint at step 3000\n",
      "Step 3010 Training Accuracy 0.234... Training Loss 2.977...\n",
      "Step 3020 Training Accuracy 0.281... Training Loss 2.842...\n",
      "Step 3030 Training Accuracy 0.359... Training Loss 2.595...\n",
      "Step 3040 Training Accuracy 0.188... Training Loss 3.153...\n",
      "Step 3050 Training Accuracy 0.203... Training Loss 2.878...\n",
      "Step 3060 Training Accuracy 0.203... Training Loss 3.058...\n",
      "Step 3070 Training Accuracy 0.219... Training Loss 2.835...\n",
      "Step 3080 Training Accuracy 0.188... Training Loss 3.105...\n",
      "Step 3090 Training Accuracy 0.219... Training Loss 2.863...\n",
      "Step 3100 Training Accuracy 0.328... Training Loss 2.627...\n",
      "Step 3110 Training Accuracy 0.250... Training Loss 3.012...\n",
      "Step 3120 Training Accuracy 0.203... Training Loss 3.042...\n",
      "Step 3130 Training Accuracy 0.328... Training Loss 2.695...\n",
      "Step 3140 Training Accuracy 0.250... Training Loss 2.816...\n",
      "Step 3150 Training Accuracy 0.188... Training Loss 3.191...\n",
      "Step 3160 Training Accuracy 0.141... Training Loss 3.016...\n",
      "Step 3170 Training Accuracy 0.312... Training Loss 2.843...\n",
      "Step 3180 Training Accuracy 0.250... Training Loss 3.034...\n",
      "Step 3190 Training Accuracy 0.312... Training Loss 2.883...\n",
      "Step 3200 Training Accuracy 0.266... Training Loss 2.883...\n",
      "Step 3210 Training Accuracy 0.219... Training Loss 3.152...\n",
      "Step 3220 Training Accuracy 0.266... Training Loss 3.023...\n",
      "Step 3230 Training Accuracy 0.359... Training Loss 2.578...\n",
      "Step 3240 Training Accuracy 0.281... Training Loss 2.862...\n",
      "Step 3250 Training Accuracy 0.344... Training Loss 2.442...\n",
      "Step 3260 Training Accuracy 0.312... Training Loss 2.639...\n",
      "Step 3270 Training Accuracy 0.234... Training Loss 2.812...\n",
      "Step 3280 Training Accuracy 0.188... Training Loss 3.174...\n",
      "Step 3290 Training Accuracy 0.250... Training Loss 2.951...\n",
      "Step 3300 Training Accuracy 0.219... Training Loss 2.704...\n",
      "Step 3310 Training Accuracy 0.344... Training Loss 2.784...\n",
      "Step 3320 Training Accuracy 0.344... Training Loss 2.568...\n",
      "Step 3330 Training Accuracy 0.266... Training Loss 2.902...\n",
      "Step 3340 Training Accuracy 0.203... Training Loss 3.086...\n",
      "Step 3350 Training Accuracy 0.281... Training Loss 2.790...\n",
      "Step 3360 Training Accuracy 0.234... Training Loss 3.240...\n",
      "Step 3370 Training Accuracy 0.234... Training Loss 2.811...\n",
      "Step 3380 Training Accuracy 0.391... Training Loss 2.565...\n",
      "Step 3390 Training Accuracy 0.312... Training Loss 2.703...\n",
      "Step 3400 Training Accuracy 0.312... Training Loss 2.812...\n",
      "Step 3410 Training Accuracy 0.250... Training Loss 3.004...\n",
      "Step 3420 Training Accuracy 0.328... Training Loss 2.713...\n",
      "Step 3430 Training Accuracy 0.234... Training Loss 3.058...\n",
      "Step 3440 Training Accuracy 0.234... Training Loss 2.779...\n",
      "Step 3450 Training Accuracy 0.312... Training Loss 2.803...\n",
      "Step 3460 Training Accuracy 0.344... Training Loss 2.662...\n",
      "Step 3470 Training Accuracy 0.281... Training Loss 2.733...\n",
      "Step 3480 Training Accuracy 0.281... Training Loss 2.831...\n",
      "Step 3490 Training Accuracy 0.328... Training Loss 2.792...\n",
      "Step 3500 Training Accuracy 0.406... Training Loss 2.649...\n",
      "Step 3510 Training Accuracy 0.281... Training Loss 2.573...\n",
      "Step 3520 Training Accuracy 0.344... Training Loss 2.442...\n",
      "Step 3530 Training Accuracy 0.250... Training Loss 2.713...\n",
      "Step 3540 Training Accuracy 0.328... Training Loss 2.688...\n",
      "Step 3550 Training Accuracy 0.297... Training Loss 2.882...\n",
      "Step 3560 Training Accuracy 0.219... Training Loss 2.907...\n",
      "Step 3570 Training Accuracy 0.344... Training Loss 2.492...\n",
      "Step 3580 Training Accuracy 0.328... Training Loss 2.464...\n",
      "Step 3590 Training Accuracy 0.375... Training Loss 2.541...\n",
      "Step 3600 Training Accuracy 0.281... Training Loss 2.803...\n",
      "Step 3610 Training Accuracy 0.281... Training Loss 2.664...\n",
      "Step 3620 Training Accuracy 0.234... Training Loss 2.980...\n",
      "Step 3630 Training Accuracy 0.344... Training Loss 2.980...\n",
      "Step 3640 Training Accuracy 0.266... Training Loss 2.764...\n",
      "Step 3650 Training Accuracy 0.250... Training Loss 2.694...\n",
      "Step 3660 Training Accuracy 0.281... Training Loss 2.654...\n",
      "Step 3670 Training Accuracy 0.188... Training Loss 2.844...\n",
      "Step 3680 Training Accuracy 0.297... Training Loss 2.671...\n",
      "Step 3690 Training Accuracy 0.250... Training Loss 2.736...\n",
      "Step 3700 Training Accuracy 0.203... Training Loss 2.867...\n",
      "Step 3710 Training Accuracy 0.297... Training Loss 2.770...\n",
      "Step 3720 Training Accuracy 0.156... Training Loss 3.305...\n",
      "Step 3730 Training Accuracy 0.359... Training Loss 2.491...\n",
      "Step 3740 Training Accuracy 0.328... Training Loss 2.732...\n",
      "Step 3750 Training Accuracy 0.219... Training Loss 2.622...\n",
      "Step 3760 Training Accuracy 0.250... Training Loss 2.764...\n",
      "Step 3770 Training Accuracy 0.297... Training Loss 2.585...\n",
      "Step 3780 Training Accuracy 0.234... Training Loss 2.681...\n",
      "Step 3790 Training Accuracy 0.312... Training Loss 2.638...\n",
      "Step 3800 Training Accuracy 0.281... Training Loss 2.772...\n",
      "Step 3810 Training Accuracy 0.312... Training Loss 2.702...\n",
      "Step 3820 Training Accuracy 0.344... Training Loss 2.595...\n",
      "Step 3830 Training Accuracy 0.328... Training Loss 2.511...\n",
      "Step 3840 Training Accuracy 0.312... Training Loss 2.533...\n",
      "Step 3850 Training Accuracy 0.328... Training Loss 2.736...\n",
      "Step 3860 Training Accuracy 0.391... Training Loss 2.599...\n",
      "Step 3870 Training Accuracy 0.297... Training Loss 2.687...\n",
      "Step 3880 Training Accuracy 0.266... Training Loss 2.986...\n",
      "Step 3890 Training Accuracy 0.359... Training Loss 2.630...\n",
      "Step 3900 Training Accuracy 0.297... Training Loss 2.884...\n",
      "Step 3910 Training Accuracy 0.359... Training Loss 2.834...\n",
      "Step 3920 Training Accuracy 0.312... Training Loss 2.798...\n",
      "Step 3930 Training Accuracy 0.250... Training Loss 3.066...\n",
      "Step 3940 Training Accuracy 0.250... Training Loss 2.608...\n",
      "Step 3950 Training Accuracy 0.266... Training Loss 2.655...\n",
      "Step 3960 Training Accuracy 0.375... Training Loss 2.494...\n",
      "Step 3970 Training Accuracy 0.312... Training Loss 2.642...\n",
      "Step 3980 Training Accuracy 0.250... Training Loss 2.997...\n",
      "Step 3990 Training Accuracy 0.297... Training Loss 2.742...\n",
      "Step 4000 Training Accuracy 0.312... Training Loss 2.670...\n",
      "Writing checkpoint at step 4000\n",
      "Step 4010 Training Accuracy 0.266... Training Loss 2.804...\n",
      "Step 4020 Training Accuracy 0.234... Training Loss 2.967...\n",
      "Step 4030 Training Accuracy 0.328... Training Loss 2.551...\n",
      "Step 4040 Training Accuracy 0.312... Training Loss 2.601...\n",
      "Step 4050 Training Accuracy 0.359... Training Loss 2.475...\n",
      "Step 4060 Training Accuracy 0.312... Training Loss 2.488...\n",
      "Step 4070 Training Accuracy 0.391... Training Loss 2.935...\n",
      "Step 4080 Training Accuracy 0.281... Training Loss 2.711...\n",
      "Step 4090 Training Accuracy 0.312... Training Loss 2.647...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4100 Training Accuracy 0.344... Training Loss 2.518...\n",
      "Step 4110 Training Accuracy 0.266... Training Loss 2.599...\n",
      "Step 4120 Training Accuracy 0.297... Training Loss 2.797...\n",
      "Step 4130 Training Accuracy 0.234... Training Loss 3.052...\n",
      "Step 4140 Training Accuracy 0.266... Training Loss 2.611...\n",
      "Step 4150 Training Accuracy 0.344... Training Loss 2.611...\n",
      "Step 4160 Training Accuracy 0.328... Training Loss 2.553...\n",
      "Step 4170 Training Accuracy 0.234... Training Loss 3.171...\n",
      "Step 4180 Training Accuracy 0.250... Training Loss 3.054...\n",
      "Step 4190 Training Accuracy 0.312... Training Loss 2.773...\n",
      "Step 4200 Training Accuracy 0.281... Training Loss 2.734...\n",
      "Step 4210 Training Accuracy 0.375... Training Loss 2.548...\n",
      "Step 4220 Training Accuracy 0.344... Training Loss 2.457...\n",
      "Step 4230 Training Accuracy 0.266... Training Loss 2.464...\n",
      "Step 4240 Training Accuracy 0.438... Training Loss 2.294...\n",
      "Step 4250 Training Accuracy 0.406... Training Loss 2.551...\n",
      "Step 4260 Training Accuracy 0.250... Training Loss 2.653...\n",
      "Step 4270 Training Accuracy 0.281... Training Loss 2.750...\n",
      "Step 4280 Training Accuracy 0.234... Training Loss 2.764...\n",
      "Step 4290 Training Accuracy 0.469... Training Loss 2.228...\n",
      "Step 4300 Training Accuracy 0.312... Training Loss 2.663...\n",
      "Step 4310 Training Accuracy 0.250... Training Loss 2.901...\n",
      "Step 4320 Training Accuracy 0.328... Training Loss 2.666...\n",
      "Step 4330 Training Accuracy 0.219... Training Loss 2.755...\n",
      "Step 4340 Training Accuracy 0.359... Training Loss 2.403...\n",
      "Step 4350 Training Accuracy 0.328... Training Loss 2.668...\n",
      "Step 4360 Training Accuracy 0.203... Training Loss 2.841...\n",
      "Step 4370 Training Accuracy 0.391... Training Loss 2.430...\n",
      "Step 4380 Training Accuracy 0.328... Training Loss 2.789...\n",
      "Step 4390 Training Accuracy 0.266... Training Loss 2.720...\n",
      "Step 4400 Training Accuracy 0.297... Training Loss 2.822...\n",
      "Step 4410 Training Accuracy 0.297... Training Loss 2.663...\n",
      "Step 4420 Training Accuracy 0.422... Training Loss 2.387...\n",
      "Step 4430 Training Accuracy 0.344... Training Loss 2.588...\n",
      "Step 4440 Training Accuracy 0.266... Training Loss 2.771...\n",
      "Step 4450 Training Accuracy 0.297... Training Loss 2.746...\n",
      "Step 4460 Training Accuracy 0.297... Training Loss 2.561...\n",
      "Step 4470 Training Accuracy 0.281... Training Loss 2.994...\n",
      "Step 4480 Training Accuracy 0.234... Training Loss 3.058...\n",
      "Step 4490 Training Accuracy 0.359... Training Loss 2.455...\n",
      "Step 4500 Training Accuracy 0.281... Training Loss 2.565...\n",
      "Step 4510 Training Accuracy 0.250... Training Loss 2.863...\n",
      "Step 4520 Training Accuracy 0.359... Training Loss 2.642...\n",
      "Step 4530 Training Accuracy 0.406... Training Loss 2.377...\n",
      "Step 4540 Training Accuracy 0.359... Training Loss 2.458...\n",
      "Step 4550 Training Accuracy 0.438... Training Loss 2.129...\n",
      "Step 4560 Training Accuracy 0.203... Training Loss 2.772...\n",
      "Step 4570 Training Accuracy 0.266... Training Loss 2.943...\n",
      "Step 4580 Training Accuracy 0.391... Training Loss 2.428...\n",
      "Step 4590 Training Accuracy 0.297... Training Loss 2.664...\n",
      "Step 4600 Training Accuracy 0.422... Training Loss 2.210...\n",
      "Step 4610 Training Accuracy 0.266... Training Loss 2.586...\n",
      "Step 4620 Training Accuracy 0.406... Training Loss 2.106...\n",
      "Step 4630 Training Accuracy 0.281... Training Loss 2.666...\n",
      "Step 4640 Training Accuracy 0.344... Training Loss 2.559...\n",
      "Step 4650 Training Accuracy 0.203... Training Loss 3.159...\n",
      "Step 4660 Training Accuracy 0.375... Training Loss 2.545...\n",
      "Step 4670 Training Accuracy 0.344... Training Loss 2.638...\n",
      "Step 4680 Training Accuracy 0.203... Training Loss 3.075...\n",
      "Step 4690 Training Accuracy 0.406... Training Loss 2.358...\n",
      "Step 4700 Training Accuracy 0.297... Training Loss 2.992...\n",
      "Step 4710 Training Accuracy 0.297... Training Loss 2.453...\n",
      "Step 4720 Training Accuracy 0.406... Training Loss 2.197...\n",
      "Step 4730 Training Accuracy 0.391... Training Loss 2.462...\n",
      "Step 4740 Training Accuracy 0.266... Training Loss 2.543...\n",
      "Step 4750 Training Accuracy 0.359... Training Loss 2.345...\n",
      "Step 4760 Training Accuracy 0.234... Training Loss 2.651...\n",
      "Step 4770 Training Accuracy 0.375... Training Loss 2.461...\n",
      "Step 4780 Training Accuracy 0.281... Training Loss 2.579...\n",
      "Step 4790 Training Accuracy 0.359... Training Loss 2.354...\n",
      "Step 4800 Training Accuracy 0.281... Training Loss 2.721...\n",
      "Step 4810 Training Accuracy 0.312... Training Loss 2.570...\n",
      "Step 4820 Training Accuracy 0.344... Training Loss 2.309...\n",
      "Step 4830 Training Accuracy 0.312... Training Loss 2.603...\n",
      "Step 4840 Training Accuracy 0.312... Training Loss 2.508...\n",
      "Step 4850 Training Accuracy 0.312... Training Loss 2.550...\n",
      "Step 4860 Training Accuracy 0.312... Training Loss 2.536...\n",
      "Step 4870 Training Accuracy 0.406... Training Loss 2.110...\n",
      "Step 4880 Training Accuracy 0.328... Training Loss 2.159...\n",
      "Step 4890 Training Accuracy 0.453... Training Loss 2.308...\n",
      "Step 4900 Training Accuracy 0.391... Training Loss 2.257...\n",
      "Step 4910 Training Accuracy 0.344... Training Loss 2.481...\n",
      "Step 4920 Training Accuracy 0.297... Training Loss 2.939...\n",
      "Step 4930 Training Accuracy 0.359... Training Loss 2.268...\n",
      "Step 4940 Training Accuracy 0.375... Training Loss 2.355...\n",
      "Step 4950 Training Accuracy 0.359... Training Loss 2.463...\n",
      "Step 4960 Training Accuracy 0.375... Training Loss 2.400...\n",
      "Step 4970 Training Accuracy 0.359... Training Loss 2.260...\n",
      "Step 4980 Training Accuracy 0.375... Training Loss 2.173...\n",
      "Step 4990 Training Accuracy 0.234... Training Loss 2.814...\n",
      "Step 5000 Training Accuracy 0.344... Training Loss 2.577...\n",
      "Writing checkpoint at step 5000\n",
      "Step 5010 Training Accuracy 0.406... Training Loss 2.222...\n",
      "Step 5020 Training Accuracy 0.234... Training Loss 2.751...\n",
      "Step 5030 Training Accuracy 0.328... Training Loss 2.236...\n",
      "Step 5040 Training Accuracy 0.250... Training Loss 2.898...\n",
      "Step 5050 Training Accuracy 0.453... Training Loss 1.936...\n",
      "Step 5060 Training Accuracy 0.422... Training Loss 2.275...\n",
      "Step 5070 Training Accuracy 0.453... Training Loss 2.062...\n",
      "Step 5080 Training Accuracy 0.516... Training Loss 2.254...\n",
      "Step 5090 Training Accuracy 0.422... Training Loss 2.270...\n",
      "Step 5100 Training Accuracy 0.391... Training Loss 2.351...\n",
      "Step 5110 Training Accuracy 0.391... Training Loss 2.486...\n",
      "Step 5120 Training Accuracy 0.328... Training Loss 2.606...\n",
      "Step 5130 Training Accuracy 0.328... Training Loss 2.361...\n",
      "Step 5140 Training Accuracy 0.344... Training Loss 2.549...\n",
      "Step 5150 Training Accuracy 0.391... Training Loss 2.388...\n",
      "Step 5160 Training Accuracy 0.406... Training Loss 2.126...\n",
      "Step 5170 Training Accuracy 0.391... Training Loss 2.247...\n",
      "Step 5180 Training Accuracy 0.422... Training Loss 2.318...\n",
      "Step 5190 Training Accuracy 0.328... Training Loss 2.364...\n",
      "Step 5200 Training Accuracy 0.406... Training Loss 2.414...\n",
      "Step 5210 Training Accuracy 0.328... Training Loss 2.458...\n",
      "Step 5220 Training Accuracy 0.234... Training Loss 2.870...\n",
      "Step 5230 Training Accuracy 0.484... Training Loss 1.984...\n",
      "Step 5240 Training Accuracy 0.422... Training Loss 2.283...\n",
      "Step 5250 Training Accuracy 0.406... Training Loss 2.409...\n",
      "Step 5260 Training Accuracy 0.406... Training Loss 2.377...\n",
      "Step 5270 Training Accuracy 0.344... Training Loss 2.238...\n",
      "Step 5280 Training Accuracy 0.359... Training Loss 2.458...\n",
      "Step 5290 Training Accuracy 0.203... Training Loss 3.016...\n",
      "Step 5300 Training Accuracy 0.406... Training Loss 2.442...\n",
      "Step 5310 Training Accuracy 0.375... Training Loss 2.357...\n",
      "Step 5320 Training Accuracy 0.375... Training Loss 2.281...\n",
      "Step 5330 Training Accuracy 0.438... Training Loss 2.406...\n",
      "Step 5340 Training Accuracy 0.453... Training Loss 2.014...\n",
      "Step 5350 Training Accuracy 0.422... Training Loss 2.315...\n",
      "Step 5360 Training Accuracy 0.312... Training Loss 2.795...\n",
      "Step 5370 Training Accuracy 0.406... Training Loss 2.438...\n",
      "Step 5380 Training Accuracy 0.391... Training Loss 2.492...\n",
      "Step 5390 Training Accuracy 0.297... Training Loss 2.504...\n",
      "Step 5400 Training Accuracy 0.422... Training Loss 2.183...\n",
      "Step 5410 Training Accuracy 0.531... Training Loss 1.838...\n",
      "Step 5420 Training Accuracy 0.344... Training Loss 2.588...\n",
      "Step 5430 Training Accuracy 0.375... Training Loss 2.382...\n",
      "Step 5440 Training Accuracy 0.344... Training Loss 2.259...\n",
      "Step 5450 Training Accuracy 0.328... Training Loss 2.284...\n",
      "Step 5460 Training Accuracy 0.312... Training Loss 2.532...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5470 Training Accuracy 0.359... Training Loss 2.247...\n",
      "Step 5480 Training Accuracy 0.359... Training Loss 2.507...\n",
      "Step 5490 Training Accuracy 0.406... Training Loss 2.189...\n",
      "Step 5500 Training Accuracy 0.234... Training Loss 2.705...\n",
      "Step 5510 Training Accuracy 0.375... Training Loss 2.694...\n",
      "Step 5520 Training Accuracy 0.359... Training Loss 2.358...\n",
      "Step 5530 Training Accuracy 0.297... Training Loss 2.255...\n",
      "Step 5540 Training Accuracy 0.391... Training Loss 2.206...\n",
      "Step 5550 Training Accuracy 0.578... Training Loss 1.731...\n",
      "Step 5560 Training Accuracy 0.219... Training Loss 2.822...\n",
      "Step 5570 Training Accuracy 0.344... Training Loss 2.288...\n",
      "Step 5580 Training Accuracy 0.344... Training Loss 2.152...\n",
      "Step 5590 Training Accuracy 0.359... Training Loss 2.434...\n",
      "Step 5600 Training Accuracy 0.422... Training Loss 2.275...\n",
      "Step 5610 Training Accuracy 0.312... Training Loss 2.305...\n",
      "Step 5620 Training Accuracy 0.391... Training Loss 2.529...\n",
      "Step 5630 Training Accuracy 0.422... Training Loss 2.478...\n",
      "Step 5640 Training Accuracy 0.391... Training Loss 2.205...\n",
      "Step 5650 Training Accuracy 0.469... Training Loss 2.009...\n",
      "Step 5660 Training Accuracy 0.453... Training Loss 2.044...\n",
      "Step 5670 Training Accuracy 0.344... Training Loss 2.462...\n",
      "Step 5680 Training Accuracy 0.453... Training Loss 2.389...\n",
      "Step 5690 Training Accuracy 0.422... Training Loss 2.175...\n",
      "Step 5700 Training Accuracy 0.359... Training Loss 2.536...\n",
      "Step 5710 Training Accuracy 0.281... Training Loss 2.502...\n",
      "Step 5720 Training Accuracy 0.438... Training Loss 2.008...\n",
      "Step 5730 Training Accuracy 0.391... Training Loss 1.903...\n",
      "Step 5740 Training Accuracy 0.453... Training Loss 2.188...\n",
      "Step 5750 Training Accuracy 0.453... Training Loss 1.996...\n",
      "Step 5760 Training Accuracy 0.328... Training Loss 2.590...\n",
      "Step 5770 Training Accuracy 0.422... Training Loss 2.202...\n",
      "Step 5780 Training Accuracy 0.281... Training Loss 2.641...\n",
      "Step 5790 Training Accuracy 0.422... Training Loss 2.155...\n",
      "Step 5800 Training Accuracy 0.453... Training Loss 2.276...\n",
      "Step 5810 Training Accuracy 0.391... Training Loss 2.508...\n",
      "Step 5820 Training Accuracy 0.391... Training Loss 2.404...\n",
      "Step 5830 Training Accuracy 0.344... Training Loss 2.535...\n",
      "Step 5840 Training Accuracy 0.359... Training Loss 2.547...\n",
      "Step 5850 Training Accuracy 0.484... Training Loss 2.174...\n",
      "Step 5860 Training Accuracy 0.406... Training Loss 2.275...\n",
      "Step 5870 Training Accuracy 0.328... Training Loss 2.417...\n",
      "Step 5880 Training Accuracy 0.469... Training Loss 1.862...\n",
      "Step 5890 Training Accuracy 0.438... Training Loss 1.999...\n",
      "Step 5900 Training Accuracy 0.422... Training Loss 1.947...\n",
      "Step 5910 Training Accuracy 0.391... Training Loss 2.196...\n",
      "Step 5920 Training Accuracy 0.391... Training Loss 2.391...\n",
      "Step 5930 Training Accuracy 0.422... Training Loss 2.171...\n",
      "Step 5940 Training Accuracy 0.406... Training Loss 2.430...\n",
      "Step 5950 Training Accuracy 0.375... Training Loss 2.205...\n",
      "Step 5960 Training Accuracy 0.406... Training Loss 2.151...\n",
      "Step 5970 Training Accuracy 0.500... Training Loss 2.003...\n",
      "Step 5980 Training Accuracy 0.469... Training Loss 2.079...\n",
      "Step 5990 Training Accuracy 0.438... Training Loss 2.199...\n",
      "Step 6000 Training Accuracy 0.328... Training Loss 2.485...\n",
      "Writing checkpoint at step 6000\n",
      "Step 6010 Training Accuracy 0.469... Training Loss 2.152...\n",
      "Step 6020 Training Accuracy 0.453... Training Loss 1.923...\n",
      "Step 6030 Training Accuracy 0.500... Training Loss 2.259...\n",
      "Step 6040 Training Accuracy 0.422... Training Loss 2.296...\n",
      "Step 6050 Training Accuracy 0.516... Training Loss 2.074...\n",
      "Step 6060 Training Accuracy 0.500... Training Loss 1.886...\n",
      "Step 6070 Training Accuracy 0.344... Training Loss 2.295...\n",
      "Step 6080 Training Accuracy 0.375... Training Loss 2.443...\n",
      "Step 6090 Training Accuracy 0.422... Training Loss 2.240...\n",
      "Step 6100 Training Accuracy 0.375... Training Loss 2.270...\n",
      "Step 6110 Training Accuracy 0.438... Training Loss 2.132...\n",
      "Step 6120 Training Accuracy 0.391... Training Loss 2.115...\n",
      "Step 6130 Training Accuracy 0.422... Training Loss 2.045...\n",
      "Step 6140 Training Accuracy 0.484... Training Loss 2.057...\n",
      "Step 6150 Training Accuracy 0.344... Training Loss 2.322...\n",
      "Step 6160 Training Accuracy 0.453... Training Loss 2.001...\n",
      "Step 6170 Training Accuracy 0.422... Training Loss 2.302...\n",
      "Step 6180 Training Accuracy 0.453... Training Loss 1.807...\n",
      "Step 6190 Training Accuracy 0.266... Training Loss 2.894...\n",
      "Step 6200 Training Accuracy 0.312... Training Loss 2.340...\n",
      "Step 6210 Training Accuracy 0.359... Training Loss 2.455...\n",
      "Step 6220 Training Accuracy 0.328... Training Loss 2.319...\n",
      "Step 6230 Training Accuracy 0.531... Training Loss 2.096...\n",
      "Step 6240 Training Accuracy 0.391... Training Loss 2.249...\n",
      "Step 6250 Training Accuracy 0.438... Training Loss 2.151...\n",
      "Step 6260 Training Accuracy 0.391... Training Loss 2.439...\n",
      "Step 6270 Training Accuracy 0.406... Training Loss 1.903...\n",
      "Step 6280 Training Accuracy 0.359... Training Loss 2.192...\n",
      "Step 6290 Training Accuracy 0.406... Training Loss 2.210...\n",
      "Step 6300 Training Accuracy 0.297... Training Loss 2.392...\n",
      "Step 6310 Training Accuracy 0.375... Training Loss 2.543...\n",
      "Step 6320 Training Accuracy 0.406... Training Loss 2.314...\n",
      "Step 6330 Training Accuracy 0.453... Training Loss 2.125...\n",
      "Step 6340 Training Accuracy 0.281... Training Loss 2.597...\n",
      "Step 6350 Training Accuracy 0.438... Training Loss 2.153...\n",
      "Step 6360 Training Accuracy 0.500... Training Loss 2.249...\n",
      "Step 6370 Training Accuracy 0.438... Training Loss 1.900...\n",
      "Step 6380 Training Accuracy 0.500... Training Loss 2.046...\n",
      "Step 6390 Training Accuracy 0.453... Training Loss 2.190...\n",
      "Step 6400 Training Accuracy 0.297... Training Loss 2.261...\n",
      "Step 6410 Training Accuracy 0.500... Training Loss 1.970...\n",
      "Step 6420 Training Accuracy 0.500... Training Loss 1.951...\n",
      "Step 6430 Training Accuracy 0.469... Training Loss 1.647...\n",
      "Step 6440 Training Accuracy 0.375... Training Loss 2.356...\n",
      "Step 6450 Training Accuracy 0.375... Training Loss 2.287...\n",
      "Step 6460 Training Accuracy 0.422... Training Loss 2.299...\n",
      "Step 6470 Training Accuracy 0.375... Training Loss 2.105...\n",
      "Step 6480 Training Accuracy 0.547... Training Loss 1.940...\n",
      "Step 6490 Training Accuracy 0.438... Training Loss 1.860...\n",
      "Step 6500 Training Accuracy 0.281... Training Loss 2.228...\n",
      "Step 6510 Training Accuracy 0.453... Training Loss 1.930...\n",
      "Step 6520 Training Accuracy 0.297... Training Loss 2.568...\n",
      "Step 6530 Training Accuracy 0.266... Training Loss 2.647...\n",
      "Step 6540 Training Accuracy 0.375... Training Loss 2.385...\n",
      "Step 6550 Training Accuracy 0.406... Training Loss 1.977...\n",
      "Step 6560 Training Accuracy 0.484... Training Loss 2.157...\n",
      "Step 6570 Training Accuracy 0.422... Training Loss 2.300...\n",
      "Step 6580 Training Accuracy 0.422... Training Loss 2.009...\n",
      "Step 6590 Training Accuracy 0.375... Training Loss 2.117...\n",
      "Step 6600 Training Accuracy 0.547... Training Loss 1.620...\n",
      "Step 6610 Training Accuracy 0.469... Training Loss 1.966...\n",
      "Step 6620 Training Accuracy 0.453... Training Loss 1.953...\n",
      "Step 6630 Training Accuracy 0.406... Training Loss 2.230...\n",
      "Step 6640 Training Accuracy 0.406... Training Loss 2.161...\n",
      "Step 6650 Training Accuracy 0.469... Training Loss 2.076...\n",
      "Step 6660 Training Accuracy 0.422... Training Loss 2.194...\n",
      "Step 6670 Training Accuracy 0.438... Training Loss 2.115...\n",
      "Step 6680 Training Accuracy 0.391... Training Loss 2.091...\n",
      "Step 6690 Training Accuracy 0.375... Training Loss 2.338...\n",
      "Step 6700 Training Accuracy 0.312... Training Loss 2.418...\n",
      "Step 6710 Training Accuracy 0.438... Training Loss 2.065...\n",
      "Step 6720 Training Accuracy 0.500... Training Loss 1.975...\n",
      "Step 6730 Training Accuracy 0.562... Training Loss 1.733...\n",
      "Step 6740 Training Accuracy 0.500... Training Loss 1.596...\n",
      "Step 6750 Training Accuracy 0.500... Training Loss 2.095...\n",
      "Step 6760 Training Accuracy 0.375... Training Loss 2.410...\n",
      "Step 6770 Training Accuracy 0.469... Training Loss 1.927...\n",
      "Step 6780 Training Accuracy 0.516... Training Loss 2.056...\n",
      "Step 6790 Training Accuracy 0.516... Training Loss 1.722...\n",
      "Step 6800 Training Accuracy 0.438... Training Loss 2.429...\n",
      "Step 6810 Training Accuracy 0.453... Training Loss 2.013...\n",
      "Step 6820 Training Accuracy 0.406... Training Loss 2.544...\n",
      "Step 6830 Training Accuracy 0.453... Training Loss 2.115...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6840 Training Accuracy 0.375... Training Loss 2.102...\n",
      "Step 6850 Training Accuracy 0.422... Training Loss 2.088...\n",
      "Step 6860 Training Accuracy 0.406... Training Loss 1.875...\n",
      "Step 6870 Training Accuracy 0.375... Training Loss 2.295...\n",
      "Step 6880 Training Accuracy 0.547... Training Loss 1.882...\n",
      "Step 6890 Training Accuracy 0.500... Training Loss 1.963...\n",
      "Step 6900 Training Accuracy 0.531... Training Loss 1.835...\n",
      "Step 6910 Training Accuracy 0.484... Training Loss 1.846...\n",
      "Step 6920 Training Accuracy 0.453... Training Loss 1.964...\n",
      "Step 6930 Training Accuracy 0.469... Training Loss 2.188...\n",
      "Step 6940 Training Accuracy 0.359... Training Loss 2.325...\n",
      "Step 6950 Training Accuracy 0.297... Training Loss 2.624...\n",
      "Step 6960 Training Accuracy 0.500... Training Loss 1.914...\n",
      "Step 6970 Training Accuracy 0.516... Training Loss 1.815...\n",
      "Step 6980 Training Accuracy 0.391... Training Loss 2.151...\n",
      "Step 6990 Training Accuracy 0.500... Training Loss 1.812...\n",
      "Step 7000 Training Accuracy 0.375... Training Loss 1.901...\n",
      "Writing checkpoint at step 7000\n",
      "Step 7010 Training Accuracy 0.438... Training Loss 1.983...\n",
      "Step 7020 Training Accuracy 0.484... Training Loss 2.047...\n",
      "Step 7030 Training Accuracy 0.359... Training Loss 1.992...\n",
      "Step 7040 Training Accuracy 0.469... Training Loss 1.765...\n",
      "Step 7050 Training Accuracy 0.531... Training Loss 1.831...\n",
      "Step 7060 Training Accuracy 0.422... Training Loss 2.202...\n",
      "Step 7070 Training Accuracy 0.438... Training Loss 1.917...\n",
      "Step 7080 Training Accuracy 0.500... Training Loss 1.845...\n",
      "Step 7090 Training Accuracy 0.406... Training Loss 2.081...\n",
      "Step 7100 Training Accuracy 0.500... Training Loss 1.776...\n",
      "Step 7110 Training Accuracy 0.500... Training Loss 1.806...\n",
      "Step 7120 Training Accuracy 0.453... Training Loss 2.059...\n",
      "Step 7130 Training Accuracy 0.453... Training Loss 2.042...\n",
      "Step 7140 Training Accuracy 0.500... Training Loss 2.177...\n",
      "Step 7150 Training Accuracy 0.438... Training Loss 2.196...\n",
      "Step 7160 Training Accuracy 0.500... Training Loss 2.032...\n",
      "Step 7170 Training Accuracy 0.453... Training Loss 2.137...\n",
      "Step 7180 Training Accuracy 0.375... Training Loss 2.230...\n",
      "Step 7190 Training Accuracy 0.516... Training Loss 2.045...\n",
      "Step 7200 Training Accuracy 0.406... Training Loss 2.179...\n",
      "Step 7210 Training Accuracy 0.469... Training Loss 1.786...\n",
      "Step 7220 Training Accuracy 0.375... Training Loss 2.164...\n",
      "Step 7230 Training Accuracy 0.578... Training Loss 1.756...\n",
      "Step 7240 Training Accuracy 0.438... Training Loss 1.878...\n",
      "Step 7250 Training Accuracy 0.438... Training Loss 2.047...\n",
      "Step 7260 Training Accuracy 0.469... Training Loss 2.276...\n",
      "Step 7270 Training Accuracy 0.453... Training Loss 2.066...\n",
      "Step 7280 Training Accuracy 0.500... Training Loss 1.913...\n",
      "Step 7290 Training Accuracy 0.469... Training Loss 2.184...\n",
      "Step 7300 Training Accuracy 0.500... Training Loss 1.925...\n",
      "Step 7310 Training Accuracy 0.438... Training Loss 1.916...\n",
      "Step 7320 Training Accuracy 0.531... Training Loss 2.080...\n",
      "Step 7330 Training Accuracy 0.656... Training Loss 1.528...\n",
      "Step 7340 Training Accuracy 0.453... Training Loss 2.115...\n",
      "Step 7350 Training Accuracy 0.484... Training Loss 1.915...\n",
      "Step 7360 Training Accuracy 0.391... Training Loss 2.226...\n",
      "Step 7370 Training Accuracy 0.359... Training Loss 1.806...\n",
      "Step 7380 Training Accuracy 0.406... Training Loss 2.326...\n",
      "Step 7390 Training Accuracy 0.500... Training Loss 1.916...\n",
      "Step 7400 Training Accuracy 0.531... Training Loss 1.699...\n",
      "Step 7410 Training Accuracy 0.453... Training Loss 2.010...\n",
      "Step 7420 Training Accuracy 0.469... Training Loss 1.996...\n",
      "Step 7430 Training Accuracy 0.562... Training Loss 1.652...\n",
      "Step 7440 Training Accuracy 0.484... Training Loss 1.844...\n",
      "Step 7450 Training Accuracy 0.547... Training Loss 1.666...\n",
      "Step 7460 Training Accuracy 0.500... Training Loss 1.771...\n",
      "Step 7470 Training Accuracy 0.484... Training Loss 1.967...\n",
      "Step 7480 Training Accuracy 0.469... Training Loss 1.772...\n",
      "Step 7490 Training Accuracy 0.484... Training Loss 1.943...\n",
      "Step 7500 Training Accuracy 0.531... Training Loss 2.059...\n",
      "Step 7510 Training Accuracy 0.422... Training Loss 2.019...\n",
      "Step 7520 Training Accuracy 0.484... Training Loss 1.919...\n",
      "Step 7530 Training Accuracy 0.453... Training Loss 2.037...\n",
      "Step 7540 Training Accuracy 0.500... Training Loss 1.886...\n",
      "Step 7550 Training Accuracy 0.516... Training Loss 1.953...\n",
      "Step 7560 Training Accuracy 0.391... Training Loss 2.433...\n",
      "Step 7570 Training Accuracy 0.406... Training Loss 2.224...\n",
      "Step 7580 Training Accuracy 0.406... Training Loss 2.053...\n",
      "Step 7590 Training Accuracy 0.531... Training Loss 1.899...\n",
      "Step 7600 Training Accuracy 0.547... Training Loss 1.756...\n",
      "Step 7610 Training Accuracy 0.453... Training Loss 2.042...\n",
      "Step 7620 Training Accuracy 0.469... Training Loss 1.754...\n",
      "Step 7630 Training Accuracy 0.406... Training Loss 2.225...\n",
      "Step 7640 Training Accuracy 0.359... Training Loss 2.317...\n",
      "Step 7650 Training Accuracy 0.344... Training Loss 2.120...\n",
      "Step 7660 Training Accuracy 0.562... Training Loss 1.657...\n",
      "Step 7670 Training Accuracy 0.500... Training Loss 1.704...\n",
      "Step 7680 Training Accuracy 0.672... Training Loss 1.643...\n",
      "Step 7690 Training Accuracy 0.531... Training Loss 1.584...\n",
      "Step 7700 Training Accuracy 0.656... Training Loss 1.444...\n",
      "Step 7710 Training Accuracy 0.516... Training Loss 1.716...\n",
      "Step 7720 Training Accuracy 0.516... Training Loss 1.856...\n",
      "Step 7730 Training Accuracy 0.484... Training Loss 1.754...\n",
      "Step 7740 Training Accuracy 0.484... Training Loss 1.691...\n",
      "Step 7750 Training Accuracy 0.594... Training Loss 1.621...\n",
      "Step 7760 Training Accuracy 0.516... Training Loss 1.580...\n",
      "Step 7770 Training Accuracy 0.453... Training Loss 1.851...\n",
      "Step 7780 Training Accuracy 0.500... Training Loss 1.652...\n",
      "Step 7790 Training Accuracy 0.547... Training Loss 1.686...\n",
      "Step 7800 Training Accuracy 0.406... Training Loss 1.940...\n",
      "Step 7810 Training Accuracy 0.531... Training Loss 1.744...\n",
      "Step 7820 Training Accuracy 0.469... Training Loss 2.109...\n",
      "Step 7830 Training Accuracy 0.453... Training Loss 1.755...\n",
      "Step 7840 Training Accuracy 0.469... Training Loss 2.053...\n",
      "Step 7850 Training Accuracy 0.453... Training Loss 2.129...\n",
      "Step 7860 Training Accuracy 0.469... Training Loss 1.996...\n",
      "Step 7870 Training Accuracy 0.422... Training Loss 1.841...\n",
      "Step 7880 Training Accuracy 0.562... Training Loss 1.560...\n",
      "Step 7890 Training Accuracy 0.531... Training Loss 1.764...\n",
      "Step 7900 Training Accuracy 0.500... Training Loss 1.709...\n",
      "Step 7910 Training Accuracy 0.594... Training Loss 1.532...\n",
      "Step 7920 Training Accuracy 0.453... Training Loss 1.759...\n",
      "Step 7930 Training Accuracy 0.391... Training Loss 2.229...\n",
      "Step 7940 Training Accuracy 0.516... Training Loss 1.684...\n",
      "Step 7950 Training Accuracy 0.484... Training Loss 1.932...\n",
      "Step 7960 Training Accuracy 0.484... Training Loss 1.873...\n",
      "Step 7970 Training Accuracy 0.469... Training Loss 1.809...\n",
      "Step 7980 Training Accuracy 0.562... Training Loss 1.525...\n",
      "Step 7990 Training Accuracy 0.406... Training Loss 1.787...\n",
      "Step 8000 Training Accuracy 0.500... Training Loss 1.795...\n",
      "Writing checkpoint at step 8000\n",
      "Step 8010 Training Accuracy 0.500... Training Loss 1.912...\n",
      "Step 8020 Training Accuracy 0.406... Training Loss 1.958...\n",
      "Step 8030 Training Accuracy 0.469... Training Loss 2.015...\n",
      "Step 8040 Training Accuracy 0.500... Training Loss 1.701...\n",
      "Step 8050 Training Accuracy 0.438... Training Loss 2.015...\n",
      "Step 8060 Training Accuracy 0.609... Training Loss 1.512...\n",
      "Step 8070 Training Accuracy 0.578... Training Loss 1.635...\n",
      "Step 8080 Training Accuracy 0.500... Training Loss 1.719...\n",
      "Step 8090 Training Accuracy 0.453... Training Loss 1.701...\n",
      "Step 8100 Training Accuracy 0.453... Training Loss 1.916...\n",
      "Step 8110 Training Accuracy 0.562... Training Loss 1.642...\n",
      "Step 8120 Training Accuracy 0.312... Training Loss 2.422...\n",
      "Step 8130 Training Accuracy 0.516... Training Loss 1.869...\n",
      "Step 8140 Training Accuracy 0.484... Training Loss 1.844...\n",
      "Step 8150 Training Accuracy 0.500... Training Loss 1.724...\n",
      "Step 8160 Training Accuracy 0.516... Training Loss 1.702...\n",
      "Step 8170 Training Accuracy 0.594... Training Loss 1.667...\n",
      "Step 8180 Training Accuracy 0.516... Training Loss 1.721...\n",
      "Step 8190 Training Accuracy 0.453... Training Loss 1.858...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8200 Training Accuracy 0.438... Training Loss 1.889...\n",
      "Step 8210 Training Accuracy 0.500... Training Loss 1.550...\n",
      "Step 8220 Training Accuracy 0.578... Training Loss 1.838...\n",
      "Step 8230 Training Accuracy 0.469... Training Loss 1.963...\n",
      "Step 8240 Training Accuracy 0.531... Training Loss 1.794...\n",
      "Step 8250 Training Accuracy 0.516... Training Loss 1.699...\n",
      "Step 8260 Training Accuracy 0.594... Training Loss 1.652...\n",
      "Step 8270 Training Accuracy 0.469... Training Loss 1.802...\n",
      "Step 8280 Training Accuracy 0.422... Training Loss 1.732...\n",
      "Step 8290 Training Accuracy 0.531... Training Loss 1.857...\n",
      "Step 8300 Training Accuracy 0.578... Training Loss 1.544...\n",
      "Step 8310 Training Accuracy 0.453... Training Loss 1.926...\n",
      "Step 8320 Training Accuracy 0.500... Training Loss 1.766...\n",
      "Step 8330 Training Accuracy 0.422... Training Loss 2.032...\n",
      "Step 8340 Training Accuracy 0.406... Training Loss 2.207...\n",
      "Step 8350 Training Accuracy 0.469... Training Loss 2.033...\n",
      "Step 8360 Training Accuracy 0.562... Training Loss 1.547...\n",
      "Step 8370 Training Accuracy 0.547... Training Loss 1.654...\n",
      "Step 8380 Training Accuracy 0.531... Training Loss 1.644...\n",
      "Step 8390 Training Accuracy 0.484... Training Loss 1.690...\n",
      "Step 8400 Training Accuracy 0.438... Training Loss 1.879...\n",
      "Step 8410 Training Accuracy 0.516... Training Loss 1.741...\n",
      "Step 8420 Training Accuracy 0.531... Training Loss 1.577...\n",
      "Step 8430 Training Accuracy 0.547... Training Loss 1.545...\n",
      "Step 8440 Training Accuracy 0.531... Training Loss 1.549...\n",
      "Step 8450 Training Accuracy 0.578... Training Loss 1.592...\n",
      "Step 8460 Training Accuracy 0.594... Training Loss 1.665...\n",
      "Step 8470 Training Accuracy 0.609... Training Loss 1.453...\n",
      "Step 8480 Training Accuracy 0.391... Training Loss 2.043...\n",
      "Step 8490 Training Accuracy 0.609... Training Loss 1.446...\n",
      "Step 8500 Training Accuracy 0.656... Training Loss 1.388...\n",
      "Step 8510 Training Accuracy 0.500... Training Loss 1.647...\n",
      "Step 8520 Training Accuracy 0.625... Training Loss 1.627...\n",
      "Step 8530 Training Accuracy 0.516... Training Loss 2.178...\n",
      "Step 8540 Training Accuracy 0.609... Training Loss 1.861...\n",
      "Step 8550 Training Accuracy 0.641... Training Loss 1.248...\n",
      "Step 8560 Training Accuracy 0.500... Training Loss 1.689...\n",
      "Step 8570 Training Accuracy 0.547... Training Loss 1.714...\n",
      "Step 8580 Training Accuracy 0.625... Training Loss 1.639...\n",
      "Step 8590 Training Accuracy 0.469... Training Loss 1.628...\n",
      "Step 8600 Training Accuracy 0.438... Training Loss 1.997...\n",
      "Step 8610 Training Accuracy 0.531... Training Loss 1.845...\n",
      "Step 8620 Training Accuracy 0.656... Training Loss 1.122...\n",
      "Step 8630 Training Accuracy 0.656... Training Loss 1.296...\n",
      "Step 8640 Training Accuracy 0.500... Training Loss 1.688...\n",
      "Step 8650 Training Accuracy 0.500... Training Loss 1.679...\n",
      "Step 8660 Training Accuracy 0.484... Training Loss 1.578...\n",
      "Step 8670 Training Accuracy 0.500... Training Loss 1.823...\n",
      "Step 8680 Training Accuracy 0.500... Training Loss 1.656...\n",
      "Step 8690 Training Accuracy 0.531... Training Loss 1.784...\n",
      "Step 8700 Training Accuracy 0.547... Training Loss 1.796...\n",
      "Step 8710 Training Accuracy 0.484... Training Loss 1.501...\n",
      "Step 8720 Training Accuracy 0.484... Training Loss 1.784...\n",
      "Step 8730 Training Accuracy 0.547... Training Loss 1.562...\n",
      "Step 8740 Training Accuracy 0.562... Training Loss 1.510...\n",
      "Step 8750 Training Accuracy 0.516... Training Loss 1.917...\n",
      "Step 8760 Training Accuracy 0.531... Training Loss 1.606...\n",
      "Step 8770 Training Accuracy 0.422... Training Loss 2.153...\n",
      "Step 8780 Training Accuracy 0.578... Training Loss 1.519...\n",
      "Step 8790 Training Accuracy 0.672... Training Loss 1.259...\n",
      "Step 8800 Training Accuracy 0.500... Training Loss 1.744...\n",
      "Step 8810 Training Accuracy 0.609... Training Loss 1.491...\n",
      "Step 8820 Training Accuracy 0.594... Training Loss 1.489...\n",
      "Step 8830 Training Accuracy 0.609... Training Loss 1.607...\n",
      "Step 8840 Training Accuracy 0.578... Training Loss 1.453...\n",
      "Step 8850 Training Accuracy 0.484... Training Loss 1.905...\n",
      "Step 8860 Training Accuracy 0.484... Training Loss 1.857...\n",
      "Step 8870 Training Accuracy 0.516... Training Loss 1.673...\n",
      "Step 8880 Training Accuracy 0.625... Training Loss 1.323...\n",
      "Step 8890 Training Accuracy 0.531... Training Loss 1.764...\n",
      "Step 8900 Training Accuracy 0.484... Training Loss 2.190...\n",
      "Step 8910 Training Accuracy 0.641... Training Loss 1.416...\n",
      "Step 8920 Training Accuracy 0.594... Training Loss 1.796...\n",
      "Step 8930 Training Accuracy 0.578... Training Loss 1.509...\n",
      "Step 8940 Training Accuracy 0.547... Training Loss 1.383...\n",
      "Step 8950 Training Accuracy 0.516... Training Loss 1.704...\n",
      "Step 8960 Training Accuracy 0.484... Training Loss 1.568...\n",
      "Step 8970 Training Accuracy 0.562... Training Loss 1.557...\n",
      "Step 8980 Training Accuracy 0.594... Training Loss 1.497...\n",
      "Step 8990 Training Accuracy 0.594... Training Loss 1.427...\n",
      "Step 9000 Training Accuracy 0.531... Training Loss 1.448...\n",
      "Writing checkpoint at step 9000\n",
      "Step 9010 Training Accuracy 0.438... Training Loss 1.848...\n",
      "Step 9020 Training Accuracy 0.516... Training Loss 1.667...\n",
      "Step 9030 Training Accuracy 0.625... Training Loss 1.606...\n",
      "Step 9040 Training Accuracy 0.562... Training Loss 1.691...\n",
      "Step 9050 Training Accuracy 0.578... Training Loss 1.452...\n",
      "Step 9060 Training Accuracy 0.609... Training Loss 1.559...\n",
      "Step 9070 Training Accuracy 0.516... Training Loss 1.828...\n",
      "Step 9080 Training Accuracy 0.562... Training Loss 1.834...\n",
      "Step 9090 Training Accuracy 0.625... Training Loss 1.385...\n",
      "Step 9100 Training Accuracy 0.703... Training Loss 1.222...\n",
      "Step 9110 Training Accuracy 0.609... Training Loss 1.367...\n",
      "Step 9120 Training Accuracy 0.547... Training Loss 1.611...\n",
      "Step 9130 Training Accuracy 0.578... Training Loss 1.662...\n",
      "Step 9140 Training Accuracy 0.562... Training Loss 1.514...\n",
      "Step 9150 Training Accuracy 0.516... Training Loss 1.604...\n",
      "Step 9160 Training Accuracy 0.469... Training Loss 1.882...\n",
      "Step 9170 Training Accuracy 0.594... Training Loss 1.323...\n",
      "Step 9180 Training Accuracy 0.516... Training Loss 1.814...\n",
      "Step 9190 Training Accuracy 0.547... Training Loss 1.473...\n",
      "Step 9200 Training Accuracy 0.656... Training Loss 1.360...\n",
      "Step 9210 Training Accuracy 0.641... Training Loss 1.348...\n",
      "Step 9220 Training Accuracy 0.562... Training Loss 1.435...\n",
      "Step 9230 Training Accuracy 0.609... Training Loss 1.387...\n",
      "Step 9240 Training Accuracy 0.500... Training Loss 1.753...\n",
      "Step 9250 Training Accuracy 0.453... Training Loss 1.937...\n",
      "Step 9260 Training Accuracy 0.438... Training Loss 1.762...\n",
      "Step 9270 Training Accuracy 0.562... Training Loss 1.568...\n",
      "Step 9280 Training Accuracy 0.641... Training Loss 1.277...\n",
      "Step 9290 Training Accuracy 0.641... Training Loss 1.380...\n",
      "Step 9300 Training Accuracy 0.594... Training Loss 1.241...\n",
      "Step 9310 Training Accuracy 0.562... Training Loss 1.894...\n",
      "Step 9320 Training Accuracy 0.594... Training Loss 1.525...\n",
      "Step 9330 Training Accuracy 0.703... Training Loss 1.071...\n",
      "Step 9340 Training Accuracy 0.500... Training Loss 1.853...\n",
      "Step 9350 Training Accuracy 0.609... Training Loss 1.430...\n",
      "Step 9360 Training Accuracy 0.422... Training Loss 1.698...\n",
      "Step 9370 Training Accuracy 0.656... Training Loss 1.241...\n",
      "Step 9380 Training Accuracy 0.688... Training Loss 1.098...\n",
      "Step 9390 Training Accuracy 0.594... Training Loss 1.462...\n",
      "Step 9400 Training Accuracy 0.672... Training Loss 1.139...\n",
      "Step 9410 Training Accuracy 0.547... Training Loss 1.498...\n",
      "Step 9420 Training Accuracy 0.469... Training Loss 1.763...\n",
      "Step 9430 Training Accuracy 0.594... Training Loss 1.451...\n",
      "Step 9440 Training Accuracy 0.422... Training Loss 2.062...\n",
      "Step 9450 Training Accuracy 0.500... Training Loss 1.403...\n",
      "Step 9460 Training Accuracy 0.594... Training Loss 1.522...\n",
      "Step 9470 Training Accuracy 0.469... Training Loss 1.809...\n",
      "Step 9480 Training Accuracy 0.578... Training Loss 1.485...\n",
      "Step 9490 Training Accuracy 0.500... Training Loss 1.492...\n",
      "Step 9500 Training Accuracy 0.484... Training Loss 1.875...\n",
      "Step 9510 Training Accuracy 0.578... Training Loss 1.596...\n",
      "Step 9520 Training Accuracy 0.609... Training Loss 1.351...\n",
      "Step 9530 Training Accuracy 0.609... Training Loss 1.565...\n",
      "Step 9540 Training Accuracy 0.516... Training Loss 1.557...\n",
      "Step 9550 Training Accuracy 0.562... Training Loss 1.318...\n",
      "Step 9560 Training Accuracy 0.547... Training Loss 1.583...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9570 Training Accuracy 0.500... Training Loss 1.644...\n",
      "Step 9580 Training Accuracy 0.609... Training Loss 1.431...\n",
      "Step 9590 Training Accuracy 0.469... Training Loss 1.735...\n",
      "Step 9600 Training Accuracy 0.656... Training Loss 1.184...\n",
      "Step 9610 Training Accuracy 0.688... Training Loss 0.981...\n",
      "Step 9620 Training Accuracy 0.609... Training Loss 1.387...\n",
      "Step 9630 Training Accuracy 0.531... Training Loss 1.476...\n",
      "Step 9640 Training Accuracy 0.562... Training Loss 1.720...\n",
      "Step 9650 Training Accuracy 0.562... Training Loss 1.631...\n",
      "Step 9660 Training Accuracy 0.672... Training Loss 1.316...\n",
      "Step 9670 Training Accuracy 0.656... Training Loss 1.366...\n",
      "Step 9680 Training Accuracy 0.547... Training Loss 1.625...\n",
      "Step 9690 Training Accuracy 0.500... Training Loss 1.684...\n",
      "Step 9700 Training Accuracy 0.578... Training Loss 1.417...\n",
      "Step 9710 Training Accuracy 0.547... Training Loss 1.624...\n",
      "Step 9720 Training Accuracy 0.562... Training Loss 1.585...\n",
      "Step 9730 Training Accuracy 0.656... Training Loss 1.297...\n",
      "Step 9740 Training Accuracy 0.594... Training Loss 1.463...\n",
      "Step 9750 Training Accuracy 0.594... Training Loss 1.090...\n",
      "Step 9760 Training Accuracy 0.609... Training Loss 1.300...\n",
      "Step 9770 Training Accuracy 0.531... Training Loss 1.631...\n",
      "Step 9780 Training Accuracy 0.641... Training Loss 1.176...\n",
      "Step 9790 Training Accuracy 0.516... Training Loss 1.627...\n",
      "Step 9800 Training Accuracy 0.578... Training Loss 1.495...\n",
      "Step 9810 Training Accuracy 0.531... Training Loss 1.722...\n",
      "Step 9820 Training Accuracy 0.453... Training Loss 1.487...\n",
      "Step 9830 Training Accuracy 0.656... Training Loss 1.374...\n",
      "Step 9840 Training Accuracy 0.594... Training Loss 1.535...\n",
      "Step 9850 Training Accuracy 0.641... Training Loss 1.178...\n",
      "Step 9860 Training Accuracy 0.562... Training Loss 1.417...\n",
      "Step 9870 Training Accuracy 0.609... Training Loss 1.347...\n",
      "Step 9880 Training Accuracy 0.516... Training Loss 1.674...\n",
      "Step 9890 Training Accuracy 0.547... Training Loss 1.717...\n",
      "Step 9900 Training Accuracy 0.656... Training Loss 1.532...\n",
      "Step 9910 Training Accuracy 0.484... Training Loss 1.342...\n",
      "Step 9920 Training Accuracy 0.531... Training Loss 1.414...\n",
      "Step 9930 Training Accuracy 0.609... Training Loss 1.374...\n",
      "Step 9940 Training Accuracy 0.641... Training Loss 1.067...\n",
      "Step 9950 Training Accuracy 0.688... Training Loss 1.213...\n",
      "Step 9960 Training Accuracy 0.438... Training Loss 1.895...\n",
      "Step 9970 Training Accuracy 0.547... Training Loss 1.659...\n",
      "Step 9980 Training Accuracy 0.484... Training Loss 1.982...\n",
      "Step 9990 Training Accuracy 0.578... Training Loss 1.509...\n",
      "Step 10000 Training Accuracy 0.594... Training Loss 1.374...\n",
      "Writing checkpoint at step 10000\n",
      "Step 10010 Training Accuracy 0.625... Training Loss 1.345...\n",
      "Step 10020 Training Accuracy 0.531... Training Loss 1.403...\n",
      "Step 10030 Training Accuracy 0.625... Training Loss 1.315...\n",
      "Step 10040 Training Accuracy 0.531... Training Loss 1.477...\n",
      "Step 10050 Training Accuracy 0.484... Training Loss 1.974...\n",
      "Step 10060 Training Accuracy 0.531... Training Loss 1.653...\n",
      "Step 10070 Training Accuracy 0.562... Training Loss 1.544...\n",
      "Step 10080 Training Accuracy 0.391... Training Loss 2.014...\n",
      "Step 10090 Training Accuracy 0.641... Training Loss 1.279...\n",
      "Step 10100 Training Accuracy 0.562... Training Loss 1.554...\n",
      "Step 10110 Training Accuracy 0.688... Training Loss 1.291...\n",
      "Step 10120 Training Accuracy 0.609... Training Loss 1.269...\n",
      "Step 10130 Training Accuracy 0.609... Training Loss 1.451...\n",
      "Step 10140 Training Accuracy 0.578... Training Loss 1.608...\n",
      "Step 10150 Training Accuracy 0.609... Training Loss 1.343...\n",
      "Step 10160 Training Accuracy 0.562... Training Loss 1.610...\n",
      "Step 10170 Training Accuracy 0.578... Training Loss 1.497...\n",
      "Step 10180 Training Accuracy 0.594... Training Loss 1.461...\n",
      "Step 10190 Training Accuracy 0.609... Training Loss 1.466...\n",
      "Step 10200 Training Accuracy 0.594... Training Loss 1.495...\n",
      "Step 10210 Training Accuracy 0.656... Training Loss 1.598...\n",
      "Step 10220 Training Accuracy 0.594... Training Loss 1.128...\n",
      "Step 10230 Training Accuracy 0.734... Training Loss 0.986...\n",
      "Step 10240 Training Accuracy 0.672... Training Loss 1.072...\n",
      "Step 10250 Training Accuracy 0.594... Training Loss 1.534...\n",
      "Step 10260 Training Accuracy 0.594... Training Loss 1.531...\n",
      "Step 10270 Training Accuracy 0.656... Training Loss 1.448...\n",
      "Step 10280 Training Accuracy 0.594... Training Loss 1.565...\n",
      "Step 10290 Training Accuracy 0.625... Training Loss 1.462...\n",
      "Step 10300 Training Accuracy 0.469... Training Loss 1.579...\n",
      "Step 10310 Training Accuracy 0.562... Training Loss 1.234...\n",
      "Step 10320 Training Accuracy 0.672... Training Loss 1.017...\n",
      "Step 10330 Training Accuracy 0.562... Training Loss 1.561...\n",
      "Step 10340 Training Accuracy 0.594... Training Loss 1.251...\n",
      "Step 10350 Training Accuracy 0.609... Training Loss 1.258...\n",
      "Step 10360 Training Accuracy 0.531... Training Loss 1.413...\n",
      "Step 10370 Training Accuracy 0.688... Training Loss 1.267...\n",
      "Step 10380 Training Accuracy 0.594... Training Loss 1.397...\n",
      "Step 10390 Training Accuracy 0.625... Training Loss 1.349...\n",
      "Step 10400 Training Accuracy 0.562... Training Loss 1.596...\n",
      "Step 10410 Training Accuracy 0.641... Training Loss 1.115...\n",
      "Step 10420 Training Accuracy 0.578... Training Loss 1.386...\n",
      "Step 10430 Training Accuracy 0.516... Training Loss 1.675...\n",
      "Step 10440 Training Accuracy 0.500... Training Loss 1.369...\n",
      "Step 10450 Training Accuracy 0.750... Training Loss 0.909...\n",
      "Step 10460 Training Accuracy 0.594... Training Loss 1.511...\n",
      "Step 10470 Training Accuracy 0.609... Training Loss 1.299...\n",
      "Step 10480 Training Accuracy 0.703... Training Loss 1.108...\n",
      "Step 10490 Training Accuracy 0.625... Training Loss 1.560...\n",
      "Step 10500 Training Accuracy 0.625... Training Loss 1.138...\n",
      "Step 10510 Training Accuracy 0.594... Training Loss 1.249...\n",
      "Step 10520 Training Accuracy 0.578... Training Loss 1.786...\n",
      "Step 10530 Training Accuracy 0.625... Training Loss 1.482...\n",
      "Step 10540 Training Accuracy 0.641... Training Loss 1.176...\n",
      "Step 10550 Training Accuracy 0.641... Training Loss 1.253...\n",
      "Step 10560 Training Accuracy 0.594... Training Loss 1.512...\n",
      "Step 10570 Training Accuracy 0.625... Training Loss 1.549...\n",
      "Step 10580 Training Accuracy 0.609... Training Loss 1.321...\n",
      "Step 10590 Training Accuracy 0.656... Training Loss 1.177...\n",
      "Step 10600 Training Accuracy 0.594... Training Loss 1.376...\n",
      "Step 10610 Training Accuracy 0.609... Training Loss 1.318...\n",
      "Step 10620 Training Accuracy 0.672... Training Loss 1.122...\n",
      "Step 10630 Training Accuracy 0.641... Training Loss 1.120...\n",
      "Step 10640 Training Accuracy 0.594... Training Loss 1.131...\n",
      "Step 10650 Training Accuracy 0.625... Training Loss 1.264...\n",
      "Step 10660 Training Accuracy 0.641... Training Loss 1.307...\n",
      "Step 10670 Training Accuracy 0.672... Training Loss 1.197...\n",
      "Step 10680 Training Accuracy 0.641... Training Loss 1.265...\n",
      "Step 10690 Training Accuracy 0.578... Training Loss 1.589...\n",
      "Step 10700 Training Accuracy 0.688... Training Loss 1.214...\n",
      "Step 10710 Training Accuracy 0.547... Training Loss 1.389...\n",
      "Step 10720 Training Accuracy 0.562... Training Loss 1.366...\n",
      "Step 10730 Training Accuracy 0.609... Training Loss 1.280...\n",
      "Step 10740 Training Accuracy 0.500... Training Loss 1.892...\n",
      "Step 10750 Training Accuracy 0.594... Training Loss 1.562...\n",
      "Step 10760 Training Accuracy 0.656... Training Loss 1.021...\n",
      "Step 10770 Training Accuracy 0.672... Training Loss 1.335...\n",
      "Step 10780 Training Accuracy 0.609... Training Loss 1.298...\n",
      "Step 10790 Training Accuracy 0.719... Training Loss 1.277...\n",
      "Step 10800 Training Accuracy 0.609... Training Loss 1.414...\n",
      "Step 10810 Training Accuracy 0.609... Training Loss 1.082...\n",
      "Step 10820 Training Accuracy 0.672... Training Loss 1.279...\n",
      "Step 10830 Training Accuracy 0.734... Training Loss 1.255...\n",
      "Step 10840 Training Accuracy 0.688... Training Loss 0.981...\n",
      "Step 10850 Training Accuracy 0.562... Training Loss 1.554...\n",
      "Step 10860 Training Accuracy 0.594... Training Loss 1.442...\n",
      "Step 10870 Training Accuracy 0.719... Training Loss 1.044...\n",
      "Step 10880 Training Accuracy 0.594... Training Loss 1.324...\n",
      "Step 10890 Training Accuracy 0.625... Training Loss 1.370...\n",
      "Step 10900 Training Accuracy 0.562... Training Loss 1.626...\n",
      "Step 10910 Training Accuracy 0.609... Training Loss 1.620...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10920 Training Accuracy 0.688... Training Loss 1.100...\n",
      "Step 10930 Training Accuracy 0.672... Training Loss 1.211...\n",
      "Step 10940 Training Accuracy 0.734... Training Loss 0.860...\n",
      "Step 10950 Training Accuracy 0.609... Training Loss 1.298...\n",
      "Step 10960 Training Accuracy 0.750... Training Loss 1.014...\n",
      "Step 10970 Training Accuracy 0.562... Training Loss 1.352...\n",
      "Step 10980 Training Accuracy 0.734... Training Loss 0.913...\n",
      "Step 10990 Training Accuracy 0.609... Training Loss 1.197...\n",
      "Step 11000 Training Accuracy 0.609... Training Loss 1.479...\n",
      "Writing checkpoint at step 11000\n",
      "Step 11010 Training Accuracy 0.641... Training Loss 1.369...\n",
      "Step 11020 Training Accuracy 0.578... Training Loss 1.424...\n",
      "Step 11030 Training Accuracy 0.625... Training Loss 1.226...\n",
      "Step 11040 Training Accuracy 0.625... Training Loss 1.385...\n",
      "Step 11050 Training Accuracy 0.500... Training Loss 1.363...\n",
      "Step 11060 Training Accuracy 0.688... Training Loss 1.186...\n",
      "Step 11070 Training Accuracy 0.625... Training Loss 1.165...\n",
      "Step 11080 Training Accuracy 0.703... Training Loss 1.000...\n",
      "Step 11090 Training Accuracy 0.672... Training Loss 1.245...\n",
      "Step 11100 Training Accuracy 0.609... Training Loss 1.101...\n",
      "Step 11110 Training Accuracy 0.609... Training Loss 1.327...\n",
      "Step 11120 Training Accuracy 0.641... Training Loss 1.284...\n",
      "Step 11130 Training Accuracy 0.562... Training Loss 1.530...\n",
      "Step 11140 Training Accuracy 0.641... Training Loss 1.426...\n",
      "Step 11150 Training Accuracy 0.625... Training Loss 1.286...\n",
      "Step 11160 Training Accuracy 0.672... Training Loss 1.067...\n",
      "Step 11170 Training Accuracy 0.656... Training Loss 1.058...\n",
      "Step 11180 Training Accuracy 0.625... Training Loss 1.308...\n",
      "Step 11190 Training Accuracy 0.562... Training Loss 1.442...\n",
      "Step 11200 Training Accuracy 0.625... Training Loss 1.162...\n",
      "Step 11210 Training Accuracy 0.594... Training Loss 1.387...\n",
      "Step 11220 Training Accuracy 0.641... Training Loss 1.108...\n",
      "Step 11230 Training Accuracy 0.688... Training Loss 1.157...\n",
      "Step 11240 Training Accuracy 0.578... Training Loss 1.347...\n",
      "Step 11250 Training Accuracy 0.750... Training Loss 1.107...\n",
      "Step 11260 Training Accuracy 0.625... Training Loss 1.210...\n",
      "Step 11270 Training Accuracy 0.594... Training Loss 1.439...\n",
      "Step 11280 Training Accuracy 0.641... Training Loss 1.283...\n",
      "Step 11290 Training Accuracy 0.734... Training Loss 0.964...\n",
      "Step 11300 Training Accuracy 0.594... Training Loss 1.510...\n",
      "Step 11310 Training Accuracy 0.625... Training Loss 1.403...\n",
      "Step 11320 Training Accuracy 0.703... Training Loss 1.205...\n",
      "Step 11330 Training Accuracy 0.609... Training Loss 1.246...\n",
      "Step 11340 Training Accuracy 0.578... Training Loss 1.493...\n",
      "Step 11350 Training Accuracy 0.594... Training Loss 1.225...\n",
      "Step 11360 Training Accuracy 0.578... Training Loss 1.366...\n",
      "Step 11370 Training Accuracy 0.625... Training Loss 1.200...\n",
      "Step 11380 Training Accuracy 0.750... Training Loss 0.980...\n",
      "Step 11390 Training Accuracy 0.719... Training Loss 0.985...\n",
      "Step 11400 Training Accuracy 0.656... Training Loss 1.193...\n",
      "Step 11410 Training Accuracy 0.609... Training Loss 1.217...\n",
      "Step 11420 Training Accuracy 0.688... Training Loss 1.022...\n",
      "Step 11430 Training Accuracy 0.562... Training Loss 1.523...\n",
      "Step 11440 Training Accuracy 0.641... Training Loss 1.003...\n",
      "Step 11450 Training Accuracy 0.625... Training Loss 1.163...\n",
      "Step 11460 Training Accuracy 0.641... Training Loss 1.299...\n",
      "Step 11470 Training Accuracy 0.734... Training Loss 0.987...\n",
      "Step 11480 Training Accuracy 0.641... Training Loss 0.988...\n",
      "Step 11490 Training Accuracy 0.719... Training Loss 0.980...\n",
      "Step 11500 Training Accuracy 0.688... Training Loss 1.123...\n",
      "Step 11510 Training Accuracy 0.656... Training Loss 1.154...\n",
      "Step 11520 Training Accuracy 0.719... Training Loss 1.070...\n",
      "Step 11530 Training Accuracy 0.656... Training Loss 1.123...\n",
      "Step 11540 Training Accuracy 0.719... Training Loss 1.021...\n",
      "Step 11550 Training Accuracy 0.625... Training Loss 1.183...\n",
      "Step 11560 Training Accuracy 0.594... Training Loss 1.283...\n",
      "Step 11570 Training Accuracy 0.703... Training Loss 1.039...\n",
      "Step 11580 Training Accuracy 0.672... Training Loss 1.452...\n",
      "Step 11590 Training Accuracy 0.516... Training Loss 1.731...\n",
      "Step 11600 Training Accuracy 0.625... Training Loss 1.424...\n",
      "Step 11610 Training Accuracy 0.578... Training Loss 1.127...\n",
      "Step 11620 Training Accuracy 0.625... Training Loss 1.297...\n",
      "Step 11630 Training Accuracy 0.594... Training Loss 1.292...\n",
      "Step 11640 Training Accuracy 0.750... Training Loss 0.758...\n",
      "Step 11650 Training Accuracy 0.578... Training Loss 1.458...\n",
      "Step 11660 Training Accuracy 0.734... Training Loss 0.925...\n",
      "Step 11670 Training Accuracy 0.766... Training Loss 0.903...\n",
      "Step 11680 Training Accuracy 0.578... Training Loss 1.220...\n",
      "Step 11690 Training Accuracy 0.688... Training Loss 0.968...\n",
      "Step 11700 Training Accuracy 0.719... Training Loss 1.148...\n",
      "Step 11710 Training Accuracy 0.672... Training Loss 1.024...\n",
      "Step 11720 Training Accuracy 0.641... Training Loss 1.244...\n",
      "Step 11730 Training Accuracy 0.750... Training Loss 0.806...\n",
      "Step 11740 Training Accuracy 0.547... Training Loss 1.494...\n",
      "Step 11750 Training Accuracy 0.641... Training Loss 1.258...\n",
      "Step 11760 Training Accuracy 0.656... Training Loss 0.930...\n",
      "Step 11770 Training Accuracy 0.547... Training Loss 1.571...\n",
      "Step 11780 Training Accuracy 0.625... Training Loss 1.290...\n",
      "Step 11790 Training Accuracy 0.688... Training Loss 0.973...\n",
      "Step 11800 Training Accuracy 0.641... Training Loss 1.148...\n",
      "Step 11810 Training Accuracy 0.719... Training Loss 1.105...\n",
      "Step 11820 Training Accuracy 0.750... Training Loss 0.916...\n",
      "Step 11830 Training Accuracy 0.750... Training Loss 0.671...\n",
      "Step 11840 Training Accuracy 0.656... Training Loss 1.118...\n",
      "Step 11850 Training Accuracy 0.641... Training Loss 0.983...\n",
      "Step 11860 Training Accuracy 0.672... Training Loss 1.101...\n",
      "Step 11870 Training Accuracy 0.688... Training Loss 1.125...\n",
      "Step 11880 Training Accuracy 0.609... Training Loss 1.228...\n",
      "Step 11890 Training Accuracy 0.719... Training Loss 1.010...\n",
      "Step 11900 Training Accuracy 0.734... Training Loss 0.877...\n",
      "Step 11910 Training Accuracy 0.766... Training Loss 0.988...\n",
      "Step 11920 Training Accuracy 0.688... Training Loss 0.955...\n",
      "Step 11930 Training Accuracy 0.734... Training Loss 0.844...\n",
      "Step 11940 Training Accuracy 0.750... Training Loss 0.850...\n",
      "Step 11950 Training Accuracy 0.594... Training Loss 1.336...\n",
      "Step 11960 Training Accuracy 0.547... Training Loss 1.220...\n",
      "Step 11970 Training Accuracy 0.766... Training Loss 0.901...\n",
      "Step 11980 Training Accuracy 0.719... Training Loss 1.226...\n",
      "Step 11990 Training Accuracy 0.625... Training Loss 1.111...\n",
      "Step 12000 Training Accuracy 0.703... Training Loss 1.027...\n",
      "Writing checkpoint at step 12000\n",
      "Step 12010 Training Accuracy 0.672... Training Loss 1.137...\n",
      "Step 12020 Training Accuracy 0.766... Training Loss 0.805...\n",
      "Step 12030 Training Accuracy 0.703... Training Loss 0.969...\n",
      "Step 12040 Training Accuracy 0.734... Training Loss 0.966...\n",
      "Step 12050 Training Accuracy 0.797... Training Loss 0.981...\n",
      "Step 12060 Training Accuracy 0.672... Training Loss 1.096...\n",
      "Step 12070 Training Accuracy 0.766... Training Loss 0.830...\n",
      "Step 12080 Training Accuracy 0.594... Training Loss 1.108...\n",
      "Step 12090 Training Accuracy 0.719... Training Loss 0.989...\n",
      "Step 12100 Training Accuracy 0.688... Training Loss 1.200...\n",
      "Step 12110 Training Accuracy 0.625... Training Loss 1.067...\n",
      "Step 12120 Training Accuracy 0.625... Training Loss 1.248...\n",
      "Step 12130 Training Accuracy 0.688... Training Loss 0.858...\n",
      "Step 12140 Training Accuracy 0.641... Training Loss 1.056...\n",
      "Step 12150 Training Accuracy 0.594... Training Loss 1.299...\n",
      "Step 12160 Training Accuracy 0.750... Training Loss 0.987...\n",
      "Step 12170 Training Accuracy 0.594... Training Loss 1.236...\n",
      "Step 12180 Training Accuracy 0.656... Training Loss 0.920...\n",
      "Step 12190 Training Accuracy 0.656... Training Loss 1.287...\n",
      "Step 12200 Training Accuracy 0.625... Training Loss 1.184...\n",
      "Step 12210 Training Accuracy 0.672... Training Loss 1.128...\n",
      "Step 12220 Training Accuracy 0.656... Training Loss 1.143...\n",
      "Step 12230 Training Accuracy 0.562... Training Loss 1.471...\n",
      "Step 12240 Training Accuracy 0.562... Training Loss 1.596...\n",
      "Step 12250 Training Accuracy 0.672... Training Loss 1.045...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 12260 Training Accuracy 0.703... Training Loss 1.163...\n",
      "Step 12270 Training Accuracy 0.594... Training Loss 1.249...\n",
      "Step 12280 Training Accuracy 0.609... Training Loss 1.099...\n",
      "Step 12290 Training Accuracy 0.703... Training Loss 0.696...\n",
      "Step 12300 Training Accuracy 0.516... Training Loss 1.573...\n",
      "Step 12310 Training Accuracy 0.656... Training Loss 1.325...\n",
      "Step 12320 Training Accuracy 0.703... Training Loss 1.081...\n",
      "Step 12330 Training Accuracy 0.578... Training Loss 1.268...\n",
      "Step 12340 Training Accuracy 0.641... Training Loss 1.195...\n",
      "Step 12350 Training Accuracy 0.750... Training Loss 0.934...\n",
      "Step 12360 Training Accuracy 0.766... Training Loss 0.801...\n",
      "Step 12370 Training Accuracy 0.609... Training Loss 1.003...\n",
      "Step 12380 Training Accuracy 0.672... Training Loss 1.152...\n",
      "Step 12390 Training Accuracy 0.703... Training Loss 1.049...\n",
      "Step 12400 Training Accuracy 0.703... Training Loss 1.098...\n",
      "Step 12410 Training Accuracy 0.656... Training Loss 1.126...\n",
      "Step 12420 Training Accuracy 0.609... Training Loss 1.363...\n",
      "Step 12430 Training Accuracy 0.766... Training Loss 0.775...\n",
      "Step 12440 Training Accuracy 0.734... Training Loss 0.938...\n",
      "Step 12450 Training Accuracy 0.641... Training Loss 1.182...\n",
      "Step 12460 Training Accuracy 0.656... Training Loss 1.096...\n",
      "Step 12470 Training Accuracy 0.688... Training Loss 1.157...\n",
      "Step 12480 Training Accuracy 0.766... Training Loss 0.839...\n",
      "Step 12490 Training Accuracy 0.719... Training Loss 0.800...\n",
      "Step 12500 Training Accuracy 0.656... Training Loss 1.077...\n",
      "Step 12510 Training Accuracy 0.719... Training Loss 0.835...\n",
      "Step 12520 Training Accuracy 0.625... Training Loss 1.230...\n",
      "Step 12530 Training Accuracy 0.703... Training Loss 0.992...\n",
      "Step 12540 Training Accuracy 0.672... Training Loss 1.102...\n",
      "Step 12550 Training Accuracy 0.703... Training Loss 1.094...\n",
      "Step 12560 Training Accuracy 0.688... Training Loss 0.966...\n",
      "Step 12570 Training Accuracy 0.672... Training Loss 1.051...\n",
      "Step 12580 Training Accuracy 0.812... Training Loss 0.741...\n",
      "Step 12590 Training Accuracy 0.656... Training Loss 1.054...\n",
      "Step 12600 Training Accuracy 0.641... Training Loss 1.279...\n",
      "Step 12610 Training Accuracy 0.703... Training Loss 1.034...\n",
      "Step 12620 Training Accuracy 0.641... Training Loss 1.455...\n",
      "Step 12630 Training Accuracy 0.734... Training Loss 1.169...\n",
      "Step 12640 Training Accuracy 0.672... Training Loss 0.860...\n",
      "Step 12650 Training Accuracy 0.734... Training Loss 0.977...\n",
      "Step 12660 Training Accuracy 0.797... Training Loss 0.956...\n",
      "Step 12670 Training Accuracy 0.703... Training Loss 1.177...\n",
      "Step 12680 Training Accuracy 0.734... Training Loss 0.927...\n",
      "Step 12690 Training Accuracy 0.688... Training Loss 1.203...\n",
      "Step 12700 Training Accuracy 0.828... Training Loss 0.757...\n",
      "Step 12710 Training Accuracy 0.672... Training Loss 1.133...\n",
      "Step 12720 Training Accuracy 0.609... Training Loss 1.053...\n",
      "Step 12730 Training Accuracy 0.703... Training Loss 0.800...\n",
      "Step 12740 Training Accuracy 0.672... Training Loss 0.991...\n",
      "Step 12750 Training Accuracy 0.672... Training Loss 1.047...\n",
      "Step 12760 Training Accuracy 0.656... Training Loss 0.738...\n",
      "Step 12770 Training Accuracy 0.688... Training Loss 0.998...\n",
      "Step 12780 Training Accuracy 0.703... Training Loss 0.882...\n",
      "Step 12790 Training Accuracy 0.734... Training Loss 1.198...\n",
      "Step 12800 Training Accuracy 0.797... Training Loss 1.017...\n",
      "Step 12810 Training Accuracy 0.656... Training Loss 1.042...\n",
      "Step 12820 Training Accuracy 0.703... Training Loss 0.955...\n",
      "Step 12830 Training Accuracy 0.844... Training Loss 0.726...\n",
      "Step 12840 Training Accuracy 0.766... Training Loss 0.804...\n",
      "Step 12850 Training Accuracy 0.703... Training Loss 1.024...\n",
      "Step 12860 Training Accuracy 0.656... Training Loss 1.117...\n",
      "Step 12870 Training Accuracy 0.719... Training Loss 0.806...\n",
      "Step 12880 Training Accuracy 0.641... Training Loss 1.004...\n",
      "Step 12890 Training Accuracy 0.703... Training Loss 0.900...\n",
      "Step 12900 Training Accuracy 0.562... Training Loss 1.245...\n",
      "Step 12910 Training Accuracy 0.672... Training Loss 1.069...\n",
      "Step 12920 Training Accuracy 0.625... Training Loss 1.148...\n",
      "Step 12930 Training Accuracy 0.656... Training Loss 1.048...\n",
      "Step 12940 Training Accuracy 0.719... Training Loss 0.750...\n",
      "Step 12950 Training Accuracy 0.703... Training Loss 0.921...\n",
      "Step 12960 Training Accuracy 0.750... Training Loss 0.915...\n",
      "Step 12970 Training Accuracy 0.672... Training Loss 0.907...\n",
      "Step 12980 Training Accuracy 0.734... Training Loss 1.109...\n",
      "Step 12990 Training Accuracy 0.797... Training Loss 0.875...\n",
      "Step 13000 Training Accuracy 0.672... Training Loss 1.078...\n",
      "Writing checkpoint at step 13000\n",
      "Step 13010 Training Accuracy 0.719... Training Loss 0.906...\n",
      "Step 13020 Training Accuracy 0.625... Training Loss 1.129...\n",
      "Step 13030 Training Accuracy 0.703... Training Loss 0.903...\n",
      "Step 13040 Training Accuracy 0.734... Training Loss 1.026...\n",
      "Step 13050 Training Accuracy 0.719... Training Loss 0.955...\n",
      "Step 13060 Training Accuracy 0.781... Training Loss 0.837...\n",
      "Step 13070 Training Accuracy 0.719... Training Loss 1.061...\n",
      "Step 13080 Training Accuracy 0.656... Training Loss 1.248...\n",
      "Step 13090 Training Accuracy 0.672... Training Loss 0.930...\n",
      "Step 13100 Training Accuracy 0.578... Training Loss 1.595...\n",
      "Step 13110 Training Accuracy 0.688... Training Loss 0.922...\n",
      "Step 13120 Training Accuracy 0.766... Training Loss 0.705...\n",
      "Step 13130 Training Accuracy 0.688... Training Loss 1.044...\n",
      "Step 13140 Training Accuracy 0.766... Training Loss 1.023...\n",
      "Step 13150 Training Accuracy 0.750... Training Loss 0.770...\n",
      "Step 13160 Training Accuracy 0.703... Training Loss 1.005...\n",
      "Step 13170 Training Accuracy 0.688... Training Loss 1.069...\n",
      "Step 13180 Training Accuracy 0.656... Training Loss 1.105...\n",
      "Step 13190 Training Accuracy 0.703... Training Loss 0.871...\n",
      "Step 13200 Training Accuracy 0.703... Training Loss 0.950...\n",
      "Step 13210 Training Accuracy 0.688... Training Loss 0.764...\n",
      "Step 13220 Training Accuracy 0.750... Training Loss 0.881...\n",
      "Step 13230 Training Accuracy 0.562... Training Loss 1.057...\n",
      "Step 13240 Training Accuracy 0.578... Training Loss 1.429...\n",
      "Step 13250 Training Accuracy 0.750... Training Loss 0.750...\n",
      "Step 13260 Training Accuracy 0.828... Training Loss 0.635...\n",
      "Step 13270 Training Accuracy 0.641... Training Loss 1.199...\n",
      "Step 13280 Training Accuracy 0.719... Training Loss 0.789...\n",
      "Step 13290 Training Accuracy 0.703... Training Loss 1.104...\n",
      "Step 13300 Training Accuracy 0.719... Training Loss 1.096...\n",
      "Step 13310 Training Accuracy 0.672... Training Loss 1.069...\n",
      "Step 13320 Training Accuracy 0.719... Training Loss 0.872...\n",
      "Step 13330 Training Accuracy 0.641... Training Loss 1.057...\n",
      "Step 13340 Training Accuracy 0.781... Training Loss 0.645...\n",
      "Step 13350 Training Accuracy 0.750... Training Loss 1.009...\n",
      "Step 13360 Training Accuracy 0.703... Training Loss 0.769...\n",
      "Step 13370 Training Accuracy 0.688... Training Loss 1.106...\n",
      "Step 13380 Training Accuracy 0.719... Training Loss 1.083...\n",
      "Step 13390 Training Accuracy 0.578... Training Loss 1.251...\n",
      "Step 13400 Training Accuracy 0.719... Training Loss 0.958...\n",
      "Step 13410 Training Accuracy 0.703... Training Loss 0.818...\n",
      "Step 13420 Training Accuracy 0.781... Training Loss 0.807...\n",
      "Step 13430 Training Accuracy 0.672... Training Loss 0.910...\n",
      "Step 13440 Training Accuracy 0.688... Training Loss 0.999...\n",
      "Step 13450 Training Accuracy 0.750... Training Loss 1.064...\n",
      "Step 13460 Training Accuracy 0.703... Training Loss 0.960...\n",
      "Step 13470 Training Accuracy 0.750... Training Loss 1.000...\n",
      "Step 13480 Training Accuracy 0.672... Training Loss 1.025...\n",
      "Step 13490 Training Accuracy 0.688... Training Loss 0.743...\n",
      "Step 13500 Training Accuracy 0.812... Training Loss 0.504...\n",
      "Step 13510 Training Accuracy 0.703... Training Loss 0.984...\n",
      "Step 13520 Training Accuracy 0.750... Training Loss 0.690...\n",
      "Step 13530 Training Accuracy 0.797... Training Loss 0.603...\n",
      "Step 13540 Training Accuracy 0.688... Training Loss 0.943...\n",
      "Step 13550 Training Accuracy 0.734... Training Loss 1.036...\n",
      "Step 13560 Training Accuracy 0.734... Training Loss 1.142...\n",
      "Step 13570 Training Accuracy 0.672... Training Loss 1.080...\n",
      "Step 13580 Training Accuracy 0.719... Training Loss 0.718...\n",
      "Step 13590 Training Accuracy 0.781... Training Loss 0.790...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 13600 Training Accuracy 0.719... Training Loss 0.773...\n",
      "Step 13610 Training Accuracy 0.781... Training Loss 0.604...\n",
      "Step 13620 Training Accuracy 0.750... Training Loss 0.926...\n",
      "Step 13630 Training Accuracy 0.719... Training Loss 0.943...\n",
      "Step 13640 Training Accuracy 0.750... Training Loss 0.965...\n",
      "Step 13650 Training Accuracy 0.625... Training Loss 1.032...\n",
      "Step 13660 Training Accuracy 0.766... Training Loss 0.812...\n",
      "Step 13670 Training Accuracy 0.656... Training Loss 1.241...\n",
      "Step 13680 Training Accuracy 0.734... Training Loss 0.839...\n",
      "Step 13690 Training Accuracy 0.812... Training Loss 0.708...\n",
      "Step 13700 Training Accuracy 0.750... Training Loss 0.870...\n",
      "Step 13710 Training Accuracy 0.766... Training Loss 0.713...\n",
      "Step 13720 Training Accuracy 0.750... Training Loss 0.730...\n",
      "Step 13730 Training Accuracy 0.641... Training Loss 1.129...\n",
      "Step 13740 Training Accuracy 0.641... Training Loss 0.864...\n",
      "Step 13750 Training Accuracy 0.672... Training Loss 1.170...\n",
      "Step 13760 Training Accuracy 0.828... Training Loss 0.859...\n",
      "Step 13770 Training Accuracy 0.625... Training Loss 1.131...\n",
      "Step 13780 Training Accuracy 0.844... Training Loss 0.580...\n",
      "Step 13790 Training Accuracy 0.672... Training Loss 1.129...\n",
      "Step 13800 Training Accuracy 0.703... Training Loss 1.020...\n",
      "Step 13810 Training Accuracy 0.781... Training Loss 0.953...\n",
      "Step 13820 Training Accuracy 0.750... Training Loss 0.789...\n",
      "Step 13830 Training Accuracy 0.688... Training Loss 1.219...\n",
      "Step 13840 Training Accuracy 0.656... Training Loss 1.244...\n",
      "Step 13850 Training Accuracy 0.688... Training Loss 1.023...\n",
      "Step 13860 Training Accuracy 0.797... Training Loss 0.809...\n",
      "Step 13870 Training Accuracy 0.703... Training Loss 0.779...\n",
      "Step 13880 Training Accuracy 0.750... Training Loss 0.777...\n",
      "Step 13890 Training Accuracy 0.844... Training Loss 0.836...\n",
      "Step 13900 Training Accuracy 0.766... Training Loss 1.037...\n",
      "Step 13910 Training Accuracy 0.688... Training Loss 1.148...\n",
      "Step 13920 Training Accuracy 0.828... Training Loss 0.836...\n",
      "Step 13930 Training Accuracy 0.578... Training Loss 1.158...\n",
      "Step 13940 Training Accuracy 0.688... Training Loss 0.866...\n",
      "Step 13950 Training Accuracy 0.797... Training Loss 0.756...\n",
      "Step 13960 Training Accuracy 0.656... Training Loss 1.089...\n",
      "Step 13970 Training Accuracy 0.766... Training Loss 0.951...\n",
      "Step 13980 Training Accuracy 0.766... Training Loss 0.623...\n",
      "Step 13990 Training Accuracy 0.812... Training Loss 0.703...\n",
      "Step 14000 Training Accuracy 0.750... Training Loss 0.868...\n",
      "Writing checkpoint at step 14000\n",
      "Step 14010 Training Accuracy 0.641... Training Loss 0.987...\n",
      "Step 14020 Training Accuracy 0.734... Training Loss 0.817...\n",
      "Step 14030 Training Accuracy 0.672... Training Loss 0.855...\n",
      "Step 14040 Training Accuracy 0.734... Training Loss 0.855...\n",
      "Step 14050 Training Accuracy 0.719... Training Loss 1.006...\n",
      "Step 14060 Training Accuracy 0.734... Training Loss 0.990...\n",
      "Step 14070 Training Accuracy 0.750... Training Loss 0.820...\n",
      "Step 14080 Training Accuracy 0.766... Training Loss 0.867...\n",
      "Step 14090 Training Accuracy 0.688... Training Loss 1.051...\n",
      "Step 14100 Training Accuracy 0.750... Training Loss 0.864...\n",
      "Step 14110 Training Accuracy 0.703... Training Loss 1.060...\n",
      "Step 14120 Training Accuracy 0.766... Training Loss 0.786...\n",
      "Step 14130 Training Accuracy 0.859... Training Loss 0.567...\n",
      "Step 14140 Training Accuracy 0.812... Training Loss 0.832...\n",
      "Step 14150 Training Accuracy 0.797... Training Loss 0.840...\n",
      "Step 14160 Training Accuracy 0.719... Training Loss 0.886...\n",
      "Step 14170 Training Accuracy 0.703... Training Loss 1.191...\n",
      "Step 14180 Training Accuracy 0.719... Training Loss 1.077...\n",
      "Step 14190 Training Accuracy 0.734... Training Loss 0.730...\n",
      "Step 14200 Training Accuracy 0.781... Training Loss 0.814...\n",
      "Step 14210 Training Accuracy 0.688... Training Loss 1.027...\n",
      "Step 14220 Training Accuracy 0.781... Training Loss 0.670...\n",
      "Step 14230 Training Accuracy 0.750... Training Loss 1.064...\n",
      "Step 14240 Training Accuracy 0.812... Training Loss 0.611...\n",
      "Step 14250 Training Accuracy 0.703... Training Loss 1.047...\n",
      "Step 14260 Training Accuracy 0.750... Training Loss 1.009...\n",
      "Step 14270 Training Accuracy 0.781... Training Loss 0.683...\n",
      "Step 14280 Training Accuracy 0.609... Training Loss 1.087...\n",
      "Step 14290 Training Accuracy 0.828... Training Loss 0.604...\n",
      "Step 14300 Training Accuracy 0.672... Training Loss 1.104...\n",
      "Step 14310 Training Accuracy 0.828... Training Loss 0.545...\n",
      "Step 14320 Training Accuracy 0.781... Training Loss 0.646...\n",
      "Step 14330 Training Accuracy 0.766... Training Loss 0.923...\n",
      "Step 14340 Training Accuracy 0.812... Training Loss 0.718...\n",
      "Step 14350 Training Accuracy 0.719... Training Loss 0.737...\n",
      "Step 14360 Training Accuracy 0.812... Training Loss 0.599...\n",
      "Step 14370 Training Accuracy 0.781... Training Loss 0.878...\n",
      "Step 14380 Training Accuracy 0.719... Training Loss 1.071...\n",
      "Step 14390 Training Accuracy 0.688... Training Loss 0.935...\n",
      "Step 14400 Training Accuracy 0.734... Training Loss 0.821...\n",
      "Step 14410 Training Accuracy 0.781... Training Loss 0.834...\n",
      "Step 14420 Training Accuracy 0.781... Training Loss 0.877...\n",
      "Step 14430 Training Accuracy 0.828... Training Loss 0.596...\n",
      "Step 14440 Training Accuracy 0.719... Training Loss 0.851...\n",
      "Step 14450 Training Accuracy 0.703... Training Loss 0.931...\n",
      "Step 14460 Training Accuracy 0.703... Training Loss 0.974...\n",
      "Step 14470 Training Accuracy 0.750... Training Loss 0.893...\n",
      "Step 14480 Training Accuracy 0.781... Training Loss 0.817...\n",
      "Step 14490 Training Accuracy 0.844... Training Loss 0.582...\n",
      "Step 14500 Training Accuracy 0.766... Training Loss 0.623...\n",
      "Step 14510 Training Accuracy 0.750... Training Loss 0.870...\n",
      "Step 14520 Training Accuracy 0.750... Training Loss 0.633...\n",
      "Step 14530 Training Accuracy 0.844... Training Loss 0.573...\n",
      "Step 14540 Training Accuracy 0.734... Training Loss 0.822...\n",
      "Step 14550 Training Accuracy 0.703... Training Loss 0.917...\n",
      "Step 14560 Training Accuracy 0.797... Training Loss 0.802...\n",
      "Step 14570 Training Accuracy 0.703... Training Loss 0.926...\n",
      "Step 14580 Training Accuracy 0.812... Training Loss 0.607...\n",
      "Step 14590 Training Accuracy 0.766... Training Loss 0.891...\n",
      "Step 14600 Training Accuracy 0.750... Training Loss 1.132...\n",
      "Step 14610 Training Accuracy 0.688... Training Loss 0.718...\n",
      "Step 14620 Training Accuracy 0.734... Training Loss 0.926...\n",
      "Step 14630 Training Accuracy 0.781... Training Loss 0.578...\n",
      "Step 14640 Training Accuracy 0.797... Training Loss 0.683...\n",
      "Step 14650 Training Accuracy 0.656... Training Loss 0.972...\n",
      "Step 14660 Training Accuracy 0.766... Training Loss 0.720...\n",
      "Step 14670 Training Accuracy 0.719... Training Loss 0.722...\n",
      "Step 14680 Training Accuracy 0.703... Training Loss 0.826...\n",
      "Step 14690 Training Accuracy 0.875... Training Loss 0.826...\n",
      "Step 14700 Training Accuracy 0.781... Training Loss 0.807...\n",
      "Step 14710 Training Accuracy 0.719... Training Loss 0.840...\n",
      "Step 14720 Training Accuracy 0.719... Training Loss 0.825...\n",
      "Step 14730 Training Accuracy 0.656... Training Loss 0.956...\n",
      "Step 14740 Training Accuracy 0.625... Training Loss 1.002...\n",
      "Step 14750 Training Accuracy 0.719... Training Loss 0.893...\n",
      "Step 14760 Training Accuracy 0.844... Training Loss 0.547...\n",
      "Step 14770 Training Accuracy 0.766... Training Loss 1.356...\n",
      "Step 14780 Training Accuracy 0.734... Training Loss 0.818...\n",
      "Step 14790 Training Accuracy 0.688... Training Loss 0.805...\n",
      "Step 14800 Training Accuracy 0.828... Training Loss 0.719...\n",
      "Step 14810 Training Accuracy 0.797... Training Loss 0.694...\n",
      "Step 14820 Training Accuracy 0.672... Training Loss 0.891...\n",
      "Step 14830 Training Accuracy 0.734... Training Loss 0.789...\n",
      "Step 14840 Training Accuracy 0.859... Training Loss 0.545...\n",
      "Step 14850 Training Accuracy 0.797... Training Loss 0.538...\n",
      "Step 14860 Training Accuracy 0.766... Training Loss 0.684...\n",
      "Step 14870 Training Accuracy 0.844... Training Loss 0.675...\n",
      "Step 14880 Training Accuracy 0.812... Training Loss 0.709...\n",
      "Step 14890 Training Accuracy 0.844... Training Loss 0.417...\n",
      "Step 14900 Training Accuracy 0.844... Training Loss 0.606...\n",
      "Step 14910 Training Accuracy 0.812... Training Loss 0.618...\n",
      "Step 14920 Training Accuracy 0.688... Training Loss 0.805...\n",
      "Step 14930 Training Accuracy 0.688... Training Loss 1.115...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 14940 Training Accuracy 0.734... Training Loss 0.757...\n",
      "Step 14950 Training Accuracy 0.734... Training Loss 1.046...\n",
      "Step 14960 Training Accuracy 0.750... Training Loss 0.778...\n",
      "Step 14970 Training Accuracy 0.734... Training Loss 0.765...\n",
      "Step 14980 Training Accuracy 0.781... Training Loss 0.744...\n",
      "Step 14990 Training Accuracy 0.797... Training Loss 0.505...\n",
      "Step 15000 Training Accuracy 0.766... Training Loss 0.700...\n",
      "Writing checkpoint at step 15000\n",
      "Step 15010 Training Accuracy 0.766... Training Loss 0.743...\n",
      "Step 15020 Training Accuracy 0.766... Training Loss 0.678...\n",
      "Step 15030 Training Accuracy 0.797... Training Loss 0.539...\n",
      "Step 15040 Training Accuracy 0.766... Training Loss 0.906...\n",
      "Step 15050 Training Accuracy 0.719... Training Loss 0.919...\n",
      "Step 15060 Training Accuracy 0.734... Training Loss 1.008...\n",
      "Step 15070 Training Accuracy 0.766... Training Loss 0.835...\n",
      "Step 15080 Training Accuracy 0.750... Training Loss 0.861...\n",
      "Step 15090 Training Accuracy 0.609... Training Loss 1.082...\n",
      "Step 15100 Training Accuracy 0.875... Training Loss 0.600...\n",
      "Step 15110 Training Accuracy 0.750... Training Loss 0.867...\n",
      "Step 15120 Training Accuracy 0.828... Training Loss 0.882...\n",
      "Step 15130 Training Accuracy 0.688... Training Loss 1.106...\n",
      "Step 15140 Training Accuracy 0.812... Training Loss 0.618...\n",
      "Step 15150 Training Accuracy 0.781... Training Loss 0.669...\n",
      "Step 15160 Training Accuracy 0.812... Training Loss 0.563...\n",
      "Step 15170 Training Accuracy 0.750... Training Loss 0.851...\n",
      "Step 15180 Training Accuracy 0.688... Training Loss 1.063...\n",
      "Step 15190 Training Accuracy 0.844... Training Loss 0.535...\n",
      "Step 15200 Training Accuracy 0.688... Training Loss 0.879...\n",
      "Step 15210 Training Accuracy 0.875... Training Loss 0.428...\n",
      "Step 15220 Training Accuracy 0.750... Training Loss 0.886...\n",
      "Step 15230 Training Accuracy 0.750... Training Loss 0.594...\n",
      "Step 15240 Training Accuracy 0.766... Training Loss 0.737...\n",
      "Step 15250 Training Accuracy 0.719... Training Loss 0.741...\n",
      "Step 15260 Training Accuracy 0.734... Training Loss 0.725...\n",
      "Step 15270 Training Accuracy 0.750... Training Loss 0.779...\n",
      "Step 15280 Training Accuracy 0.781... Training Loss 0.709...\n",
      "Step 15290 Training Accuracy 0.766... Training Loss 0.964...\n",
      "Step 15300 Training Accuracy 0.797... Training Loss 0.720...\n",
      "Step 15310 Training Accuracy 0.781... Training Loss 0.975...\n",
      "Step 15320 Training Accuracy 0.812... Training Loss 0.565...\n",
      "Step 15330 Training Accuracy 0.719... Training Loss 0.869...\n",
      "Step 15340 Training Accuracy 0.781... Training Loss 0.759...\n",
      "Step 15350 Training Accuracy 0.797... Training Loss 0.879...\n",
      "Step 15360 Training Accuracy 0.703... Training Loss 0.974...\n",
      "Step 15370 Training Accuracy 0.797... Training Loss 0.655...\n",
      "Step 15380 Training Accuracy 0.734... Training Loss 0.781...\n",
      "Step 15390 Training Accuracy 0.875... Training Loss 0.467...\n",
      "Step 15400 Training Accuracy 0.750... Training Loss 0.816...\n",
      "Step 15410 Training Accuracy 0.688... Training Loss 1.053...\n",
      "Step 15420 Training Accuracy 0.703... Training Loss 1.023...\n",
      "Step 15430 Training Accuracy 0.719... Training Loss 1.041...\n",
      "Step 15440 Training Accuracy 0.781... Training Loss 0.710...\n",
      "Step 15450 Training Accuracy 0.688... Training Loss 1.088...\n",
      "Step 15460 Training Accuracy 0.844... Training Loss 0.498...\n",
      "Step 15470 Training Accuracy 0.750... Training Loss 0.782...\n",
      "Step 15480 Training Accuracy 0.781... Training Loss 0.749...\n",
      "Step 15490 Training Accuracy 0.766... Training Loss 0.590...\n",
      "Step 15500 Training Accuracy 0.828... Training Loss 0.721...\n",
      "Step 15510 Training Accuracy 0.719... Training Loss 0.777...\n",
      "Step 15520 Training Accuracy 0.797... Training Loss 0.803...\n",
      "Step 15530 Training Accuracy 0.766... Training Loss 0.815...\n",
      "Step 15540 Training Accuracy 0.781... Training Loss 0.694...\n",
      "Step 15550 Training Accuracy 0.781... Training Loss 0.825...\n",
      "Step 15560 Training Accuracy 0.828... Training Loss 0.451...\n",
      "Step 15570 Training Accuracy 0.797... Training Loss 0.595...\n",
      "Step 15580 Training Accuracy 0.797... Training Loss 0.617...\n",
      "Step 15590 Training Accuracy 0.797... Training Loss 0.720...\n",
      "Step 15600 Training Accuracy 0.734... Training Loss 0.921...\n",
      "Step 15610 Training Accuracy 0.781... Training Loss 0.787...\n",
      "Step 15620 Training Accuracy 0.766... Training Loss 0.865...\n",
      "Step 15630 Training Accuracy 0.844... Training Loss 0.366...\n",
      "Step 15640 Training Accuracy 0.766... Training Loss 0.853...\n",
      "Step 15650 Training Accuracy 0.828... Training Loss 0.582...\n",
      "Step 15660 Training Accuracy 0.703... Training Loss 0.843...\n",
      "Step 15670 Training Accuracy 0.797... Training Loss 0.662...\n",
      "Step 15680 Training Accuracy 0.891... Training Loss 0.304...\n",
      "Step 15690 Training Accuracy 0.797... Training Loss 0.501...\n",
      "Step 15700 Training Accuracy 0.766... Training Loss 0.752...\n",
      "Step 15710 Training Accuracy 0.750... Training Loss 0.696...\n",
      "Step 15720 Training Accuracy 0.797... Training Loss 0.695...\n",
      "Step 15730 Training Accuracy 0.641... Training Loss 0.969...\n",
      "Step 15740 Training Accuracy 0.781... Training Loss 0.572...\n",
      "Step 15750 Training Accuracy 0.781... Training Loss 0.648...\n",
      "Step 15760 Training Accuracy 0.688... Training Loss 1.207...\n",
      "Step 15770 Training Accuracy 0.766... Training Loss 0.603...\n",
      "Step 15780 Training Accuracy 0.672... Training Loss 1.039...\n",
      "Step 15790 Training Accuracy 0.766... Training Loss 0.750...\n",
      "Step 15800 Training Accuracy 0.625... Training Loss 1.098...\n",
      "Step 15810 Training Accuracy 0.844... Training Loss 0.691...\n",
      "Step 15820 Training Accuracy 0.734... Training Loss 0.809...\n",
      "Step 15830 Training Accuracy 0.734... Training Loss 0.781...\n",
      "Step 15840 Training Accuracy 0.797... Training Loss 0.642...\n",
      "Step 15850 Training Accuracy 0.859... Training Loss 0.532...\n",
      "Step 15860 Training Accuracy 0.766... Training Loss 0.649...\n",
      "Step 15870 Training Accuracy 0.719... Training Loss 0.814...\n",
      "Step 15880 Training Accuracy 0.719... Training Loss 0.767...\n",
      "Step 15890 Training Accuracy 0.750... Training Loss 0.980...\n",
      "Step 15900 Training Accuracy 0.766... Training Loss 0.774...\n",
      "Step 15910 Training Accuracy 0.766... Training Loss 0.763...\n",
      "Step 15920 Training Accuracy 0.812... Training Loss 0.816...\n",
      "Step 15930 Training Accuracy 0.719... Training Loss 0.960...\n",
      "Step 15940 Training Accuracy 0.703... Training Loss 0.907...\n",
      "Step 15950 Training Accuracy 0.719... Training Loss 0.942...\n",
      "Step 15960 Training Accuracy 0.828... Training Loss 0.639...\n",
      "Step 15970 Training Accuracy 0.719... Training Loss 0.850...\n",
      "Step 15980 Training Accuracy 0.828... Training Loss 0.619...\n",
      "Step 15990 Training Accuracy 0.812... Training Loss 0.599...\n",
      "Step 16000 Training Accuracy 0.922... Training Loss 0.346...\n",
      "Writing checkpoint at step 16000\n",
      "Step 16010 Training Accuracy 0.719... Training Loss 0.974...\n",
      "Step 16020 Training Accuracy 0.688... Training Loss 0.828...\n",
      "Step 16030 Training Accuracy 0.844... Training Loss 0.551...\n",
      "Step 16040 Training Accuracy 0.812... Training Loss 0.548...\n",
      "Step 16050 Training Accuracy 0.844... Training Loss 0.581...\n",
      "Step 16060 Training Accuracy 0.828... Training Loss 0.700...\n",
      "Step 16070 Training Accuracy 0.797... Training Loss 0.652...\n",
      "Step 16080 Training Accuracy 0.734... Training Loss 1.114...\n",
      "Step 16090 Training Accuracy 0.734... Training Loss 0.672...\n",
      "Step 16100 Training Accuracy 0.750... Training Loss 0.834...\n",
      "Step 16110 Training Accuracy 0.703... Training Loss 0.965...\n",
      "Step 16120 Training Accuracy 0.719... Training Loss 1.069...\n",
      "Step 16130 Training Accuracy 0.781... Training Loss 0.814...\n",
      "Step 16140 Training Accuracy 0.719... Training Loss 0.668...\n",
      "Step 16150 Training Accuracy 0.719... Training Loss 0.849...\n",
      "Step 16160 Training Accuracy 0.797... Training Loss 0.582...\n",
      "Step 16170 Training Accuracy 0.766... Training Loss 0.693...\n",
      "Step 16180 Training Accuracy 0.766... Training Loss 0.700...\n",
      "Step 16190 Training Accuracy 0.781... Training Loss 0.699...\n",
      "Step 16200 Training Accuracy 0.781... Training Loss 0.776...\n",
      "Step 16210 Training Accuracy 0.750... Training Loss 0.957...\n",
      "Step 16220 Training Accuracy 0.781... Training Loss 0.589...\n",
      "Step 16230 Training Accuracy 0.891... Training Loss 0.554...\n",
      "Step 16240 Training Accuracy 0.844... Training Loss 0.476...\n",
      "Step 16250 Training Accuracy 0.875... Training Loss 0.389...\n",
      "Step 16260 Training Accuracy 0.875... Training Loss 0.495...\n",
      "Step 16270 Training Accuracy 0.781... Training Loss 0.699...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 16280 Training Accuracy 0.812... Training Loss 0.562...\n",
      "Step 16290 Training Accuracy 0.859... Training Loss 0.437...\n",
      "Step 16300 Training Accuracy 0.797... Training Loss 0.802...\n",
      "Step 16310 Training Accuracy 0.812... Training Loss 0.489...\n",
      "Step 16320 Training Accuracy 0.797... Training Loss 0.762...\n",
      "Step 16330 Training Accuracy 0.781... Training Loss 0.738...\n",
      "Step 16340 Training Accuracy 0.781... Training Loss 0.661...\n",
      "Step 16350 Training Accuracy 0.781... Training Loss 0.630...\n",
      "Step 16360 Training Accuracy 0.766... Training Loss 0.810...\n",
      "Step 16370 Training Accuracy 0.812... Training Loss 0.574...\n",
      "Step 16380 Training Accuracy 0.812... Training Loss 0.614...\n",
      "Step 16390 Training Accuracy 0.750... Training Loss 0.766...\n",
      "Step 16400 Training Accuracy 0.688... Training Loss 1.081...\n",
      "Step 16410 Training Accuracy 0.719... Training Loss 1.068...\n",
      "Step 16420 Training Accuracy 0.750... Training Loss 0.641...\n",
      "Step 16430 Training Accuracy 0.719... Training Loss 0.961...\n",
      "Step 16440 Training Accuracy 0.766... Training Loss 0.755...\n",
      "Step 16450 Training Accuracy 0.844... Training Loss 0.661...\n",
      "Step 16460 Training Accuracy 0.797... Training Loss 0.701...\n",
      "Step 16470 Training Accuracy 0.844... Training Loss 0.574...\n",
      "Step 16480 Training Accuracy 0.781... Training Loss 0.955...\n",
      "Step 16490 Training Accuracy 0.766... Training Loss 0.912...\n",
      "Step 16500 Training Accuracy 0.844... Training Loss 0.730...\n",
      "Step 16510 Training Accuracy 0.719... Training Loss 0.902...\n",
      "Step 16520 Training Accuracy 0.750... Training Loss 0.611...\n",
      "Step 16530 Training Accuracy 0.797... Training Loss 0.729...\n",
      "Step 16540 Training Accuracy 0.781... Training Loss 0.633...\n",
      "Step 16550 Training Accuracy 0.688... Training Loss 0.820...\n",
      "Step 16560 Training Accuracy 0.828... Training Loss 0.578...\n",
      "Step 16570 Training Accuracy 0.703... Training Loss 0.741...\n",
      "Step 16580 Training Accuracy 0.844... Training Loss 0.458...\n",
      "Step 16590 Training Accuracy 0.844... Training Loss 0.439...\n",
      "Step 16600 Training Accuracy 0.781... Training Loss 0.674...\n",
      "Step 16610 Training Accuracy 0.812... Training Loss 0.561...\n",
      "Step 16620 Training Accuracy 0.781... Training Loss 0.883...\n",
      "Step 16630 Training Accuracy 0.812... Training Loss 0.612...\n",
      "Step 16640 Training Accuracy 0.766... Training Loss 0.777...\n",
      "Step 16650 Training Accuracy 0.750... Training Loss 0.794...\n",
      "Step 16660 Training Accuracy 0.781... Training Loss 0.625...\n",
      "Step 16670 Training Accuracy 0.859... Training Loss 0.481...\n",
      "Step 16680 Training Accuracy 0.797... Training Loss 0.705...\n",
      "Step 16690 Training Accuracy 0.828... Training Loss 0.645...\n",
      "Step 16700 Training Accuracy 0.781... Training Loss 0.715...\n",
      "Step 16710 Training Accuracy 0.844... Training Loss 0.535...\n",
      "Step 16720 Training Accuracy 0.812... Training Loss 0.558...\n",
      "Step 16730 Training Accuracy 0.891... Training Loss 0.496...\n",
      "Step 16740 Training Accuracy 0.859... Training Loss 0.607...\n",
      "Step 16750 Training Accuracy 0.688... Training Loss 1.131...\n",
      "Step 16760 Training Accuracy 0.797... Training Loss 0.567...\n",
      "Step 16770 Training Accuracy 0.875... Training Loss 0.535...\n",
      "Step 16780 Training Accuracy 0.797... Training Loss 0.621...\n",
      "Step 16790 Training Accuracy 0.781... Training Loss 0.680...\n",
      "Step 16800 Training Accuracy 0.812... Training Loss 0.583...\n",
      "Step 16810 Training Accuracy 0.797... Training Loss 0.646...\n",
      "Step 16820 Training Accuracy 0.797... Training Loss 0.593...\n",
      "Step 16830 Training Accuracy 0.672... Training Loss 0.818...\n",
      "Step 16840 Training Accuracy 0.781... Training Loss 0.768...\n",
      "Step 16850 Training Accuracy 0.781... Training Loss 0.724...\n",
      "Step 16860 Training Accuracy 0.797... Training Loss 0.636...\n",
      "Step 16870 Training Accuracy 0.750... Training Loss 0.895...\n",
      "Step 16880 Training Accuracy 0.859... Training Loss 0.576...\n",
      "Step 16890 Training Accuracy 0.859... Training Loss 0.434...\n",
      "Step 16900 Training Accuracy 0.719... Training Loss 0.709...\n",
      "Step 16910 Training Accuracy 0.828... Training Loss 0.621...\n",
      "Step 16920 Training Accuracy 0.688... Training Loss 0.963...\n",
      "Step 16930 Training Accuracy 0.859... Training Loss 0.386...\n",
      "Step 16940 Training Accuracy 0.781... Training Loss 0.647...\n",
      "Step 16950 Training Accuracy 0.875... Training Loss 0.387...\n",
      "Step 16960 Training Accuracy 0.812... Training Loss 0.502...\n",
      "Step 16970 Training Accuracy 0.859... Training Loss 0.452...\n",
      "Step 16980 Training Accuracy 0.797... Training Loss 0.493...\n",
      "Step 16990 Training Accuracy 0.828... Training Loss 0.541...\n",
      "Step 17000 Training Accuracy 0.750... Training Loss 0.648...\n",
      "Writing checkpoint at step 17000\n",
      "Step 17010 Training Accuracy 0.859... Training Loss 0.512...\n",
      "Step 17020 Training Accuracy 0.781... Training Loss 0.669...\n",
      "Step 17030 Training Accuracy 0.781... Training Loss 0.587...\n",
      "Step 17040 Training Accuracy 0.844... Training Loss 0.486...\n",
      "Step 17050 Training Accuracy 0.719... Training Loss 0.775...\n",
      "Step 17060 Training Accuracy 0.828... Training Loss 0.572...\n",
      "Step 17070 Training Accuracy 0.875... Training Loss 0.411...\n",
      "Step 17080 Training Accuracy 0.797... Training Loss 0.634...\n",
      "Step 17090 Training Accuracy 0.781... Training Loss 0.637...\n",
      "Step 17100 Training Accuracy 0.859... Training Loss 0.614...\n",
      "Step 17110 Training Accuracy 0.797... Training Loss 0.582...\n",
      "Step 17120 Training Accuracy 0.812... Training Loss 0.488...\n",
      "Step 17130 Training Accuracy 0.812... Training Loss 0.608...\n",
      "Step 17140 Training Accuracy 0.797... Training Loss 0.597...\n",
      "Step 17150 Training Accuracy 0.859... Training Loss 0.619...\n",
      "Step 17160 Training Accuracy 0.812... Training Loss 0.808...\n",
      "Step 17170 Training Accuracy 0.859... Training Loss 0.438...\n",
      "Step 17180 Training Accuracy 0.766... Training Loss 0.499...\n",
      "Step 17190 Training Accuracy 0.719... Training Loss 1.050...\n",
      "Step 17200 Training Accuracy 0.781... Training Loss 0.980...\n",
      "Step 17210 Training Accuracy 0.797... Training Loss 0.645...\n",
      "Step 17220 Training Accuracy 0.703... Training Loss 0.753...\n",
      "Step 17230 Training Accuracy 0.781... Training Loss 0.506...\n",
      "Step 17240 Training Accuracy 0.828... Training Loss 0.490...\n",
      "Step 17250 Training Accuracy 0.781... Training Loss 0.715...\n",
      "Step 17260 Training Accuracy 0.750... Training Loss 0.530...\n",
      "Step 17270 Training Accuracy 0.812... Training Loss 0.608...\n",
      "Step 17280 Training Accuracy 0.750... Training Loss 0.731...\n",
      "Step 17290 Training Accuracy 0.797... Training Loss 0.596...\n",
      "Step 17300 Training Accuracy 0.781... Training Loss 0.649...\n",
      "Step 17310 Training Accuracy 0.844... Training Loss 0.697...\n",
      "Step 17320 Training Accuracy 0.906... Training Loss 0.472...\n",
      "Step 17330 Training Accuracy 0.844... Training Loss 0.728...\n",
      "Step 17340 Training Accuracy 0.828... Training Loss 0.689...\n",
      "Step 17350 Training Accuracy 0.844... Training Loss 0.496...\n",
      "Step 17360 Training Accuracy 0.797... Training Loss 0.752...\n",
      "Step 17370 Training Accuracy 0.859... Training Loss 0.715...\n",
      "Step 17380 Training Accuracy 0.562... Training Loss 1.075...\n",
      "Step 17390 Training Accuracy 0.766... Training Loss 0.779...\n",
      "Step 17400 Training Accuracy 0.812... Training Loss 0.702...\n",
      "Step 17410 Training Accuracy 0.781... Training Loss 0.701...\n",
      "Step 17420 Training Accuracy 0.812... Training Loss 0.476...\n",
      "Step 17430 Training Accuracy 0.750... Training Loss 0.752...\n",
      "Step 17440 Training Accuracy 0.781... Training Loss 0.553...\n",
      "Step 17450 Training Accuracy 0.844... Training Loss 0.672...\n",
      "Step 17460 Training Accuracy 0.844... Training Loss 0.549...\n",
      "Step 17470 Training Accuracy 0.812... Training Loss 0.554...\n",
      "Step 17480 Training Accuracy 0.781... Training Loss 0.690...\n",
      "Step 17490 Training Accuracy 0.828... Training Loss 0.642...\n",
      "Step 17500 Training Accuracy 0.766... Training Loss 0.542...\n",
      "Step 17510 Training Accuracy 0.766... Training Loss 0.713...\n",
      "Step 17520 Training Accuracy 0.797... Training Loss 0.465...\n",
      "Step 17530 Training Accuracy 0.891... Training Loss 0.465...\n",
      "Step 17540 Training Accuracy 0.672... Training Loss 0.934...\n",
      "Step 17550 Training Accuracy 0.875... Training Loss 0.469...\n",
      "Step 17560 Training Accuracy 0.797... Training Loss 0.634...\n",
      "Step 17570 Training Accuracy 0.844... Training Loss 0.679...\n",
      "Step 17580 Training Accuracy 0.906... Training Loss 0.429...\n",
      "Step 17590 Training Accuracy 0.797... Training Loss 0.649...\n",
      "Step 17600 Training Accuracy 0.781... Training Loss 0.666...\n",
      "Step 17610 Training Accuracy 0.828... Training Loss 0.477...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 17620 Training Accuracy 0.812... Training Loss 0.648...\n",
      "Step 17630 Training Accuracy 0.766... Training Loss 0.526...\n",
      "Step 17640 Training Accuracy 0.781... Training Loss 0.674...\n",
      "Step 17650 Training Accuracy 0.844... Training Loss 0.746...\n",
      "Step 17660 Training Accuracy 0.828... Training Loss 0.737...\n",
      "Step 17670 Training Accuracy 0.781... Training Loss 0.639...\n",
      "Step 17680 Training Accuracy 0.812... Training Loss 0.729...\n",
      "Step 17690 Training Accuracy 0.797... Training Loss 0.686...\n",
      "Step 17700 Training Accuracy 0.859... Training Loss 0.421...\n",
      "Step 17710 Training Accuracy 0.812... Training Loss 0.616...\n",
      "Step 17720 Training Accuracy 0.844... Training Loss 0.604...\n",
      "Step 17730 Training Accuracy 0.828... Training Loss 0.648...\n",
      "Step 17740 Training Accuracy 0.734... Training Loss 0.672...\n",
      "Step 17750 Training Accuracy 0.844... Training Loss 0.486...\n",
      "Step 17760 Training Accuracy 0.859... Training Loss 0.443...\n",
      "Step 17770 Training Accuracy 0.812... Training Loss 0.760...\n",
      "Step 17780 Training Accuracy 0.719... Training Loss 0.931...\n",
      "Step 17790 Training Accuracy 0.844... Training Loss 0.571...\n",
      "Step 17800 Training Accuracy 0.828... Training Loss 0.719...\n",
      "Step 17810 Training Accuracy 0.766... Training Loss 0.673...\n",
      "Step 17820 Training Accuracy 0.812... Training Loss 0.685...\n",
      "Step 17830 Training Accuracy 0.891... Training Loss 0.646...\n",
      "Step 17840 Training Accuracy 0.922... Training Loss 0.329...\n",
      "Step 17850 Training Accuracy 0.734... Training Loss 0.614...\n",
      "Step 17860 Training Accuracy 0.781... Training Loss 0.691...\n",
      "Step 17870 Training Accuracy 0.781... Training Loss 0.819...\n",
      "Step 17880 Training Accuracy 0.812... Training Loss 0.477...\n",
      "Step 17890 Training Accuracy 0.812... Training Loss 0.589...\n",
      "Step 17900 Training Accuracy 0.797... Training Loss 0.595...\n",
      "Step 17910 Training Accuracy 0.781... Training Loss 0.786...\n",
      "Step 17920 Training Accuracy 0.797... Training Loss 0.687...\n",
      "Step 17930 Training Accuracy 0.781... Training Loss 0.926...\n",
      "Step 17940 Training Accuracy 0.812... Training Loss 0.657...\n",
      "Step 17950 Training Accuracy 0.859... Training Loss 0.461...\n",
      "Step 17960 Training Accuracy 0.812... Training Loss 0.479...\n",
      "Step 17970 Training Accuracy 0.891... Training Loss 0.497...\n",
      "Step 17980 Training Accuracy 0.734... Training Loss 0.887...\n",
      "Step 17990 Training Accuracy 0.875... Training Loss 0.466...\n",
      "Step 18000 Training Accuracy 0.859... Training Loss 0.448...\n",
      "Writing checkpoint at step 18000\n",
      "Step 18010 Training Accuracy 0.828... Training Loss 0.693...\n",
      "Step 18020 Training Accuracy 0.891... Training Loss 0.442...\n",
      "Step 18030 Training Accuracy 0.703... Training Loss 0.766...\n",
      "Step 18040 Training Accuracy 0.812... Training Loss 0.544...\n",
      "Step 18050 Training Accuracy 0.891... Training Loss 0.539...\n",
      "Step 18060 Training Accuracy 0.828... Training Loss 0.575...\n",
      "Step 18070 Training Accuracy 0.891... Training Loss 0.382...\n",
      "Step 18080 Training Accuracy 0.828... Training Loss 0.550...\n",
      "Step 18090 Training Accuracy 0.812... Training Loss 0.625...\n",
      "Step 18100 Training Accuracy 0.844... Training Loss 0.586...\n",
      "Step 18110 Training Accuracy 0.734... Training Loss 0.839...\n",
      "Step 18120 Training Accuracy 0.797... Training Loss 1.008...\n",
      "Step 18130 Training Accuracy 0.844... Training Loss 0.467...\n",
      "Step 18140 Training Accuracy 0.812... Training Loss 0.760...\n",
      "Step 18150 Training Accuracy 0.812... Training Loss 0.602...\n",
      "Step 18160 Training Accuracy 0.828... Training Loss 0.440...\n",
      "Step 18170 Training Accuracy 0.781... Training Loss 0.844...\n",
      "Step 18180 Training Accuracy 0.828... Training Loss 0.620...\n",
      "Step 18190 Training Accuracy 0.859... Training Loss 0.417...\n",
      "Step 18200 Training Accuracy 0.891... Training Loss 0.351...\n",
      "Step 18210 Training Accuracy 0.844... Training Loss 0.651...\n",
      "Step 18220 Training Accuracy 0.859... Training Loss 0.406...\n",
      "Step 18230 Training Accuracy 0.875... Training Loss 0.358...\n",
      "Step 18240 Training Accuracy 0.875... Training Loss 0.388...\n",
      "Step 18250 Training Accuracy 0.875... Training Loss 0.428...\n",
      "Step 18260 Training Accuracy 0.875... Training Loss 0.606...\n",
      "Step 18270 Training Accuracy 0.750... Training Loss 0.776...\n",
      "Step 18280 Training Accuracy 0.859... Training Loss 0.626...\n",
      "Step 18290 Training Accuracy 0.797... Training Loss 0.719...\n",
      "Step 18300 Training Accuracy 0.828... Training Loss 0.533...\n",
      "Step 18310 Training Accuracy 0.828... Training Loss 0.479...\n",
      "Step 18320 Training Accuracy 0.891... Training Loss 0.342...\n",
      "Step 18330 Training Accuracy 0.766... Training Loss 0.798...\n",
      "Step 18340 Training Accuracy 0.875... Training Loss 0.466...\n",
      "Step 18350 Training Accuracy 0.922... Training Loss 0.373...\n",
      "Step 18360 Training Accuracy 0.875... Training Loss 0.493...\n",
      "Step 18370 Training Accuracy 0.875... Training Loss 0.286...\n",
      "Step 18380 Training Accuracy 0.672... Training Loss 1.004...\n",
      "Step 18390 Training Accuracy 0.859... Training Loss 0.456...\n",
      "Step 18400 Training Accuracy 0.891... Training Loss 0.370...\n",
      "Step 18410 Training Accuracy 0.875... Training Loss 0.352...\n",
      "Step 18420 Training Accuracy 0.828... Training Loss 0.555...\n",
      "Step 18430 Training Accuracy 0.844... Training Loss 0.425...\n",
      "Step 18440 Training Accuracy 0.828... Training Loss 0.570...\n",
      "Step 18450 Training Accuracy 0.859... Training Loss 0.498...\n",
      "Step 18460 Training Accuracy 0.766... Training Loss 0.573...\n",
      "Step 18470 Training Accuracy 0.781... Training Loss 0.540...\n",
      "Step 18480 Training Accuracy 0.906... Training Loss 0.384...\n",
      "Step 18490 Training Accuracy 0.828... Training Loss 0.542...\n",
      "Step 18500 Training Accuracy 0.766... Training Loss 0.786...\n",
      "Step 18510 Training Accuracy 0.891... Training Loss 0.474...\n",
      "Step 18520 Training Accuracy 0.828... Training Loss 0.583...\n",
      "Step 18530 Training Accuracy 0.859... Training Loss 0.354...\n",
      "Step 18540 Training Accuracy 0.859... Training Loss 0.563...\n",
      "Step 18550 Training Accuracy 0.828... Training Loss 0.465...\n",
      "Step 18560 Training Accuracy 0.859... Training Loss 0.487...\n",
      "Step 18570 Training Accuracy 0.812... Training Loss 0.505...\n",
      "Step 18580 Training Accuracy 0.859... Training Loss 0.396...\n",
      "Step 18590 Training Accuracy 0.828... Training Loss 0.547...\n",
      "Step 18600 Training Accuracy 0.703... Training Loss 0.817...\n",
      "Step 18610 Training Accuracy 0.719... Training Loss 0.863...\n",
      "Step 18620 Training Accuracy 0.797... Training Loss 0.364...\n",
      "Step 18630 Training Accuracy 0.844... Training Loss 0.530...\n",
      "Step 18640 Training Accuracy 0.844... Training Loss 0.647...\n",
      "Step 18650 Training Accuracy 0.859... Training Loss 0.342...\n",
      "Step 18660 Training Accuracy 0.875... Training Loss 0.454...\n",
      "Step 18670 Training Accuracy 0.875... Training Loss 0.364...\n",
      "Step 18680 Training Accuracy 0.797... Training Loss 0.654...\n",
      "Step 18690 Training Accuracy 0.781... Training Loss 0.589...\n",
      "Step 18700 Training Accuracy 0.750... Training Loss 0.795...\n",
      "Step 18710 Training Accuracy 0.906... Training Loss 0.367...\n",
      "Step 18720 Training Accuracy 0.828... Training Loss 0.562...\n",
      "Step 18730 Training Accuracy 0.750... Training Loss 0.709...\n",
      "Step 18740 Training Accuracy 0.906... Training Loss 0.389...\n",
      "Step 18750 Training Accuracy 0.828... Training Loss 0.642...\n",
      "Step 18760 Training Accuracy 0.766... Training Loss 0.923...\n",
      "Step 18770 Training Accuracy 0.812... Training Loss 0.485...\n",
      "Step 18780 Training Accuracy 0.797... Training Loss 0.580...\n",
      "Step 18790 Training Accuracy 0.844... Training Loss 0.444...\n",
      "Step 18800 Training Accuracy 0.797... Training Loss 0.721...\n",
      "Step 18810 Training Accuracy 0.891... Training Loss 0.323...\n",
      "Step 18820 Training Accuracy 0.906... Training Loss 0.393...\n",
      "Step 18830 Training Accuracy 0.812... Training Loss 0.608...\n",
      "Step 18840 Training Accuracy 0.781... Training Loss 0.631...\n",
      "Step 18850 Training Accuracy 0.797... Training Loss 0.536...\n",
      "Step 18860 Training Accuracy 0.828... Training Loss 0.740...\n",
      "Step 18870 Training Accuracy 0.891... Training Loss 0.532...\n",
      "Step 18880 Training Accuracy 0.828... Training Loss 0.305...\n",
      "Step 18890 Training Accuracy 0.844... Training Loss 0.486...\n",
      "Step 18900 Training Accuracy 0.828... Training Loss 0.488...\n",
      "Step 18910 Training Accuracy 0.719... Training Loss 0.870...\n",
      "Step 18920 Training Accuracy 0.891... Training Loss 0.339...\n",
      "Step 18930 Training Accuracy 0.875... Training Loss 0.409...\n",
      "Step 18940 Training Accuracy 0.688... Training Loss 0.774...\n",
      "Step 18950 Training Accuracy 0.844... Training Loss 0.444...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 18960 Training Accuracy 0.859... Training Loss 0.405...\n",
      "Step 18970 Training Accuracy 0.797... Training Loss 0.598...\n",
      "Step 18980 Training Accuracy 0.812... Training Loss 0.570...\n",
      "Step 18990 Training Accuracy 0.781... Training Loss 0.512...\n",
      "Step 19000 Training Accuracy 0.734... Training Loss 0.682...\n",
      "Writing checkpoint at step 19000\n",
      "Step 19010 Training Accuracy 0.891... Training Loss 0.341...\n",
      "Step 19020 Training Accuracy 0.828... Training Loss 0.575...\n",
      "Step 19030 Training Accuracy 0.812... Training Loss 0.477...\n",
      "Step 19040 Training Accuracy 0.812... Training Loss 0.494...\n",
      "Step 19050 Training Accuracy 0.859... Training Loss 0.686...\n",
      "Step 19060 Training Accuracy 0.844... Training Loss 0.576...\n",
      "Step 19070 Training Accuracy 0.719... Training Loss 0.734...\n",
      "Step 19080 Training Accuracy 0.781... Training Loss 0.717...\n",
      "Step 19090 Training Accuracy 0.828... Training Loss 0.650...\n",
      "Step 19100 Training Accuracy 0.781... Training Loss 0.624...\n",
      "Step 19110 Training Accuracy 0.844... Training Loss 0.509...\n",
      "Step 19120 Training Accuracy 0.859... Training Loss 0.637...\n",
      "Step 19130 Training Accuracy 0.875... Training Loss 0.329...\n",
      "Step 19140 Training Accuracy 0.797... Training Loss 0.685...\n",
      "Step 19150 Training Accuracy 0.781... Training Loss 0.655...\n",
      "Step 19160 Training Accuracy 0.859... Training Loss 0.509...\n",
      "Step 19170 Training Accuracy 0.750... Training Loss 0.618...\n",
      "Step 19180 Training Accuracy 0.938... Training Loss 0.358...\n",
      "Step 19190 Training Accuracy 0.844... Training Loss 0.564...\n",
      "Step 19200 Training Accuracy 0.875... Training Loss 0.383...\n",
      "Step 19210 Training Accuracy 0.844... Training Loss 0.439...\n",
      "Step 19220 Training Accuracy 0.859... Training Loss 0.538...\n",
      "Step 19230 Training Accuracy 0.766... Training Loss 0.628...\n",
      "Step 19240 Training Accuracy 0.828... Training Loss 0.550...\n",
      "Step 19250 Training Accuracy 0.781... Training Loss 0.669...\n",
      "Step 19260 Training Accuracy 0.828... Training Loss 0.674...\n",
      "Step 19270 Training Accuracy 0.812... Training Loss 0.408...\n",
      "Step 19280 Training Accuracy 0.812... Training Loss 0.635...\n",
      "Step 19290 Training Accuracy 0.797... Training Loss 0.554...\n",
      "Step 19300 Training Accuracy 0.812... Training Loss 0.794...\n",
      "Step 19310 Training Accuracy 0.750... Training Loss 0.575...\n",
      "Step 19320 Training Accuracy 0.875... Training Loss 0.419...\n",
      "Step 19330 Training Accuracy 0.844... Training Loss 0.333...\n",
      "Step 19340 Training Accuracy 0.906... Training Loss 0.248...\n",
      "Step 19350 Training Accuracy 0.828... Training Loss 0.551...\n",
      "Step 19360 Training Accuracy 0.875... Training Loss 0.365...\n",
      "Step 19370 Training Accuracy 0.906... Training Loss 0.250...\n",
      "Step 19380 Training Accuracy 0.781... Training Loss 0.525...\n",
      "Step 19390 Training Accuracy 0.766... Training Loss 1.048...\n",
      "Step 19400 Training Accuracy 0.781... Training Loss 0.725...\n",
      "Step 19410 Training Accuracy 0.766... Training Loss 0.705...\n",
      "Step 19420 Training Accuracy 0.781... Training Loss 0.552...\n",
      "Step 19430 Training Accuracy 0.859... Training Loss 0.480...\n",
      "Step 19440 Training Accuracy 0.859... Training Loss 0.564...\n",
      "Step 19450 Training Accuracy 0.859... Training Loss 0.385...\n",
      "Step 19460 Training Accuracy 0.750... Training Loss 0.664...\n",
      "Step 19470 Training Accuracy 0.859... Training Loss 0.561...\n",
      "Step 19480 Training Accuracy 0.859... Training Loss 0.345...\n",
      "Step 19490 Training Accuracy 0.922... Training Loss 0.405...\n",
      "Step 19500 Training Accuracy 0.797... Training Loss 0.571...\n",
      "Step 19510 Training Accuracy 0.812... Training Loss 0.493...\n",
      "Step 19520 Training Accuracy 0.859... Training Loss 0.378...\n",
      "Step 19530 Training Accuracy 0.859... Training Loss 0.358...\n",
      "Step 19540 Training Accuracy 0.828... Training Loss 0.568...\n",
      "Step 19550 Training Accuracy 0.812... Training Loss 0.544...\n",
      "Step 19560 Training Accuracy 0.844... Training Loss 0.508...\n",
      "Step 19570 Training Accuracy 0.875... Training Loss 0.439...\n",
      "Step 19580 Training Accuracy 0.859... Training Loss 0.448...\n",
      "Step 19590 Training Accuracy 0.875... Training Loss 0.437...\n",
      "Step 19600 Training Accuracy 0.859... Training Loss 0.549...\n",
      "Step 19610 Training Accuracy 0.828... Training Loss 0.542...\n",
      "Step 19620 Training Accuracy 0.891... Training Loss 0.358...\n",
      "Step 19630 Training Accuracy 0.812... Training Loss 0.562...\n",
      "Step 19640 Training Accuracy 0.828... Training Loss 0.497...\n",
      "Step 19650 Training Accuracy 0.922... Training Loss 0.181...\n",
      "Step 19660 Training Accuracy 0.875... Training Loss 0.364...\n",
      "Step 19670 Training Accuracy 0.859... Training Loss 0.454...\n",
      "Step 19680 Training Accuracy 0.922... Training Loss 0.447...\n",
      "Step 19690 Training Accuracy 0.750... Training Loss 0.558...\n",
      "Step 19700 Training Accuracy 0.891... Training Loss 0.263...\n",
      "Step 19710 Training Accuracy 0.812... Training Loss 0.513...\n",
      "Step 19720 Training Accuracy 0.812... Training Loss 0.571...\n",
      "Step 19730 Training Accuracy 0.812... Training Loss 0.634...\n",
      "Step 19740 Training Accuracy 0.891... Training Loss 0.366...\n",
      "Step 19750 Training Accuracy 0.844... Training Loss 0.542...\n",
      "Step 19760 Training Accuracy 0.875... Training Loss 0.407...\n",
      "Step 19770 Training Accuracy 0.812... Training Loss 0.625...\n",
      "Step 19780 Training Accuracy 0.797... Training Loss 0.720...\n",
      "Step 19790 Training Accuracy 0.906... Training Loss 0.421...\n",
      "Step 19800 Training Accuracy 0.781... Training Loss 0.507...\n",
      "Step 19810 Training Accuracy 0.844... Training Loss 0.507...\n",
      "Step 19820 Training Accuracy 0.797... Training Loss 0.514...\n",
      "Step 19830 Training Accuracy 0.875... Training Loss 0.375...\n",
      "Step 19840 Training Accuracy 0.859... Training Loss 0.391...\n",
      "Step 19850 Training Accuracy 0.906... Training Loss 0.381...\n",
      "Step 19860 Training Accuracy 0.828... Training Loss 0.439...\n",
      "Step 19870 Training Accuracy 0.859... Training Loss 0.471...\n",
      "Step 19880 Training Accuracy 0.969... Training Loss 0.214...\n",
      "Step 19890 Training Accuracy 0.844... Training Loss 0.506...\n",
      "Step 19900 Training Accuracy 0.875... Training Loss 0.333...\n",
      "Step 19910 Training Accuracy 0.922... Training Loss 0.456...\n",
      "Step 19920 Training Accuracy 0.875... Training Loss 0.382...\n",
      "Step 19930 Training Accuracy 0.859... Training Loss 0.394...\n",
      "Step 19940 Training Accuracy 0.812... Training Loss 0.774...\n",
      "Step 19950 Training Accuracy 0.781... Training Loss 0.658...\n",
      "Step 19960 Training Accuracy 0.875... Training Loss 0.431...\n",
      "Step 19970 Training Accuracy 0.859... Training Loss 0.387...\n",
      "Step 19980 Training Accuracy 0.828... Training Loss 0.510...\n",
      "Step 19990 Training Accuracy 0.594... Training Loss 0.794...\n",
      "Step 20000 Training Accuracy 0.812... Training Loss 0.675...\n",
      "Writing checkpoint at step 20000\n",
      "Step 20010 Training Accuracy 0.812... Training Loss 0.613...\n",
      "Step 20020 Training Accuracy 0.844... Training Loss 0.292...\n",
      "Step 20030 Training Accuracy 0.781... Training Loss 0.745...\n",
      "Step 20040 Training Accuracy 0.844... Training Loss 0.717...\n",
      "Step 20050 Training Accuracy 0.875... Training Loss 0.383...\n",
      "Step 20060 Training Accuracy 0.828... Training Loss 0.509...\n",
      "Step 20070 Training Accuracy 0.844... Training Loss 0.522...\n",
      "Step 20080 Training Accuracy 0.859... Training Loss 0.351...\n",
      "Step 20090 Training Accuracy 0.797... Training Loss 0.648...\n",
      "Step 20100 Training Accuracy 0.812... Training Loss 0.513...\n",
      "Step 20110 Training Accuracy 0.812... Training Loss 0.583...\n",
      "Step 20120 Training Accuracy 0.875... Training Loss 0.349...\n",
      "Step 20130 Training Accuracy 0.875... Training Loss 0.449...\n",
      "Step 20140 Training Accuracy 0.812... Training Loss 0.597...\n",
      "Step 20150 Training Accuracy 0.875... Training Loss 0.379...\n",
      "Step 20160 Training Accuracy 0.875... Training Loss 0.544...\n",
      "Step 20170 Training Accuracy 0.812... Training Loss 0.606...\n",
      "Step 20180 Training Accuracy 0.875... Training Loss 0.320...\n",
      "Step 20190 Training Accuracy 0.922... Training Loss 0.304...\n",
      "Step 20200 Training Accuracy 0.812... Training Loss 0.537...\n",
      "Step 20210 Training Accuracy 0.875... Training Loss 0.383...\n",
      "Step 20220 Training Accuracy 0.859... Training Loss 0.435...\n",
      "Step 20230 Training Accuracy 0.844... Training Loss 0.410...\n",
      "Step 20240 Training Accuracy 0.828... Training Loss 0.480...\n",
      "Step 20250 Training Accuracy 0.859... Training Loss 0.374...\n",
      "Step 20260 Training Accuracy 0.938... Training Loss 0.399...\n",
      "Step 20270 Training Accuracy 0.828... Training Loss 0.597...\n",
      "Step 20280 Training Accuracy 0.828... Training Loss 0.524...\n",
      "Step 20290 Training Accuracy 0.750... Training Loss 0.848...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 20300 Training Accuracy 0.891... Training Loss 0.496...\n",
      "Step 20310 Training Accuracy 0.859... Training Loss 0.367...\n",
      "Step 20320 Training Accuracy 0.906... Training Loss 0.493...\n",
      "Step 20330 Training Accuracy 0.859... Training Loss 0.515...\n",
      "Step 20340 Training Accuracy 0.797... Training Loss 0.638...\n",
      "Step 20350 Training Accuracy 0.953... Training Loss 0.300...\n",
      "Step 20360 Training Accuracy 0.859... Training Loss 0.428...\n",
      "Step 20370 Training Accuracy 0.938... Training Loss 0.283...\n",
      "Step 20380 Training Accuracy 0.750... Training Loss 0.914...\n",
      "Step 20390 Training Accuracy 0.797... Training Loss 0.772...\n",
      "Step 20400 Training Accuracy 0.875... Training Loss 0.452...\n",
      "Step 20410 Training Accuracy 0.844... Training Loss 0.574...\n",
      "Step 20420 Training Accuracy 0.875... Training Loss 0.548...\n",
      "Step 20430 Training Accuracy 0.859... Training Loss 0.435...\n",
      "Step 20440 Training Accuracy 0.766... Training Loss 0.620...\n",
      "Step 20450 Training Accuracy 0.812... Training Loss 0.533...\n",
      "Step 20460 Training Accuracy 0.891... Training Loss 0.304...\n",
      "Step 20470 Training Accuracy 0.828... Training Loss 0.581...\n",
      "Step 20480 Training Accuracy 0.797... Training Loss 0.537...\n",
      "Step 20490 Training Accuracy 0.938... Training Loss 0.362...\n",
      "Step 20500 Training Accuracy 0.859... Training Loss 0.420...\n",
      "Step 20510 Training Accuracy 0.891... Training Loss 0.392...\n",
      "Step 20520 Training Accuracy 0.859... Training Loss 0.439...\n",
      "Step 20530 Training Accuracy 0.891... Training Loss 0.468...\n",
      "Step 20540 Training Accuracy 0.875... Training Loss 0.436...\n",
      "Step 20550 Training Accuracy 0.891... Training Loss 0.303...\n",
      "Step 20560 Training Accuracy 0.875... Training Loss 0.425...\n",
      "Step 20570 Training Accuracy 0.844... Training Loss 0.482...\n",
      "Step 20580 Training Accuracy 0.906... Training Loss 0.289...\n",
      "Step 20590 Training Accuracy 0.844... Training Loss 0.423...\n",
      "Step 20600 Training Accuracy 0.844... Training Loss 0.603...\n",
      "Step 20610 Training Accuracy 0.844... Training Loss 0.613...\n",
      "Step 20620 Training Accuracy 0.844... Training Loss 0.521...\n",
      "Step 20630 Training Accuracy 0.859... Training Loss 0.537...\n",
      "Step 20640 Training Accuracy 0.906... Training Loss 0.396...\n",
      "Step 20650 Training Accuracy 0.828... Training Loss 0.543...\n",
      "Step 20660 Training Accuracy 0.781... Training Loss 0.626...\n",
      "Step 20670 Training Accuracy 0.844... Training Loss 0.480...\n",
      "Step 20680 Training Accuracy 0.859... Training Loss 0.453...\n",
      "Step 20690 Training Accuracy 0.812... Training Loss 0.533...\n",
      "Step 20700 Training Accuracy 0.844... Training Loss 0.287...\n",
      "Step 20710 Training Accuracy 0.797... Training Loss 0.595...\n",
      "Step 20720 Training Accuracy 0.812... Training Loss 0.556...\n",
      "Step 20730 Training Accuracy 0.812... Training Loss 0.450...\n",
      "Step 20740 Training Accuracy 0.828... Training Loss 0.527...\n",
      "Step 20750 Training Accuracy 0.859... Training Loss 0.402...\n",
      "Step 20760 Training Accuracy 0.891... Training Loss 0.496...\n",
      "Step 20770 Training Accuracy 0.875... Training Loss 0.456...\n",
      "Step 20780 Training Accuracy 0.906... Training Loss 0.399...\n",
      "Step 20790 Training Accuracy 0.922... Training Loss 0.254...\n",
      "Step 20800 Training Accuracy 0.922... Training Loss 0.245...\n",
      "Step 20810 Training Accuracy 0.859... Training Loss 0.375...\n",
      "Step 20820 Training Accuracy 0.859... Training Loss 0.505...\n",
      "Step 20830 Training Accuracy 0.859... Training Loss 0.524...\n",
      "Step 20840 Training Accuracy 0.844... Training Loss 0.325...\n",
      "Step 20850 Training Accuracy 0.781... Training Loss 0.559...\n",
      "Step 20860 Training Accuracy 0.844... Training Loss 0.611...\n",
      "Step 20870 Training Accuracy 0.875... Training Loss 0.460...\n",
      "Step 20880 Training Accuracy 0.875... Training Loss 0.537...\n",
      "Step 20890 Training Accuracy 0.812... Training Loss 0.601...\n",
      "Step 20900 Training Accuracy 0.844... Training Loss 0.488...\n",
      "Step 20910 Training Accuracy 0.797... Training Loss 0.589...\n",
      "Step 20920 Training Accuracy 0.859... Training Loss 0.426...\n",
      "Step 20930 Training Accuracy 0.828... Training Loss 0.586...\n",
      "Step 20940 Training Accuracy 0.844... Training Loss 0.338...\n",
      "Step 20950 Training Accuracy 0.891... Training Loss 0.285...\n",
      "Step 20960 Training Accuracy 0.828... Training Loss 0.395...\n",
      "Step 20970 Training Accuracy 0.875... Training Loss 0.409...\n",
      "Step 20980 Training Accuracy 0.844... Training Loss 0.476...\n",
      "Step 20990 Training Accuracy 0.891... Training Loss 0.382...\n",
      "Step 21000 Training Accuracy 0.812... Training Loss 0.588...\n",
      "Writing checkpoint at step 21000\n",
      "Step 21010 Training Accuracy 0.875... Training Loss 0.449...\n",
      "Step 21020 Training Accuracy 0.953... Training Loss 0.257...\n",
      "Step 21030 Training Accuracy 0.891... Training Loss 0.328...\n",
      "Step 21040 Training Accuracy 0.844... Training Loss 0.515...\n",
      "Step 21050 Training Accuracy 0.859... Training Loss 0.330...\n",
      "Step 21060 Training Accuracy 0.891... Training Loss 0.400...\n",
      "Step 21070 Training Accuracy 0.859... Training Loss 0.348...\n",
      "Step 21080 Training Accuracy 0.844... Training Loss 0.445...\n",
      "Step 21090 Training Accuracy 0.891... Training Loss 0.367...\n",
      "Step 21100 Training Accuracy 0.891... Training Loss 0.332...\n",
      "Step 21110 Training Accuracy 0.812... Training Loss 0.473...\n",
      "Step 21120 Training Accuracy 0.766... Training Loss 0.727...\n",
      "Step 21130 Training Accuracy 0.750... Training Loss 0.665...\n",
      "Step 21140 Training Accuracy 0.859... Training Loss 0.341...\n",
      "Step 21150 Training Accuracy 0.891... Training Loss 0.379...\n",
      "Step 21160 Training Accuracy 0.922... Training Loss 0.237...\n",
      "Step 21170 Training Accuracy 0.906... Training Loss 0.455...\n",
      "Step 21180 Training Accuracy 0.875... Training Loss 0.452...\n",
      "Step 21190 Training Accuracy 0.891... Training Loss 0.401...\n",
      "Step 21200 Training Accuracy 0.906... Training Loss 0.224...\n",
      "Step 21210 Training Accuracy 0.828... Training Loss 0.456...\n",
      "Step 21220 Training Accuracy 0.891... Training Loss 0.357...\n",
      "Step 21230 Training Accuracy 0.844... Training Loss 0.354...\n",
      "Step 21240 Training Accuracy 0.891... Training Loss 0.355...\n",
      "Step 21250 Training Accuracy 0.812... Training Loss 0.269...\n",
      "Step 21260 Training Accuracy 0.922... Training Loss 0.288...\n",
      "Step 21270 Training Accuracy 0.953... Training Loss 0.250...\n",
      "Step 21280 Training Accuracy 0.859... Training Loss 0.510...\n",
      "Step 21290 Training Accuracy 0.844... Training Loss 0.377...\n",
      "Step 21300 Training Accuracy 0.859... Training Loss 0.529...\n",
      "Step 21310 Training Accuracy 0.891... Training Loss 0.317...\n",
      "Step 21320 Training Accuracy 0.797... Training Loss 0.548...\n",
      "Step 21330 Training Accuracy 0.891... Training Loss 0.266...\n",
      "Step 21340 Training Accuracy 0.844... Training Loss 0.526...\n",
      "Step 21350 Training Accuracy 0.922... Training Loss 0.372...\n",
      "Step 21360 Training Accuracy 0.781... Training Loss 0.527...\n",
      "Step 21370 Training Accuracy 0.859... Training Loss 0.544...\n",
      "Step 21380 Training Accuracy 0.906... Training Loss 0.241...\n",
      "Step 21390 Training Accuracy 0.859... Training Loss 0.357...\n",
      "Step 21400 Training Accuracy 0.875... Training Loss 0.415...\n",
      "Step 21410 Training Accuracy 0.875... Training Loss 0.402...\n",
      "Step 21420 Training Accuracy 0.906... Training Loss 0.376...\n",
      "Step 21430 Training Accuracy 0.891... Training Loss 0.414...\n",
      "Step 21440 Training Accuracy 0.859... Training Loss 0.336...\n",
      "Step 21450 Training Accuracy 0.922... Training Loss 0.379...\n",
      "Step 21460 Training Accuracy 0.797... Training Loss 0.523...\n",
      "Step 21470 Training Accuracy 0.875... Training Loss 0.418...\n",
      "Step 21480 Training Accuracy 0.797... Training Loss 0.785...\n",
      "Step 21490 Training Accuracy 0.875... Training Loss 0.442...\n",
      "Step 21500 Training Accuracy 0.844... Training Loss 0.437...\n",
      "Step 21510 Training Accuracy 0.844... Training Loss 0.414...\n",
      "Step 21520 Training Accuracy 0.781... Training Loss 0.578...\n",
      "Step 21530 Training Accuracy 0.906... Training Loss 0.374...\n",
      "Step 21540 Training Accuracy 0.875... Training Loss 0.466...\n",
      "Step 21550 Training Accuracy 0.844... Training Loss 0.547...\n",
      "Step 21560 Training Accuracy 0.844... Training Loss 0.364...\n",
      "Step 21570 Training Accuracy 0.938... Training Loss 0.319...\n",
      "Step 21580 Training Accuracy 0.922... Training Loss 0.261...\n",
      "Step 21590 Training Accuracy 0.828... Training Loss 0.647...\n",
      "Step 21600 Training Accuracy 0.875... Training Loss 0.301...\n",
      "Step 21610 Training Accuracy 0.891... Training Loss 0.418...\n",
      "Step 21620 Training Accuracy 0.859... Training Loss 0.481...\n",
      "Step 21630 Training Accuracy 0.875... Training Loss 0.386...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 21640 Training Accuracy 0.812... Training Loss 0.709...\n",
      "Step 21650 Training Accuracy 0.891... Training Loss 0.460...\n",
      "Step 21660 Training Accuracy 0.828... Training Loss 0.408...\n",
      "Step 21670 Training Accuracy 0.906... Training Loss 0.423...\n",
      "Step 21680 Training Accuracy 0.750... Training Loss 0.664...\n",
      "Step 21690 Training Accuracy 0.875... Training Loss 0.356...\n",
      "Step 21700 Training Accuracy 0.906... Training Loss 0.239...\n",
      "Step 21710 Training Accuracy 0.828... Training Loss 0.570...\n",
      "Step 21720 Training Accuracy 0.891... Training Loss 0.304...\n",
      "Step 21730 Training Accuracy 0.906... Training Loss 0.278...\n",
      "Step 21740 Training Accuracy 0.906... Training Loss 0.385...\n",
      "Step 21750 Training Accuracy 0.906... Training Loss 0.366...\n",
      "Step 21760 Training Accuracy 0.875... Training Loss 0.299...\n",
      "Step 21770 Training Accuracy 0.844... Training Loss 0.444...\n",
      "Step 21780 Training Accuracy 0.812... Training Loss 0.497...\n",
      "Step 21790 Training Accuracy 0.891... Training Loss 0.473...\n",
      "Step 21800 Training Accuracy 0.781... Training Loss 0.898...\n",
      "Step 21810 Training Accuracy 0.797... Training Loss 0.505...\n",
      "Step 21820 Training Accuracy 0.859... Training Loss 0.380...\n",
      "Step 21830 Training Accuracy 0.906... Training Loss 0.351...\n",
      "Step 21840 Training Accuracy 0.828... Training Loss 0.565...\n",
      "Step 21850 Training Accuracy 0.875... Training Loss 0.316...\n",
      "Step 21860 Training Accuracy 0.859... Training Loss 0.389...\n",
      "Step 21870 Training Accuracy 0.859... Training Loss 0.445...\n",
      "Step 21880 Training Accuracy 0.812... Training Loss 0.540...\n",
      "Step 21890 Training Accuracy 0.891... Training Loss 0.386...\n",
      "Step 21900 Training Accuracy 0.828... Training Loss 0.528...\n",
      "Step 21910 Training Accuracy 0.844... Training Loss 0.388...\n",
      "Step 21920 Training Accuracy 0.906... Training Loss 0.293...\n",
      "Step 21930 Training Accuracy 0.828... Training Loss 0.470...\n",
      "Step 21940 Training Accuracy 0.922... Training Loss 0.194...\n",
      "Step 21950 Training Accuracy 0.812... Training Loss 0.610...\n",
      "Step 21960 Training Accuracy 0.906... Training Loss 0.303...\n",
      "Step 21970 Training Accuracy 0.875... Training Loss 0.295...\n",
      "Step 21980 Training Accuracy 0.844... Training Loss 0.424...\n",
      "Step 21990 Training Accuracy 0.875... Training Loss 0.466...\n",
      "Step 22000 Training Accuracy 0.875... Training Loss 0.332...\n",
      "Writing checkpoint at step 22000\n",
      "Step 22010 Training Accuracy 0.891... Training Loss 0.405...\n",
      "Step 22020 Training Accuracy 0.906... Training Loss 0.319...\n",
      "Step 22030 Training Accuracy 0.906... Training Loss 0.327...\n",
      "Step 22040 Training Accuracy 0.922... Training Loss 0.321...\n",
      "Step 22050 Training Accuracy 0.922... Training Loss 0.554...\n",
      "Step 22060 Training Accuracy 0.844... Training Loss 0.468...\n",
      "Step 22070 Training Accuracy 0.781... Training Loss 0.728...\n",
      "Step 22080 Training Accuracy 0.906... Training Loss 0.456...\n",
      "Step 22090 Training Accuracy 0.938... Training Loss 0.117...\n",
      "Step 22100 Training Accuracy 0.906... Training Loss 0.371...\n",
      "Step 22110 Training Accuracy 0.828... Training Loss 0.426...\n",
      "Step 22120 Training Accuracy 0.828... Training Loss 0.560...\n",
      "Step 22130 Training Accuracy 0.875... Training Loss 0.524...\n",
      "Step 22140 Training Accuracy 0.750... Training Loss 0.780...\n",
      "Step 22150 Training Accuracy 0.875... Training Loss 0.453...\n",
      "Step 22160 Training Accuracy 0.844... Training Loss 0.356...\n",
      "Step 22170 Training Accuracy 0.875... Training Loss 0.381...\n",
      "Step 22180 Training Accuracy 0.938... Training Loss 0.217...\n",
      "Step 22190 Training Accuracy 0.859... Training Loss 0.319...\n",
      "Step 22200 Training Accuracy 0.891... Training Loss 0.310...\n",
      "Step 22210 Training Accuracy 0.969... Training Loss 0.225...\n",
      "Step 22220 Training Accuracy 0.844... Training Loss 0.527...\n",
      "Step 22230 Training Accuracy 0.812... Training Loss 0.427...\n",
      "Step 22240 Training Accuracy 0.828... Training Loss 0.449...\n",
      "Step 22250 Training Accuracy 0.797... Training Loss 0.563...\n",
      "Step 22260 Training Accuracy 0.891... Training Loss 0.379...\n",
      "Step 22270 Training Accuracy 0.875... Training Loss 0.360...\n",
      "Step 22280 Training Accuracy 0.875... Training Loss 0.298...\n",
      "Step 22290 Training Accuracy 0.891... Training Loss 0.367...\n",
      "Step 22300 Training Accuracy 0.797... Training Loss 0.653...\n",
      "Step 22310 Training Accuracy 0.875... Training Loss 0.314...\n",
      "Step 22320 Training Accuracy 0.828... Training Loss 0.624...\n",
      "Step 22330 Training Accuracy 0.797... Training Loss 0.650...\n",
      "Step 22340 Training Accuracy 0.891... Training Loss 0.307...\n",
      "Step 22350 Training Accuracy 0.875... Training Loss 0.579...\n",
      "Step 22360 Training Accuracy 0.891... Training Loss 0.355...\n",
      "Step 22370 Training Accuracy 0.844... Training Loss 0.614...\n",
      "Step 22380 Training Accuracy 0.891... Training Loss 0.307...\n",
      "Step 22390 Training Accuracy 0.859... Training Loss 0.270...\n",
      "Step 22400 Training Accuracy 0.875... Training Loss 0.288...\n",
      "Step 22410 Training Accuracy 0.906... Training Loss 0.221...\n",
      "Step 22420 Training Accuracy 0.938... Training Loss 0.258...\n",
      "Step 22430 Training Accuracy 0.859... Training Loss 0.376...\n",
      "Step 22440 Training Accuracy 0.891... Training Loss 0.365...\n",
      "Step 22450 Training Accuracy 0.922... Training Loss 0.295...\n",
      "Step 22460 Training Accuracy 0.953... Training Loss 0.153...\n",
      "Step 22470 Training Accuracy 0.906... Training Loss 0.325...\n",
      "Step 22480 Training Accuracy 0.938... Training Loss 0.253...\n",
      "Step 22490 Training Accuracy 0.844... Training Loss 0.617...\n",
      "Step 22500 Training Accuracy 0.875... Training Loss 0.450...\n",
      "Step 22510 Training Accuracy 0.938... Training Loss 0.233...\n",
      "Step 22520 Training Accuracy 0.875... Training Loss 0.362...\n",
      "Step 22530 Training Accuracy 0.891... Training Loss 0.339...\n",
      "Step 22540 Training Accuracy 0.844... Training Loss 0.238...\n",
      "Step 22550 Training Accuracy 0.859... Training Loss 0.334...\n",
      "Step 22560 Training Accuracy 0.891... Training Loss 0.301...\n",
      "Step 22570 Training Accuracy 0.828... Training Loss 0.578...\n",
      "Step 22580 Training Accuracy 0.891... Training Loss 0.577...\n",
      "Step 22590 Training Accuracy 0.812... Training Loss 0.504...\n",
      "Step 22600 Training Accuracy 0.891... Training Loss 0.388...\n",
      "Step 22610 Training Accuracy 0.875... Training Loss 0.321...\n",
      "Step 22620 Training Accuracy 0.906... Training Loss 0.381...\n",
      "Step 22630 Training Accuracy 0.828... Training Loss 0.543...\n",
      "Step 22640 Training Accuracy 0.875... Training Loss 0.294...\n",
      "Step 22650 Training Accuracy 0.906... Training Loss 0.433...\n",
      "Step 22660 Training Accuracy 0.906... Training Loss 0.276...\n",
      "Step 22670 Training Accuracy 0.906... Training Loss 0.313...\n",
      "Step 22680 Training Accuracy 0.922... Training Loss 0.194...\n",
      "Step 22690 Training Accuracy 0.922... Training Loss 0.388...\n",
      "Step 22700 Training Accuracy 0.891... Training Loss 0.433...\n",
      "Step 22710 Training Accuracy 0.844... Training Loss 0.306...\n",
      "Step 22720 Training Accuracy 0.828... Training Loss 0.850...\n",
      "Step 22730 Training Accuracy 0.938... Training Loss 0.450...\n",
      "Step 22740 Training Accuracy 0.844... Training Loss 0.475...\n",
      "Step 22750 Training Accuracy 0.938... Training Loss 0.184...\n",
      "Step 22760 Training Accuracy 0.875... Training Loss 0.435...\n",
      "Step 22770 Training Accuracy 0.891... Training Loss 0.323...\n",
      "Step 22780 Training Accuracy 0.859... Training Loss 0.544...\n",
      "Step 22790 Training Accuracy 0.938... Training Loss 0.230...\n",
      "Step 22800 Training Accuracy 0.891... Training Loss 0.415...\n",
      "Step 22810 Training Accuracy 0.859... Training Loss 0.418...\n",
      "Step 22820 Training Accuracy 0.906... Training Loss 0.230...\n",
      "Step 22830 Training Accuracy 0.844... Training Loss 0.556...\n",
      "Step 22840 Training Accuracy 0.891... Training Loss 0.165...\n",
      "Step 22850 Training Accuracy 0.859... Training Loss 0.411...\n",
      "Step 22860 Training Accuracy 0.938... Training Loss 0.272...\n",
      "Step 22870 Training Accuracy 0.875... Training Loss 0.343...\n",
      "Step 22880 Training Accuracy 0.859... Training Loss 0.457...\n",
      "Step 22890 Training Accuracy 0.844... Training Loss 0.583...\n",
      "Step 22900 Training Accuracy 0.891... Training Loss 0.257...\n",
      "Step 22910 Training Accuracy 0.719... Training Loss 0.802...\n",
      "Step 22920 Training Accuracy 0.859... Training Loss 0.482...\n",
      "Step 22930 Training Accuracy 0.875... Training Loss 0.273...\n",
      "Step 22940 Training Accuracy 0.797... Training Loss 0.541...\n",
      "Step 22950 Training Accuracy 0.766... Training Loss 0.642...\n",
      "Step 22960 Training Accuracy 0.859... Training Loss 0.330...\n",
      "Step 22970 Training Accuracy 0.906... Training Loss 0.457...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 22980 Training Accuracy 0.891... Training Loss 0.261...\n",
      "Step 22990 Training Accuracy 0.828... Training Loss 0.615...\n",
      "Step 23000 Training Accuracy 0.812... Training Loss 0.453...\n",
      "Writing checkpoint at step 23000\n",
      "Step 23010 Training Accuracy 0.812... Training Loss 0.550...\n",
      "Step 23020 Training Accuracy 0.891... Training Loss 0.464...\n",
      "Step 23030 Training Accuracy 0.922... Training Loss 0.391...\n",
      "Step 23040 Training Accuracy 0.922... Training Loss 0.210...\n",
      "Step 23050 Training Accuracy 0.906... Training Loss 0.329...\n",
      "Step 23060 Training Accuracy 0.906... Training Loss 0.319...\n",
      "Step 23070 Training Accuracy 0.875... Training Loss 0.335...\n",
      "Step 23080 Training Accuracy 0.906... Training Loss 0.361...\n",
      "Step 23090 Training Accuracy 0.891... Training Loss 0.469...\n",
      "Step 23100 Training Accuracy 0.812... Training Loss 0.552...\n",
      "Step 23110 Training Accuracy 0.875... Training Loss 0.451...\n",
      "Step 23120 Training Accuracy 0.844... Training Loss 0.298...\n",
      "Step 23130 Training Accuracy 0.906... Training Loss 0.282...\n",
      "Step 23140 Training Accuracy 0.938... Training Loss 0.242...\n",
      "Step 23150 Training Accuracy 0.875... Training Loss 0.351...\n",
      "Step 23160 Training Accuracy 0.812... Training Loss 0.561...\n",
      "Step 23170 Training Accuracy 0.875... Training Loss 0.522...\n",
      "Step 23180 Training Accuracy 0.969... Training Loss 0.270...\n",
      "Step 23190 Training Accuracy 0.859... Training Loss 0.460...\n",
      "Step 23200 Training Accuracy 0.812... Training Loss 0.740...\n",
      "Step 23210 Training Accuracy 0.859... Training Loss 0.410...\n",
      "Step 23220 Training Accuracy 0.922... Training Loss 0.348...\n",
      "Step 23230 Training Accuracy 0.891... Training Loss 0.330...\n",
      "Step 23240 Training Accuracy 0.859... Training Loss 0.390...\n",
      "Step 23250 Training Accuracy 0.875... Training Loss 0.287...\n",
      "Step 23260 Training Accuracy 0.859... Training Loss 0.421...\n",
      "Step 23270 Training Accuracy 0.812... Training Loss 0.493...\n",
      "Step 23280 Training Accuracy 0.875... Training Loss 0.417...\n",
      "Step 23290 Training Accuracy 0.891... Training Loss 0.379...\n",
      "Step 23300 Training Accuracy 0.906... Training Loss 0.237...\n",
      "Step 23310 Training Accuracy 0.859... Training Loss 0.408...\n",
      "Step 23320 Training Accuracy 0.781... Training Loss 0.564...\n",
      "Step 23330 Training Accuracy 0.922... Training Loss 0.393...\n",
      "Step 23340 Training Accuracy 0.891... Training Loss 0.336...\n",
      "Step 23350 Training Accuracy 0.766... Training Loss 0.466...\n",
      "Step 23360 Training Accuracy 0.906... Training Loss 0.394...\n",
      "Step 23370 Training Accuracy 0.828... Training Loss 0.357...\n",
      "Step 23380 Training Accuracy 0.906... Training Loss 0.287...\n",
      "Step 23390 Training Accuracy 0.938... Training Loss 0.273...\n",
      "Step 23400 Training Accuracy 0.906... Training Loss 0.312...\n",
      "Step 23410 Training Accuracy 0.859... Training Loss 0.346...\n",
      "Step 23420 Training Accuracy 0.875... Training Loss 0.291...\n",
      "Step 23430 Training Accuracy 0.859... Training Loss 0.467...\n",
      "Step 23440 Training Accuracy 0.828... Training Loss 0.564...\n",
      "Step 23450 Training Accuracy 0.938... Training Loss 0.337...\n",
      "Step 23460 Training Accuracy 0.891... Training Loss 0.349...\n",
      "Step 23470 Training Accuracy 0.875... Training Loss 0.330...\n",
      "Step 23480 Training Accuracy 0.891... Training Loss 0.382...\n",
      "Step 23490 Training Accuracy 0.844... Training Loss 0.515...\n",
      "Step 23500 Training Accuracy 0.922... Training Loss 0.267...\n",
      "Step 23510 Training Accuracy 0.938... Training Loss 0.260...\n",
      "Step 23520 Training Accuracy 0.891... Training Loss 0.301...\n",
      "Step 23530 Training Accuracy 0.828... Training Loss 0.427...\n",
      "Step 23540 Training Accuracy 0.844... Training Loss 0.384...\n",
      "Step 23550 Training Accuracy 0.906... Training Loss 0.290...\n",
      "Step 23560 Training Accuracy 0.922... Training Loss 0.434...\n",
      "Step 23570 Training Accuracy 0.953... Training Loss 0.141...\n",
      "Step 23580 Training Accuracy 0.938... Training Loss 0.318...\n",
      "Step 23590 Training Accuracy 0.875... Training Loss 0.433...\n",
      "Step 23600 Training Accuracy 0.875... Training Loss 0.414...\n",
      "Step 23610 Training Accuracy 0.922... Training Loss 0.351...\n",
      "Step 23620 Training Accuracy 0.906... Training Loss 0.254...\n",
      "Step 23630 Training Accuracy 0.844... Training Loss 0.456...\n",
      "Step 23640 Training Accuracy 0.859... Training Loss 0.407...\n",
      "Step 23650 Training Accuracy 0.859... Training Loss 0.393...\n",
      "Step 23660 Training Accuracy 0.844... Training Loss 0.468...\n",
      "Step 23670 Training Accuracy 0.922... Training Loss 0.440...\n",
      "Step 23680 Training Accuracy 0.875... Training Loss 0.320...\n",
      "Step 23690 Training Accuracy 0.922... Training Loss 0.232...\n",
      "Step 23700 Training Accuracy 0.844... Training Loss 0.373...\n",
      "Step 23710 Training Accuracy 0.906... Training Loss 0.233...\n",
      "Step 23720 Training Accuracy 0.953... Training Loss 0.318...\n",
      "Step 23730 Training Accuracy 0.844... Training Loss 0.491...\n",
      "Step 23740 Training Accuracy 0.938... Training Loss 0.191...\n",
      "Step 23750 Training Accuracy 0.891... Training Loss 0.578...\n",
      "Step 23760 Training Accuracy 0.922... Training Loss 0.293...\n",
      "Step 23770 Training Accuracy 0.859... Training Loss 0.603...\n",
      "Step 23780 Training Accuracy 0.906... Training Loss 0.268...\n",
      "Step 23790 Training Accuracy 0.906... Training Loss 0.323...\n",
      "Step 23800 Training Accuracy 0.859... Training Loss 0.479...\n",
      "Step 23810 Training Accuracy 0.906... Training Loss 0.219...\n",
      "Step 23820 Training Accuracy 0.844... Training Loss 0.272...\n",
      "Step 23830 Training Accuracy 0.922... Training Loss 0.190...\n",
      "Step 23840 Training Accuracy 0.844... Training Loss 0.217...\n",
      "Step 23850 Training Accuracy 0.859... Training Loss 0.550...\n",
      "Step 23860 Training Accuracy 0.844... Training Loss 0.510...\n",
      "Step 23870 Training Accuracy 0.891... Training Loss 0.383...\n",
      "Step 23880 Training Accuracy 0.859... Training Loss 0.315...\n",
      "Step 23890 Training Accuracy 0.797... Training Loss 0.562...\n",
      "Step 23900 Training Accuracy 0.844... Training Loss 0.533...\n",
      "Step 23910 Training Accuracy 0.828... Training Loss 0.627...\n",
      "Step 23920 Training Accuracy 0.953... Training Loss 0.262...\n",
      "Step 23930 Training Accuracy 0.875... Training Loss 0.338...\n",
      "Step 23940 Training Accuracy 0.922... Training Loss 0.299...\n",
      "Step 23950 Training Accuracy 0.922... Training Loss 0.237...\n",
      "Step 23960 Training Accuracy 0.828... Training Loss 0.406...\n",
      "Step 23970 Training Accuracy 0.875... Training Loss 0.255...\n",
      "Step 23980 Training Accuracy 0.891... Training Loss 0.386...\n",
      "Step 23990 Training Accuracy 0.812... Training Loss 0.712...\n",
      "Step 24000 Training Accuracy 0.766... Training Loss 0.688...\n",
      "Writing checkpoint at step 24000\n",
      "Step 24010 Training Accuracy 0.922... Training Loss 0.321...\n",
      "Step 24020 Training Accuracy 0.906... Training Loss 0.340...\n",
      "Step 24030 Training Accuracy 0.828... Training Loss 0.498...\n",
      "Step 24040 Training Accuracy 0.953... Training Loss 0.156...\n",
      "Step 24050 Training Accuracy 0.953... Training Loss 0.388...\n",
      "Step 24060 Training Accuracy 0.953... Training Loss 0.295...\n",
      "Step 24070 Training Accuracy 0.891... Training Loss 0.352...\n",
      "Step 24080 Training Accuracy 0.891... Training Loss 0.373...\n",
      "Step 24090 Training Accuracy 0.875... Training Loss 0.356...\n",
      "Step 24100 Training Accuracy 0.922... Training Loss 0.123...\n",
      "Step 24110 Training Accuracy 0.906... Training Loss 0.253...\n",
      "Step 24120 Training Accuracy 0.891... Training Loss 0.334...\n",
      "Step 24130 Training Accuracy 0.906... Training Loss 0.276...\n",
      "Step 24140 Training Accuracy 0.812... Training Loss 0.417...\n",
      "Step 24150 Training Accuracy 0.922... Training Loss 0.302...\n",
      "Step 24160 Training Accuracy 0.922... Training Loss 0.214...\n",
      "Step 24170 Training Accuracy 0.875... Training Loss 0.532...\n",
      "Step 24180 Training Accuracy 0.844... Training Loss 0.459...\n",
      "Step 24190 Training Accuracy 0.828... Training Loss 0.540...\n",
      "Step 24200 Training Accuracy 0.938... Training Loss 0.242...\n",
      "Step 24210 Training Accuracy 0.844... Training Loss 0.547...\n",
      "Step 24220 Training Accuracy 0.844... Training Loss 0.462...\n",
      "Step 24230 Training Accuracy 0.859... Training Loss 0.451...\n",
      "Step 24240 Training Accuracy 0.906... Training Loss 0.253...\n",
      "Step 24250 Training Accuracy 0.922... Training Loss 0.303...\n",
      "Step 24260 Training Accuracy 0.906... Training Loss 0.281...\n",
      "Step 24270 Training Accuracy 0.906... Training Loss 0.263...\n",
      "Step 24280 Training Accuracy 0.891... Training Loss 0.353...\n",
      "Step 24290 Training Accuracy 0.906... Training Loss 0.284...\n",
      "Step 24300 Training Accuracy 0.844... Training Loss 0.361...\n",
      "Step 24310 Training Accuracy 0.922... Training Loss 0.348...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 24320 Training Accuracy 0.797... Training Loss 0.558...\n",
      "Step 24330 Training Accuracy 0.891... Training Loss 0.258...\n",
      "Step 24340 Training Accuracy 0.906... Training Loss 0.354...\n",
      "Step 24350 Training Accuracy 0.812... Training Loss 0.620...\n",
      "Step 24360 Training Accuracy 0.844... Training Loss 0.395...\n",
      "Step 24370 Training Accuracy 0.875... Training Loss 0.327...\n",
      "Step 24380 Training Accuracy 0.781... Training Loss 0.701...\n",
      "Step 24390 Training Accuracy 0.969... Training Loss 0.268...\n",
      "Step 24400 Training Accuracy 0.859... Training Loss 0.348...\n",
      "Step 24410 Training Accuracy 0.906... Training Loss 0.177...\n",
      "Step 24420 Training Accuracy 0.875... Training Loss 0.530...\n",
      "Step 24430 Training Accuracy 0.906... Training Loss 0.232...\n",
      "Step 24440 Training Accuracy 0.922... Training Loss 0.283...\n",
      "Step 24450 Training Accuracy 0.922... Training Loss 0.396...\n",
      "Step 24460 Training Accuracy 0.844... Training Loss 0.385...\n",
      "Step 24470 Training Accuracy 0.922... Training Loss 0.250...\n",
      "Step 24480 Training Accuracy 0.844... Training Loss 0.398...\n",
      "Step 24490 Training Accuracy 0.906... Training Loss 0.293...\n",
      "Step 24500 Training Accuracy 0.922... Training Loss 0.274...\n",
      "Step 24510 Training Accuracy 0.906... Training Loss 0.371...\n",
      "Step 24520 Training Accuracy 0.859... Training Loss 0.444...\n",
      "Step 24530 Training Accuracy 0.891... Training Loss 0.299...\n",
      "Step 24540 Training Accuracy 0.906... Training Loss 0.299...\n",
      "Step 24550 Training Accuracy 0.891... Training Loss 0.329...\n",
      "Step 24560 Training Accuracy 0.875... Training Loss 0.253...\n",
      "Step 24570 Training Accuracy 0.922... Training Loss 0.158...\n",
      "Step 24580 Training Accuracy 0.859... Training Loss 0.446...\n",
      "Step 24590 Training Accuracy 0.953... Training Loss 0.315...\n",
      "Step 24600 Training Accuracy 0.859... Training Loss 0.431...\n",
      "Step 24610 Training Accuracy 0.891... Training Loss 0.379...\n",
      "Step 24620 Training Accuracy 0.906... Training Loss 0.268...\n",
      "Step 24630 Training Accuracy 0.953... Training Loss 0.233...\n",
      "Step 24640 Training Accuracy 0.875... Training Loss 0.226...\n",
      "Step 24650 Training Accuracy 0.922... Training Loss 0.197...\n",
      "Step 24660 Training Accuracy 0.781... Training Loss 0.458...\n",
      "Step 24670 Training Accuracy 0.844... Training Loss 0.352...\n",
      "Step 24680 Training Accuracy 0.875... Training Loss 0.335...\n",
      "Step 24690 Training Accuracy 0.844... Training Loss 0.431...\n",
      "Step 24700 Training Accuracy 0.922... Training Loss 0.188...\n",
      "Step 24710 Training Accuracy 0.891... Training Loss 0.441...\n",
      "Step 24720 Training Accuracy 0.953... Training Loss 0.293...\n",
      "Step 24730 Training Accuracy 0.891... Training Loss 0.416...\n",
      "Step 24740 Training Accuracy 0.969... Training Loss 0.152...\n",
      "Step 24750 Training Accuracy 0.953... Training Loss 0.183...\n",
      "Step 24760 Training Accuracy 0.859... Training Loss 0.322...\n",
      "Step 24770 Training Accuracy 0.906... Training Loss 0.143...\n",
      "Step 24780 Training Accuracy 0.922... Training Loss 0.424...\n",
      "Step 24790 Training Accuracy 0.875... Training Loss 0.272...\n",
      "Step 24800 Training Accuracy 0.906... Training Loss 0.344...\n",
      "Step 24810 Training Accuracy 0.938... Training Loss 0.211...\n",
      "Step 24820 Training Accuracy 0.906... Training Loss 0.300...\n",
      "Step 24830 Training Accuracy 0.875... Training Loss 0.367...\n",
      "Step 24840 Training Accuracy 0.891... Training Loss 0.514...\n",
      "Step 24850 Training Accuracy 0.938... Training Loss 0.155...\n",
      "Step 24860 Training Accuracy 0.953... Training Loss 0.131...\n",
      "Step 24870 Training Accuracy 0.859... Training Loss 0.297...\n",
      "Step 24880 Training Accuracy 0.812... Training Loss 0.716...\n",
      "Step 24890 Training Accuracy 0.953... Training Loss 0.207...\n",
      "Step 24900 Training Accuracy 0.875... Training Loss 0.280...\n",
      "Step 24910 Training Accuracy 0.875... Training Loss 0.275...\n",
      "Step 24920 Training Accuracy 0.922... Training Loss 0.303...\n",
      "Step 24930 Training Accuracy 0.875... Training Loss 0.323...\n",
      "Step 24940 Training Accuracy 0.953... Training Loss 0.187...\n",
      "Step 24950 Training Accuracy 0.875... Training Loss 0.307...\n",
      "Step 24960 Training Accuracy 0.875... Training Loss 0.284...\n",
      "Step 24970 Training Accuracy 0.891... Training Loss 0.397...\n",
      "Step 24980 Training Accuracy 0.891... Training Loss 0.288...\n",
      "Step 24990 Training Accuracy 0.922... Training Loss 0.273...\n",
      "Step 25000 Training Accuracy 0.938... Training Loss 0.351...\n",
      "Writing checkpoint at step 25000\n",
      "Step 25010 Training Accuracy 0.906... Training Loss 0.238...\n",
      "Step 25020 Training Accuracy 0.938... Training Loss 0.276...\n",
      "Step 25030 Training Accuracy 0.922... Training Loss 0.279...\n",
      "Step 25040 Training Accuracy 0.891... Training Loss 0.195...\n",
      "Step 25050 Training Accuracy 0.859... Training Loss 0.228...\n",
      "Step 25060 Training Accuracy 0.828... Training Loss 0.563...\n",
      "Step 25070 Training Accuracy 0.938... Training Loss 0.245...\n",
      "Step 25080 Training Accuracy 0.938... Training Loss 0.242...\n",
      "Step 25090 Training Accuracy 0.953... Training Loss 0.238...\n",
      "Step 25100 Training Accuracy 0.953... Training Loss 0.218...\n",
      "Step 25110 Training Accuracy 0.938... Training Loss 0.333...\n",
      "Step 25120 Training Accuracy 0.938... Training Loss 0.277...\n",
      "Step 25130 Training Accuracy 0.922... Training Loss 0.187...\n",
      "Step 25140 Training Accuracy 0.859... Training Loss 0.347...\n",
      "Step 25150 Training Accuracy 0.859... Training Loss 0.316...\n",
      "Step 25160 Training Accuracy 0.891... Training Loss 0.270...\n",
      "Step 25170 Training Accuracy 0.859... Training Loss 0.339...\n",
      "Step 25180 Training Accuracy 0.922... Training Loss 0.250...\n",
      "Step 25190 Training Accuracy 0.859... Training Loss 0.279...\n",
      "Step 25200 Training Accuracy 0.859... Training Loss 0.455...\n",
      "Step 25210 Training Accuracy 0.844... Training Loss 0.690...\n",
      "Step 25220 Training Accuracy 0.875... Training Loss 0.241...\n",
      "Step 25230 Training Accuracy 0.812... Training Loss 0.332...\n",
      "Step 25240 Training Accuracy 0.906... Training Loss 0.295...\n",
      "Step 25250 Training Accuracy 0.875... Training Loss 0.365...\n",
      "Step 25260 Training Accuracy 0.938... Training Loss 0.195...\n",
      "Step 25270 Training Accuracy 0.922... Training Loss 0.272...\n",
      "Step 25280 Training Accuracy 0.875... Training Loss 0.310...\n",
      "Step 25290 Training Accuracy 0.875... Training Loss 0.342...\n",
      "Step 25300 Training Accuracy 0.938... Training Loss 0.231...\n",
      "Step 25310 Training Accuracy 0.891... Training Loss 0.433...\n",
      "Step 25320 Training Accuracy 0.922... Training Loss 0.217...\n",
      "Step 25330 Training Accuracy 0.922... Training Loss 0.273...\n",
      "Step 25340 Training Accuracy 0.797... Training Loss 0.637...\n",
      "Step 25350 Training Accuracy 0.891... Training Loss 0.310...\n",
      "Step 25360 Training Accuracy 0.922... Training Loss 0.236...\n",
      "Step 25370 Training Accuracy 0.953... Training Loss 0.188...\n",
      "Step 25380 Training Accuracy 0.812... Training Loss 0.447...\n",
      "Step 25390 Training Accuracy 0.938... Training Loss 0.181...\n",
      "Step 25400 Training Accuracy 0.906... Training Loss 0.407...\n",
      "Step 25410 Training Accuracy 0.812... Training Loss 0.413...\n",
      "Step 25420 Training Accuracy 0.922... Training Loss 0.280...\n",
      "Step 25430 Training Accuracy 0.953... Training Loss 0.422...\n",
      "Step 25440 Training Accuracy 0.844... Training Loss 0.371...\n",
      "Step 25450 Training Accuracy 0.828... Training Loss 0.501...\n",
      "Step 25460 Training Accuracy 0.906... Training Loss 0.295...\n",
      "Step 25470 Training Accuracy 0.906... Training Loss 0.346...\n",
      "Step 25480 Training Accuracy 0.812... Training Loss 0.461...\n",
      "Step 25490 Training Accuracy 0.922... Training Loss 0.241...\n",
      "Step 25500 Training Accuracy 0.953... Training Loss 0.403...\n",
      "Step 25510 Training Accuracy 0.922... Training Loss 0.230...\n",
      "Step 25520 Training Accuracy 0.969... Training Loss 0.102...\n",
      "Step 25530 Training Accuracy 0.891... Training Loss 0.346...\n",
      "Step 25540 Training Accuracy 0.953... Training Loss 0.334...\n",
      "Step 25550 Training Accuracy 0.906... Training Loss 0.302...\n",
      "Step 25560 Training Accuracy 0.906... Training Loss 0.412...\n",
      "Step 25570 Training Accuracy 0.922... Training Loss 0.358...\n",
      "Step 25580 Training Accuracy 0.875... Training Loss 0.210...\n",
      "Step 25590 Training Accuracy 0.906... Training Loss 0.227...\n",
      "Step 25600 Training Accuracy 0.906... Training Loss 0.265...\n",
      "Step 25610 Training Accuracy 0.953... Training Loss 0.212...\n",
      "Step 25620 Training Accuracy 0.938... Training Loss 0.220...\n",
      "Step 25630 Training Accuracy 0.797... Training Loss 0.601...\n",
      "Step 25640 Training Accuracy 0.906... Training Loss 0.246...\n",
      "Step 25650 Training Accuracy 0.781... Training Loss 0.470...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 25660 Training Accuracy 0.781... Training Loss 0.566...\n",
      "Step 25670 Training Accuracy 0.922... Training Loss 0.257...\n",
      "Step 25680 Training Accuracy 0.828... Training Loss 0.479...\n",
      "Step 25690 Training Accuracy 0.859... Training Loss 0.313...\n",
      "Step 25700 Training Accuracy 0.922... Training Loss 0.250...\n",
      "Step 25710 Training Accuracy 0.875... Training Loss 0.399...\n",
      "Step 25720 Training Accuracy 0.953... Training Loss 0.173...\n",
      "Step 25730 Training Accuracy 0.922... Training Loss 0.261...\n",
      "Step 25740 Training Accuracy 0.922... Training Loss 0.270...\n",
      "Step 25750 Training Accuracy 0.875... Training Loss 0.469...\n",
      "Step 25760 Training Accuracy 0.938... Training Loss 0.210...\n",
      "Step 25770 Training Accuracy 0.844... Training Loss 0.391...\n",
      "Step 25780 Training Accuracy 0.922... Training Loss 0.195...\n",
      "Step 25790 Training Accuracy 0.922... Training Loss 0.345...\n",
      "Step 25800 Training Accuracy 0.781... Training Loss 0.608...\n",
      "Step 25810 Training Accuracy 0.906... Training Loss 0.297...\n",
      "Step 25820 Training Accuracy 0.938... Training Loss 0.186...\n",
      "Step 25830 Training Accuracy 0.953... Training Loss 0.250...\n",
      "Step 25840 Training Accuracy 0.953... Training Loss 0.157...\n",
      "Step 25850 Training Accuracy 0.859... Training Loss 0.350...\n",
      "Step 25860 Training Accuracy 0.906... Training Loss 0.425...\n",
      "Step 25870 Training Accuracy 0.891... Training Loss 0.281...\n",
      "Step 25880 Training Accuracy 0.828... Training Loss 0.458...\n",
      "Step 25890 Training Accuracy 0.953... Training Loss 0.224...\n",
      "Step 25900 Training Accuracy 0.938... Training Loss 0.142...\n",
      "Step 25910 Training Accuracy 0.922... Training Loss 0.268...\n",
      "Step 25920 Training Accuracy 0.859... Training Loss 0.337...\n",
      "Step 25930 Training Accuracy 0.875... Training Loss 0.303...\n",
      "Step 25940 Training Accuracy 0.938... Training Loss 0.316...\n",
      "Step 25950 Training Accuracy 0.922... Training Loss 0.372...\n",
      "Step 25960 Training Accuracy 0.984... Training Loss 0.182...\n",
      "Step 25970 Training Accuracy 0.953... Training Loss 0.220...\n",
      "Step 25980 Training Accuracy 0.859... Training Loss 0.251...\n",
      "Step 25990 Training Accuracy 0.875... Training Loss 0.503...\n",
      "Step 26000 Training Accuracy 0.906... Training Loss 0.185...\n",
      "Writing checkpoint at step 26000\n",
      "Step 26010 Training Accuracy 0.859... Training Loss 0.465...\n",
      "Step 26020 Training Accuracy 0.953... Training Loss 0.200...\n",
      "Step 26030 Training Accuracy 0.922... Training Loss 0.334...\n",
      "Step 26040 Training Accuracy 0.906... Training Loss 0.277...\n",
      "Step 26050 Training Accuracy 0.875... Training Loss 0.356...\n",
      "Step 26060 Training Accuracy 0.859... Training Loss 0.303...\n",
      "Step 26070 Training Accuracy 0.875... Training Loss 0.417...\n",
      "Step 26080 Training Accuracy 0.922... Training Loss 0.322...\n",
      "Step 26090 Training Accuracy 0.922... Training Loss 0.260...\n",
      "Step 26100 Training Accuracy 0.844... Training Loss 0.271...\n",
      "Step 26110 Training Accuracy 0.938... Training Loss 0.193...\n",
      "Step 26120 Training Accuracy 0.906... Training Loss 0.324...\n",
      "Step 26130 Training Accuracy 0.906... Training Loss 0.249...\n",
      "Step 26140 Training Accuracy 0.844... Training Loss 0.384...\n",
      "Step 26150 Training Accuracy 0.922... Training Loss 0.278...\n",
      "Step 26160 Training Accuracy 0.859... Training Loss 0.382...\n",
      "Step 26170 Training Accuracy 0.906... Training Loss 0.201...\n",
      "Step 26180 Training Accuracy 0.859... Training Loss 0.446...\n",
      "Step 26190 Training Accuracy 0.922... Training Loss 0.165...\n",
      "Step 26200 Training Accuracy 0.859... Training Loss 0.297...\n",
      "Step 26210 Training Accuracy 0.875... Training Loss 0.339...\n",
      "Step 26220 Training Accuracy 0.938... Training Loss 0.180...\n",
      "Step 26230 Training Accuracy 0.891... Training Loss 0.348...\n",
      "Step 26240 Training Accuracy 0.891... Training Loss 0.292...\n",
      "Step 26250 Training Accuracy 0.906... Training Loss 0.267...\n",
      "Step 26260 Training Accuracy 0.938... Training Loss 0.167...\n",
      "Step 26270 Training Accuracy 0.859... Training Loss 0.389...\n",
      "Step 26280 Training Accuracy 0.938... Training Loss 0.349...\n",
      "Step 26290 Training Accuracy 0.922... Training Loss 0.356...\n",
      "Step 26300 Training Accuracy 0.922... Training Loss 0.203...\n",
      "Step 26310 Training Accuracy 0.844... Training Loss 0.404...\n",
      "Step 26320 Training Accuracy 0.875... Training Loss 0.388...\n",
      "Step 26330 Training Accuracy 0.875... Training Loss 0.475...\n",
      "Step 26340 Training Accuracy 0.922... Training Loss 0.271...\n",
      "Step 26350 Training Accuracy 0.875... Training Loss 0.482...\n",
      "Step 26360 Training Accuracy 0.859... Training Loss 0.429...\n",
      "Step 26370 Training Accuracy 0.891... Training Loss 0.304...\n",
      "Step 26380 Training Accuracy 0.875... Training Loss 0.270...\n",
      "Step 26390 Training Accuracy 0.906... Training Loss 0.213...\n",
      "Step 26400 Training Accuracy 0.938... Training Loss 0.211...\n",
      "Step 26410 Training Accuracy 0.875... Training Loss 0.203...\n",
      "Step 26420 Training Accuracy 0.859... Training Loss 0.285...\n",
      "Step 26430 Training Accuracy 0.875... Training Loss 0.309...\n",
      "Step 26440 Training Accuracy 0.844... Training Loss 0.489...\n",
      "Step 26450 Training Accuracy 0.844... Training Loss 0.744...\n",
      "Step 26460 Training Accuracy 0.922... Training Loss 0.319...\n",
      "Step 26470 Training Accuracy 0.906... Training Loss 0.212...\n",
      "Step 26480 Training Accuracy 0.844... Training Loss 0.435...\n",
      "Step 26490 Training Accuracy 0.859... Training Loss 0.400...\n",
      "Step 26500 Training Accuracy 0.891... Training Loss 0.334...\n",
      "Step 26510 Training Accuracy 0.891... Training Loss 0.287...\n",
      "Step 26520 Training Accuracy 0.922... Training Loss 0.360...\n",
      "Step 26530 Training Accuracy 0.844... Training Loss 0.426...\n",
      "Step 26540 Training Accuracy 0.891... Training Loss 0.496...\n",
      "Step 26550 Training Accuracy 0.922... Training Loss 0.243...\n",
      "Step 26560 Training Accuracy 0.891... Training Loss 0.392...\n",
      "Step 26570 Training Accuracy 0.859... Training Loss 0.376...\n",
      "Step 26580 Training Accuracy 0.953... Training Loss 0.234...\n",
      "Step 26590 Training Accuracy 0.906... Training Loss 0.342...\n",
      "Step 26600 Training Accuracy 0.828... Training Loss 0.417...\n",
      "Step 26610 Training Accuracy 0.938... Training Loss 0.358...\n",
      "Step 26620 Training Accuracy 0.938... Training Loss 0.187...\n",
      "Step 26630 Training Accuracy 0.875... Training Loss 0.506...\n",
      "Step 26640 Training Accuracy 0.875... Training Loss 0.546...\n",
      "Step 26650 Training Accuracy 0.891... Training Loss 0.363...\n",
      "Step 26660 Training Accuracy 0.906... Training Loss 0.342...\n",
      "Step 26670 Training Accuracy 0.828... Training Loss 0.448...\n",
      "Step 26680 Training Accuracy 0.875... Training Loss 0.373...\n",
      "Step 26690 Training Accuracy 0.875... Training Loss 0.346...\n",
      "Step 26700 Training Accuracy 0.812... Training Loss 0.351...\n",
      "Step 26710 Training Accuracy 0.797... Training Loss 0.565...\n",
      "Step 26720 Training Accuracy 0.953... Training Loss 0.340...\n",
      "Step 26730 Training Accuracy 0.953... Training Loss 0.132...\n",
      "Step 26740 Training Accuracy 0.922... Training Loss 0.197...\n",
      "Step 26750 Training Accuracy 0.891... Training Loss 0.307...\n",
      "Step 26760 Training Accuracy 0.906... Training Loss 0.262...\n",
      "Step 26770 Training Accuracy 0.875... Training Loss 0.469...\n",
      "Step 26780 Training Accuracy 0.953... Training Loss 0.278...\n",
      "Step 26790 Training Accuracy 0.938... Training Loss 0.253...\n",
      "Step 26800 Training Accuracy 0.859... Training Loss 0.462...\n",
      "Step 26810 Training Accuracy 0.906... Training Loss 0.270...\n",
      "Step 26820 Training Accuracy 0.938... Training Loss 0.274...\n",
      "Step 26830 Training Accuracy 0.953... Training Loss 0.223...\n",
      "Step 26840 Training Accuracy 0.906... Training Loss 0.292...\n",
      "Step 26850 Training Accuracy 0.844... Training Loss 0.320...\n",
      "Step 26860 Training Accuracy 0.812... Training Loss 0.454...\n",
      "Step 26870 Training Accuracy 0.938... Training Loss 0.273...\n",
      "Step 26880 Training Accuracy 0.938... Training Loss 0.217...\n",
      "Step 26890 Training Accuracy 0.938... Training Loss 0.346...\n",
      "Step 26900 Training Accuracy 0.969... Training Loss 0.302...\n",
      "Step 26910 Training Accuracy 0.969... Training Loss 0.128...\n",
      "Step 26920 Training Accuracy 0.922... Training Loss 0.205...\n",
      "Step 26930 Training Accuracy 0.891... Training Loss 0.326...\n",
      "Step 26940 Training Accuracy 0.922... Training Loss 0.434...\n",
      "Step 26950 Training Accuracy 0.938... Training Loss 0.211...\n",
      "Step 26960 Training Accuracy 0.984... Training Loss 0.122...\n",
      "Step 26970 Training Accuracy 0.938... Training Loss 0.163...\n",
      "Step 26980 Training Accuracy 0.812... Training Loss 0.456...\n",
      "Step 26990 Training Accuracy 0.891... Training Loss 0.445...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 27000 Training Accuracy 0.906... Training Loss 0.547...\n",
      "Writing checkpoint at step 27000\n",
      "Step 27010 Training Accuracy 0.859... Training Loss 0.462...\n",
      "Step 27020 Training Accuracy 0.953... Training Loss 0.244...\n",
      "Step 27030 Training Accuracy 0.922... Training Loss 0.300...\n",
      "Step 27040 Training Accuracy 0.875... Training Loss 0.328...\n",
      "Step 27050 Training Accuracy 0.938... Training Loss 0.155...\n",
      "Step 27060 Training Accuracy 0.875... Training Loss 0.569...\n",
      "Step 27070 Training Accuracy 0.859... Training Loss 0.507...\n",
      "Step 27080 Training Accuracy 0.906... Training Loss 0.259...\n",
      "Step 27090 Training Accuracy 0.859... Training Loss 0.348...\n",
      "Step 27100 Training Accuracy 0.906... Training Loss 0.145...\n",
      "Step 27110 Training Accuracy 0.891... Training Loss 0.284...\n",
      "Step 27120 Training Accuracy 0.828... Training Loss 0.798...\n",
      "Step 27130 Training Accuracy 0.875... Training Loss 0.317...\n",
      "Step 27140 Training Accuracy 0.922... Training Loss 0.296...\n",
      "Step 27150 Training Accuracy 0.922... Training Loss 0.159...\n",
      "Step 27160 Training Accuracy 0.922... Training Loss 0.265...\n",
      "Step 27170 Training Accuracy 0.922... Training Loss 0.364...\n",
      "Step 27180 Training Accuracy 0.906... Training Loss 0.303...\n",
      "Step 27190 Training Accuracy 0.859... Training Loss 0.361...\n",
      "Step 27200 Training Accuracy 0.938... Training Loss 0.241...\n",
      "Step 27210 Training Accuracy 0.859... Training Loss 0.361...\n",
      "Step 27220 Training Accuracy 0.891... Training Loss 0.245...\n",
      "Step 27230 Training Accuracy 0.875... Training Loss 0.438...\n",
      "Step 27240 Training Accuracy 0.891... Training Loss 0.326...\n",
      "Step 27250 Training Accuracy 0.938... Training Loss 0.182...\n",
      "Step 27260 Training Accuracy 0.953... Training Loss 0.198...\n",
      "Step 27270 Training Accuracy 0.875... Training Loss 0.267...\n",
      "Step 27280 Training Accuracy 0.828... Training Loss 0.454...\n",
      "Step 27290 Training Accuracy 0.922... Training Loss 0.346...\n",
      "Step 27300 Training Accuracy 0.953... Training Loss 0.137...\n",
      "Step 27310 Training Accuracy 0.875... Training Loss 0.411...\n",
      "Step 27320 Training Accuracy 0.828... Training Loss 0.379...\n",
      "Step 27330 Training Accuracy 0.922... Training Loss 0.119...\n",
      "Step 27340 Training Accuracy 0.953... Training Loss 0.195...\n",
      "Step 27350 Training Accuracy 0.938... Training Loss 0.183...\n",
      "Step 27360 Training Accuracy 0.922... Training Loss 0.168...\n",
      "Step 27370 Training Accuracy 0.875... Training Loss 0.259...\n",
      "Step 27380 Training Accuracy 0.891... Training Loss 0.276...\n",
      "Step 27390 Training Accuracy 0.906... Training Loss 0.249...\n",
      "Step 27400 Training Accuracy 0.906... Training Loss 0.362...\n",
      "Step 27410 Training Accuracy 0.906... Training Loss 0.313...\n",
      "Step 27420 Training Accuracy 0.922... Training Loss 0.300...\n",
      "Step 27430 Training Accuracy 0.891... Training Loss 0.291...\n",
      "Step 27440 Training Accuracy 0.875... Training Loss 0.329...\n",
      "Step 27450 Training Accuracy 0.922... Training Loss 0.148...\n",
      "Step 27460 Training Accuracy 0.922... Training Loss 0.143...\n",
      "Step 27470 Training Accuracy 0.922... Training Loss 0.193...\n",
      "Step 27480 Training Accuracy 0.953... Training Loss 0.107...\n",
      "Step 27490 Training Accuracy 0.906... Training Loss 0.216...\n",
      "Step 27500 Training Accuracy 0.969... Training Loss 0.154...\n",
      "Step 27510 Training Accuracy 0.859... Training Loss 0.349...\n",
      "Step 27520 Training Accuracy 0.953... Training Loss 0.264...\n",
      "Step 27530 Training Accuracy 0.859... Training Loss 0.282...\n",
      "Step 27540 Training Accuracy 0.953... Training Loss 0.195...\n",
      "Step 27550 Training Accuracy 0.922... Training Loss 0.307...\n",
      "Step 27560 Training Accuracy 0.938... Training Loss 0.148...\n",
      "Step 27570 Training Accuracy 0.922... Training Loss 0.257...\n",
      "Step 27580 Training Accuracy 0.812... Training Loss 0.493...\n",
      "Step 27590 Training Accuracy 0.891... Training Loss 0.239...\n",
      "Step 27600 Training Accuracy 0.906... Training Loss 0.330...\n",
      "Step 27610 Training Accuracy 0.938... Training Loss 0.253...\n",
      "Step 27620 Training Accuracy 0.891... Training Loss 0.310...\n",
      "Step 27630 Training Accuracy 0.938... Training Loss 0.279...\n",
      "Step 27640 Training Accuracy 0.906... Training Loss 0.340...\n",
      "Step 27650 Training Accuracy 0.922... Training Loss 0.364...\n",
      "Step 27660 Training Accuracy 0.844... Training Loss 0.411...\n",
      "Step 27670 Training Accuracy 0.906... Training Loss 0.328...\n",
      "Step 27680 Training Accuracy 0.844... Training Loss 0.495...\n",
      "Step 27690 Training Accuracy 0.859... Training Loss 0.397...\n",
      "Step 27700 Training Accuracy 0.875... Training Loss 0.429...\n",
      "Step 27710 Training Accuracy 0.891... Training Loss 0.230...\n",
      "Step 27720 Training Accuracy 0.844... Training Loss 0.354...\n",
      "Step 27730 Training Accuracy 0.938... Training Loss 0.121...\n",
      "Step 27740 Training Accuracy 0.922... Training Loss 0.213...\n",
      "Step 27750 Training Accuracy 0.922... Training Loss 0.245...\n",
      "Step 27760 Training Accuracy 0.938... Training Loss 0.174...\n",
      "Step 27770 Training Accuracy 0.875... Training Loss 0.362...\n",
      "Step 27780 Training Accuracy 0.953... Training Loss 0.225...\n",
      "Step 27790 Training Accuracy 0.953... Training Loss 0.160...\n",
      "Step 27800 Training Accuracy 0.922... Training Loss 0.183...\n",
      "Step 27810 Training Accuracy 0.859... Training Loss 0.205...\n",
      "Step 27820 Training Accuracy 0.828... Training Loss 0.440...\n",
      "Step 27830 Training Accuracy 0.922... Training Loss 0.156...\n",
      "Step 27840 Training Accuracy 0.953... Training Loss 0.226...\n",
      "Step 27850 Training Accuracy 0.953... Training Loss 0.285...\n",
      "Step 27860 Training Accuracy 0.828... Training Loss 0.386...\n",
      "Step 27870 Training Accuracy 0.906... Training Loss 0.387...\n",
      "Step 27880 Training Accuracy 0.922... Training Loss 0.194...\n",
      "Step 27890 Training Accuracy 0.938... Training Loss 0.189...\n",
      "Step 27900 Training Accuracy 0.891... Training Loss 0.242...\n",
      "Step 27910 Training Accuracy 0.953... Training Loss 0.144...\n",
      "Step 27920 Training Accuracy 0.891... Training Loss 0.412...\n",
      "Step 27930 Training Accuracy 0.859... Training Loss 0.275...\n",
      "Step 27940 Training Accuracy 0.922... Training Loss 0.256...\n",
      "Step 27950 Training Accuracy 0.906... Training Loss 0.350...\n",
      "Step 27960 Training Accuracy 0.969... Training Loss 0.137...\n",
      "Step 27970 Training Accuracy 0.938... Training Loss 0.172...\n",
      "Step 27980 Training Accuracy 0.938... Training Loss 0.252...\n",
      "Step 27990 Training Accuracy 0.891... Training Loss 0.262...\n",
      "Step 28000 Training Accuracy 0.938... Training Loss 0.137...\n",
      "Writing checkpoint at step 28000\n",
      "Step 28010 Training Accuracy 0.922... Training Loss 0.296...\n",
      "Step 28020 Training Accuracy 0.969... Training Loss 0.178...\n",
      "Step 28030 Training Accuracy 0.906... Training Loss 0.365...\n",
      "Step 28040 Training Accuracy 0.938... Training Loss 0.393...\n",
      "Step 28050 Training Accuracy 0.844... Training Loss 0.490...\n",
      "Step 28060 Training Accuracy 0.906... Training Loss 0.195...\n",
      "Step 28070 Training Accuracy 0.922... Training Loss 0.358...\n",
      "Step 28080 Training Accuracy 0.875... Training Loss 0.333...\n",
      "Step 28090 Training Accuracy 0.922... Training Loss 0.366...\n",
      "Step 28100 Training Accuracy 0.922... Training Loss 0.239...\n",
      "Step 28110 Training Accuracy 0.875... Training Loss 0.255...\n",
      "Step 28120 Training Accuracy 0.938... Training Loss 0.219...\n",
      "Step 28130 Training Accuracy 0.938... Training Loss 0.278...\n",
      "Step 28140 Training Accuracy 0.922... Training Loss 0.203...\n",
      "Step 28150 Training Accuracy 0.938... Training Loss 0.137...\n",
      "Step 28160 Training Accuracy 0.969... Training Loss 0.182...\n",
      "Step 28170 Training Accuracy 0.875... Training Loss 0.315...\n",
      "Step 28180 Training Accuracy 0.844... Training Loss 0.336...\n",
      "Step 28190 Training Accuracy 0.922... Training Loss 0.336...\n",
      "Step 28200 Training Accuracy 0.922... Training Loss 0.199...\n",
      "Step 28210 Training Accuracy 0.906... Training Loss 0.425...\n",
      "Step 28220 Training Accuracy 0.906... Training Loss 0.342...\n",
      "Step 28230 Training Accuracy 0.891... Training Loss 0.215...\n",
      "Step 28240 Training Accuracy 0.859... Training Loss 0.380...\n",
      "Step 28250 Training Accuracy 0.938... Training Loss 0.234...\n",
      "Step 28260 Training Accuracy 0.859... Training Loss 0.332...\n",
      "Step 28270 Training Accuracy 0.875... Training Loss 0.287...\n",
      "Step 28280 Training Accuracy 0.984... Training Loss 0.144...\n",
      "Step 28290 Training Accuracy 0.844... Training Loss 0.372...\n",
      "Step 28300 Training Accuracy 0.891... Training Loss 0.473...\n",
      "Step 28310 Training Accuracy 0.938... Training Loss 0.120...\n",
      "Step 28320 Training Accuracy 0.953... Training Loss 0.310...\n",
      "Step 28330 Training Accuracy 0.828... Training Loss 0.474...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 28340 Training Accuracy 0.875... Training Loss 0.380...\n",
      "Step 28350 Training Accuracy 0.891... Training Loss 0.359...\n",
      "Step 28360 Training Accuracy 0.938... Training Loss 0.194...\n",
      "Step 28370 Training Accuracy 0.922... Training Loss 0.295...\n",
      "Step 28380 Training Accuracy 0.969... Training Loss 0.240...\n",
      "Step 28390 Training Accuracy 0.938... Training Loss 0.124...\n",
      "Step 28400 Training Accuracy 0.828... Training Loss 0.435...\n",
      "Step 28410 Training Accuracy 0.906... Training Loss 0.271...\n",
      "Step 28420 Training Accuracy 0.922... Training Loss 0.131...\n",
      "Step 28430 Training Accuracy 0.859... Training Loss 0.329...\n",
      "Step 28440 Training Accuracy 0.906... Training Loss 0.346...\n",
      "Step 28450 Training Accuracy 0.922... Training Loss 0.327...\n",
      "Step 28460 Training Accuracy 0.984... Training Loss 0.123...\n",
      "Step 28470 Training Accuracy 0.953... Training Loss 0.281...\n",
      "Step 28480 Training Accuracy 0.922... Training Loss 0.339...\n",
      "Step 28490 Training Accuracy 0.906... Training Loss 0.252...\n",
      "Step 28500 Training Accuracy 0.922... Training Loss 0.235...\n",
      "Step 28510 Training Accuracy 0.859... Training Loss 0.538...\n",
      "Step 28520 Training Accuracy 0.922... Training Loss 0.154...\n",
      "Step 28530 Training Accuracy 0.891... Training Loss 0.337...\n",
      "Step 28540 Training Accuracy 0.891... Training Loss 0.258...\n",
      "Step 28550 Training Accuracy 0.906... Training Loss 0.293...\n",
      "Step 28560 Training Accuracy 0.938... Training Loss 0.134...\n",
      "Step 28570 Training Accuracy 0.891... Training Loss 0.308...\n",
      "Step 28580 Training Accuracy 0.906... Training Loss 0.376...\n",
      "Step 28590 Training Accuracy 0.969... Training Loss 0.282...\n",
      "Step 28600 Training Accuracy 0.875... Training Loss 0.401...\n",
      "Step 28610 Training Accuracy 0.906... Training Loss 0.480...\n",
      "Step 28620 Training Accuracy 0.953... Training Loss 0.056...\n",
      "Step 28630 Training Accuracy 0.875... Training Loss 0.327...\n",
      "Step 28640 Training Accuracy 0.828... Training Loss 0.273...\n",
      "Step 28650 Training Accuracy 0.875... Training Loss 0.493...\n",
      "Step 28660 Training Accuracy 0.859... Training Loss 0.248...\n",
      "Step 28670 Training Accuracy 0.906... Training Loss 0.256...\n",
      "Step 28680 Training Accuracy 0.938... Training Loss 0.179...\n",
      "Step 28690 Training Accuracy 0.922... Training Loss 0.267...\n",
      "Step 28700 Training Accuracy 0.906... Training Loss 0.347...\n",
      "Step 28710 Training Accuracy 0.906... Training Loss 0.393...\n",
      "Step 28720 Training Accuracy 0.906... Training Loss 0.335...\n",
      "Step 28730 Training Accuracy 0.938... Training Loss 0.343...\n",
      "Step 28740 Training Accuracy 0.922... Training Loss 0.426...\n",
      "Step 28750 Training Accuracy 0.891... Training Loss 0.342...\n",
      "Step 28760 Training Accuracy 0.953... Training Loss 0.314...\n",
      "Step 28770 Training Accuracy 0.938... Training Loss 0.192...\n",
      "Step 28780 Training Accuracy 0.906... Training Loss 0.184...\n",
      "Step 28790 Training Accuracy 0.828... Training Loss 0.323...\n",
      "Step 28800 Training Accuracy 0.891... Training Loss 0.284...\n",
      "Step 28810 Training Accuracy 0.859... Training Loss 0.514...\n",
      "Step 28820 Training Accuracy 0.922... Training Loss 0.336...\n",
      "Step 28830 Training Accuracy 0.922... Training Loss 0.266...\n",
      "Step 28840 Training Accuracy 0.938... Training Loss 0.130...\n",
      "Step 28850 Training Accuracy 0.922... Training Loss 0.304...\n",
      "Step 28860 Training Accuracy 0.938... Training Loss 0.215...\n",
      "Step 28870 Training Accuracy 0.875... Training Loss 0.329...\n",
      "Step 28880 Training Accuracy 0.906... Training Loss 0.347...\n",
      "Step 28890 Training Accuracy 0.891... Training Loss 0.190...\n",
      "Step 28900 Training Accuracy 0.859... Training Loss 0.515...\n",
      "Step 28910 Training Accuracy 0.969... Training Loss 0.190...\n",
      "Step 28920 Training Accuracy 0.906... Training Loss 0.310...\n",
      "Step 28930 Training Accuracy 0.938... Training Loss 0.166...\n",
      "Step 28940 Training Accuracy 0.938... Training Loss 0.270...\n",
      "Step 28950 Training Accuracy 0.969... Training Loss 0.245...\n",
      "Step 28960 Training Accuracy 0.938... Training Loss 0.197...\n",
      "Step 28970 Training Accuracy 0.875... Training Loss 0.317...\n",
      "Step 28980 Training Accuracy 0.891... Training Loss 0.512...\n",
      "Step 28990 Training Accuracy 0.891... Training Loss 0.334...\n",
      "Step 29000 Training Accuracy 0.969... Training Loss 0.216...\n",
      "Writing checkpoint at step 29000\n",
      "Step 29010 Training Accuracy 0.938... Training Loss 0.204...\n",
      "Step 29020 Training Accuracy 0.938... Training Loss 0.225...\n",
      "Step 29030 Training Accuracy 0.984... Training Loss 0.139...\n",
      "Step 29040 Training Accuracy 0.938... Training Loss 0.218...\n",
      "Step 29050 Training Accuracy 0.953... Training Loss 0.231...\n",
      "Step 29060 Training Accuracy 0.953... Training Loss 0.230...\n",
      "Step 29070 Training Accuracy 0.938... Training Loss 0.314...\n",
      "Step 29080 Training Accuracy 0.922... Training Loss 0.355...\n",
      "Step 29090 Training Accuracy 0.938... Training Loss 0.202...\n",
      "Step 29100 Training Accuracy 0.938... Training Loss 0.184...\n",
      "Step 29110 Training Accuracy 0.891... Training Loss 0.297...\n",
      "Step 29120 Training Accuracy 0.984... Training Loss 0.178...\n",
      "Step 29130 Training Accuracy 0.844... Training Loss 0.422...\n",
      "Step 29140 Training Accuracy 0.938... Training Loss 0.185...\n",
      "Step 29150 Training Accuracy 0.875... Training Loss 0.537...\n",
      "Step 29160 Training Accuracy 0.891... Training Loss 0.318...\n",
      "Step 29170 Training Accuracy 0.953... Training Loss 0.124...\n",
      "Step 29180 Training Accuracy 0.906... Training Loss 0.302...\n",
      "Step 29190 Training Accuracy 0.938... Training Loss 0.308...\n",
      "Step 29200 Training Accuracy 0.891... Training Loss 0.289...\n",
      "Step 29210 Training Accuracy 0.906... Training Loss 0.189...\n",
      "Step 29220 Training Accuracy 0.922... Training Loss 0.179...\n",
      "Step 29230 Training Accuracy 0.859... Training Loss 0.286...\n",
      "Step 29240 Training Accuracy 0.969... Training Loss 0.135...\n",
      "Step 29250 Training Accuracy 0.938... Training Loss 0.300...\n",
      "Step 29260 Training Accuracy 0.875... Training Loss 0.205...\n",
      "Step 29270 Training Accuracy 0.859... Training Loss 0.240...\n",
      "Step 29280 Training Accuracy 0.906... Training Loss 0.262...\n",
      "Step 29290 Training Accuracy 0.891... Training Loss 0.301...\n",
      "Step 29300 Training Accuracy 0.906... Training Loss 0.268...\n",
      "Step 29310 Training Accuracy 0.953... Training Loss 0.264...\n",
      "Step 29320 Training Accuracy 0.844... Training Loss 0.269...\n",
      "Step 29330 Training Accuracy 0.906... Training Loss 0.257...\n",
      "Step 29340 Training Accuracy 0.906... Training Loss 0.535...\n",
      "Step 29350 Training Accuracy 0.922... Training Loss 0.186...\n",
      "Step 29360 Training Accuracy 0.922... Training Loss 0.253...\n",
      "Step 29370 Training Accuracy 0.906... Training Loss 0.276...\n",
      "Step 29380 Training Accuracy 0.938... Training Loss 0.212...\n",
      "Step 29390 Training Accuracy 0.906... Training Loss 0.320...\n",
      "Step 29400 Training Accuracy 0.938... Training Loss 0.183...\n",
      "Step 29410 Training Accuracy 0.953... Training Loss 0.193...\n",
      "Step 29420 Training Accuracy 0.844... Training Loss 0.528...\n",
      "Step 29430 Training Accuracy 0.906... Training Loss 0.267...\n",
      "Step 29440 Training Accuracy 0.938... Training Loss 0.267...\n",
      "Step 29450 Training Accuracy 0.906... Training Loss 0.321...\n",
      "Step 29460 Training Accuracy 0.891... Training Loss 0.343...\n",
      "Step 29470 Training Accuracy 0.922... Training Loss 0.172...\n",
      "Step 29480 Training Accuracy 0.953... Training Loss 0.344...\n",
      "Step 29490 Training Accuracy 0.859... Training Loss 0.546...\n",
      "Step 29500 Training Accuracy 0.969... Training Loss 0.218...\n",
      "Step 29510 Training Accuracy 0.938... Training Loss 0.321...\n",
      "Step 29520 Training Accuracy 0.984... Training Loss 0.151...\n",
      "Step 29530 Training Accuracy 0.969... Training Loss 0.129...\n",
      "Step 29540 Training Accuracy 0.891... Training Loss 0.299...\n",
      "Step 29550 Training Accuracy 0.891... Training Loss 0.499...\n",
      "Step 29560 Training Accuracy 0.906... Training Loss 0.370...\n",
      "Step 29570 Training Accuracy 0.891... Training Loss 0.239...\n",
      "Step 29580 Training Accuracy 0.969... Training Loss 0.085...\n",
      "Step 29590 Training Accuracy 0.922... Training Loss 0.340...\n",
      "Step 29600 Training Accuracy 0.844... Training Loss 0.541...\n",
      "Step 29610 Training Accuracy 0.922... Training Loss 0.266...\n",
      "Step 29620 Training Accuracy 0.906... Training Loss 0.253...\n",
      "Step 29630 Training Accuracy 0.938... Training Loss 0.279...\n",
      "Step 29640 Training Accuracy 0.891... Training Loss 0.325...\n",
      "Step 29650 Training Accuracy 0.906... Training Loss 0.306...\n",
      "Step 29660 Training Accuracy 0.906... Training Loss 0.301...\n",
      "Step 29670 Training Accuracy 0.906... Training Loss 0.316...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 29680 Training Accuracy 0.828... Training Loss 0.850...\n",
      "Step 29690 Training Accuracy 0.953... Training Loss 0.248...\n",
      "Step 29700 Training Accuracy 0.969... Training Loss 0.042...\n",
      "Step 29710 Training Accuracy 0.938... Training Loss 0.211...\n",
      "Step 29720 Training Accuracy 0.938... Training Loss 0.134...\n",
      "Step 29730 Training Accuracy 0.922... Training Loss 0.167...\n",
      "Step 29740 Training Accuracy 0.953... Training Loss 0.232...\n",
      "Step 29750 Training Accuracy 0.953... Training Loss 0.260...\n",
      "Step 29760 Training Accuracy 0.875... Training Loss 0.416...\n",
      "Step 29770 Training Accuracy 0.891... Training Loss 0.290...\n",
      "Step 29780 Training Accuracy 0.922... Training Loss 0.310...\n",
      "Step 29790 Training Accuracy 0.891... Training Loss 0.324...\n",
      "Step 29800 Training Accuracy 0.953... Training Loss 0.215...\n",
      "Step 29810 Training Accuracy 0.875... Training Loss 0.362...\n",
      "Step 29820 Training Accuracy 0.906... Training Loss 0.452...\n",
      "Step 29830 Training Accuracy 0.891... Training Loss 0.245...\n",
      "Step 29840 Training Accuracy 0.922... Training Loss 0.307...\n",
      "Step 29850 Training Accuracy 0.969... Training Loss 0.192...\n",
      "Step 29860 Training Accuracy 0.938... Training Loss 0.228...\n",
      "Step 29870 Training Accuracy 0.938... Training Loss 0.290...\n",
      "Step 29880 Training Accuracy 0.891... Training Loss 0.349...\n",
      "Step 29890 Training Accuracy 0.906... Training Loss 0.174...\n",
      "Step 29900 Training Accuracy 0.938... Training Loss 0.202...\n",
      "Step 29910 Training Accuracy 0.938... Training Loss 0.166...\n",
      "Step 29920 Training Accuracy 0.953... Training Loss 0.234...\n",
      "Step 29930 Training Accuracy 0.875... Training Loss 0.413...\n",
      "Step 29940 Training Accuracy 0.906... Training Loss 0.321...\n",
      "Step 29950 Training Accuracy 0.875... Training Loss 0.428...\n",
      "Step 29960 Training Accuracy 0.922... Training Loss 0.226...\n",
      "Step 29970 Training Accuracy 0.922... Training Loss 0.243...\n",
      "Step 29980 Training Accuracy 0.922... Training Loss 0.335...\n",
      "Step 29990 Training Accuracy 0.891... Training Loss 0.374...\n",
      "Step 30000 Training Accuracy 0.906... Training Loss 0.316...\n",
      "Writing checkpoint at step 30000\n",
      "Step 30010 Training Accuracy 0.922... Training Loss 0.283...\n",
      "Step 30020 Training Accuracy 0.938... Training Loss 0.213...\n",
      "Step 30030 Training Accuracy 0.953... Training Loss 0.195...\n",
      "Step 30040 Training Accuracy 0.875... Training Loss 0.361...\n",
      "Step 30050 Training Accuracy 0.969... Training Loss 0.115...\n",
      "Step 30060 Training Accuracy 0.859... Training Loss 0.255...\n",
      "Step 30070 Training Accuracy 0.922... Training Loss 0.201...\n",
      "Step 30080 Training Accuracy 0.922... Training Loss 0.200...\n",
      "Step 30090 Training Accuracy 0.906... Training Loss 0.378...\n",
      "Step 30100 Training Accuracy 0.953... Training Loss 0.167...\n",
      "Step 30110 Training Accuracy 0.844... Training Loss 0.277...\n",
      "Step 30120 Training Accuracy 0.891... Training Loss 0.276...\n",
      "Step 30130 Training Accuracy 0.969... Training Loss 0.161...\n",
      "Step 30140 Training Accuracy 0.969... Training Loss 0.100...\n",
      "Step 30150 Training Accuracy 0.906... Training Loss 0.322...\n",
      "Step 30160 Training Accuracy 0.922... Training Loss 0.334...\n",
      "Step 30170 Training Accuracy 0.875... Training Loss 0.382...\n",
      "Step 30180 Training Accuracy 0.922... Training Loss 0.230...\n",
      "Step 30190 Training Accuracy 0.906... Training Loss 0.347...\n",
      "Step 30200 Training Accuracy 0.922... Training Loss 0.224...\n",
      "Step 30210 Training Accuracy 0.953... Training Loss 0.249...\n",
      "Step 30220 Training Accuracy 0.891... Training Loss 0.322...\n",
      "Step 30230 Training Accuracy 0.891... Training Loss 0.311...\n",
      "Step 30240 Training Accuracy 0.891... Training Loss 0.341...\n",
      "Step 30250 Training Accuracy 0.875... Training Loss 0.251...\n",
      "Step 30260 Training Accuracy 0.969... Training Loss 0.149...\n",
      "Step 30270 Training Accuracy 0.906... Training Loss 0.256...\n",
      "Step 30280 Training Accuracy 0.875... Training Loss 0.180...\n",
      "Step 30290 Training Accuracy 0.969... Training Loss 0.139...\n",
      "Step 30300 Training Accuracy 0.922... Training Loss 0.279...\n",
      "Step 30310 Training Accuracy 0.938... Training Loss 0.265...\n",
      "Step 30320 Training Accuracy 0.922... Training Loss 0.296...\n",
      "Step 30330 Training Accuracy 0.938... Training Loss 0.196...\n",
      "Step 30340 Training Accuracy 0.922... Training Loss 0.374...\n",
      "Step 30350 Training Accuracy 0.891... Training Loss 0.345...\n",
      "Step 30360 Training Accuracy 0.938... Training Loss 0.200...\n",
      "Step 30370 Training Accuracy 0.875... Training Loss 0.424...\n",
      "Step 30380 Training Accuracy 0.906... Training Loss 0.279...\n",
      "Step 30390 Training Accuracy 0.844... Training Loss 0.455...\n",
      "Step 30400 Training Accuracy 0.891... Training Loss 0.295...\n",
      "Step 30410 Training Accuracy 0.875... Training Loss 0.357...\n",
      "Step 30420 Training Accuracy 0.969... Training Loss 0.053...\n",
      "Step 30430 Training Accuracy 0.938... Training Loss 0.169...\n",
      "Step 30440 Training Accuracy 0.938... Training Loss 0.211...\n",
      "Step 30450 Training Accuracy 0.953... Training Loss 0.172...\n",
      "Step 30460 Training Accuracy 0.969... Training Loss 0.221...\n",
      "Step 30470 Training Accuracy 0.906... Training Loss 0.347...\n",
      "Step 30480 Training Accuracy 0.922... Training Loss 0.212...\n",
      "Step 30490 Training Accuracy 0.938... Training Loss 0.177...\n",
      "Step 30500 Training Accuracy 0.922... Training Loss 0.356...\n",
      "Step 30510 Training Accuracy 0.969... Training Loss 0.131...\n",
      "Step 30520 Training Accuracy 0.984... Training Loss 0.207...\n",
      "Step 30530 Training Accuracy 0.938... Training Loss 0.161...\n",
      "Step 30540 Training Accuracy 0.938... Training Loss 0.154...\n",
      "Step 30550 Training Accuracy 0.938... Training Loss 0.189...\n",
      "Step 30560 Training Accuracy 0.891... Training Loss 0.209...\n",
      "Step 30570 Training Accuracy 0.938... Training Loss 0.217...\n",
      "Step 30580 Training Accuracy 0.922... Training Loss 0.276...\n",
      "Step 30590 Training Accuracy 0.922... Training Loss 0.191...\n",
      "Step 30600 Training Accuracy 0.906... Training Loss 0.247...\n",
      "Step 30610 Training Accuracy 0.906... Training Loss 0.418...\n",
      "Step 30620 Training Accuracy 0.922... Training Loss 0.163...\n",
      "Step 30630 Training Accuracy 0.859... Training Loss 0.465...\n",
      "Step 30640 Training Accuracy 0.906... Training Loss 0.280...\n",
      "Step 30650 Training Accuracy 0.922... Training Loss 0.277...\n",
      "Step 30660 Training Accuracy 0.922... Training Loss 0.293...\n",
      "Step 30670 Training Accuracy 0.891... Training Loss 0.543...\n",
      "Step 30680 Training Accuracy 0.891... Training Loss 0.260...\n",
      "Step 30690 Training Accuracy 0.906... Training Loss 0.351...\n",
      "Step 30700 Training Accuracy 0.922... Training Loss 0.230...\n",
      "Step 30710 Training Accuracy 0.984... Training Loss 0.133...\n",
      "Step 30720 Training Accuracy 0.938... Training Loss 0.360...\n",
      "Step 30730 Training Accuracy 0.891... Training Loss 0.235...\n",
      "Step 30740 Training Accuracy 0.859... Training Loss 0.450...\n",
      "Step 30750 Training Accuracy 0.875... Training Loss 0.276...\n",
      "Step 30760 Training Accuracy 0.891... Training Loss 0.353...\n",
      "Step 30770 Training Accuracy 0.922... Training Loss 0.210...\n",
      "Step 30780 Training Accuracy 0.922... Training Loss 0.356...\n",
      "Step 30790 Training Accuracy 0.969... Training Loss 0.111...\n",
      "Step 30800 Training Accuracy 0.906... Training Loss 0.378...\n",
      "Step 30810 Training Accuracy 0.922... Training Loss 0.173...\n",
      "Step 30820 Training Accuracy 0.922... Training Loss 0.191...\n",
      "Step 30830 Training Accuracy 0.922... Training Loss 0.276...\n",
      "Step 30840 Training Accuracy 0.875... Training Loss 0.392...\n",
      "Step 30850 Training Accuracy 0.828... Training Loss 0.530...\n",
      "Step 30860 Training Accuracy 0.891... Training Loss 0.335...\n",
      "Step 30870 Training Accuracy 0.969... Training Loss 0.104...\n",
      "Step 30880 Training Accuracy 0.875... Training Loss 0.378...\n",
      "Step 30890 Training Accuracy 0.891... Training Loss 0.352...\n",
      "Step 30900 Training Accuracy 0.875... Training Loss 0.408...\n",
      "Step 30910 Training Accuracy 0.891... Training Loss 0.271...\n",
      "Step 30920 Training Accuracy 0.953... Training Loss 0.134...\n",
      "Step 30930 Training Accuracy 0.906... Training Loss 0.179...\n",
      "Step 30940 Training Accuracy 0.906... Training Loss 0.241...\n",
      "Step 30950 Training Accuracy 0.922... Training Loss 0.157...\n",
      "Step 30960 Training Accuracy 0.938... Training Loss 0.129...\n",
      "Step 30970 Training Accuracy 0.875... Training Loss 0.262...\n",
      "Step 30980 Training Accuracy 0.891... Training Loss 0.403...\n",
      "Step 30990 Training Accuracy 0.922... Training Loss 0.276...\n",
      "Step 31000 Training Accuracy 0.953... Training Loss 0.133...\n",
      "Writing checkpoint at step 31000\n",
      "Step 31010 Training Accuracy 0.969... Training Loss 0.205...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 31020 Training Accuracy 0.969... Training Loss 0.147...\n",
      "Step 31030 Training Accuracy 0.953... Training Loss 0.246...\n",
      "Step 31040 Training Accuracy 0.906... Training Loss 0.351...\n",
      "Step 31050 Training Accuracy 0.953... Training Loss 0.185...\n",
      "Step 31060 Training Accuracy 0.906... Training Loss 0.228...\n",
      "Step 31070 Training Accuracy 0.906... Training Loss 0.356...\n",
      "Step 31080 Training Accuracy 0.953... Training Loss 0.233...\n",
      "Step 31090 Training Accuracy 0.875... Training Loss 0.331...\n",
      "Step 31100 Training Accuracy 0.969... Training Loss 0.141...\n",
      "Step 31110 Training Accuracy 0.906... Training Loss 0.228...\n",
      "Step 31120 Training Accuracy 0.922... Training Loss 0.283...\n",
      "Step 31130 Training Accuracy 0.891... Training Loss 0.252...\n",
      "Step 31140 Training Accuracy 0.859... Training Loss 0.319...\n",
      "Step 31150 Training Accuracy 0.906... Training Loss 0.175...\n",
      "Step 31160 Training Accuracy 0.906... Training Loss 0.473...\n",
      "Step 31170 Training Accuracy 0.922... Training Loss 0.186...\n",
      "Step 31180 Training Accuracy 0.938... Training Loss 0.216...\n",
      "Step 31190 Training Accuracy 0.922... Training Loss 0.385...\n",
      "Step 31200 Training Accuracy 0.922... Training Loss 0.140...\n",
      "Step 31210 Training Accuracy 0.891... Training Loss 0.403...\n",
      "Step 31220 Training Accuracy 0.891... Training Loss 0.328...\n",
      "Step 31230 Training Accuracy 0.922... Training Loss 0.198...\n",
      "Step 31240 Training Accuracy 0.891... Training Loss 0.368...\n",
      "Step 31250 Training Accuracy 0.875... Training Loss 0.559...\n",
      "Step 31260 Training Accuracy 0.859... Training Loss 0.346...\n",
      "Step 31270 Training Accuracy 0.812... Training Loss 0.633...\n",
      "Step 31280 Training Accuracy 0.891... Training Loss 0.289...\n",
      "Step 31290 Training Accuracy 0.922... Training Loss 0.358...\n",
      "Step 31300 Training Accuracy 0.906... Training Loss 0.232...\n",
      "Step 31310 Training Accuracy 0.922... Training Loss 0.122...\n",
      "Step 31320 Training Accuracy 0.984... Training Loss 0.165...\n",
      "Step 31330 Training Accuracy 0.844... Training Loss 0.753...\n",
      "Step 31340 Training Accuracy 0.938... Training Loss 0.214...\n",
      "Step 31350 Training Accuracy 0.953... Training Loss 0.149...\n",
      "Step 31360 Training Accuracy 0.938... Training Loss 0.127...\n",
      "Step 31370 Training Accuracy 1.000... Training Loss 0.155...\n",
      "Step 31380 Training Accuracy 0.938... Training Loss 0.259...\n",
      "Step 31390 Training Accuracy 0.922... Training Loss 0.216...\n",
      "Step 31400 Training Accuracy 0.844... Training Loss 0.319...\n",
      "Step 31410 Training Accuracy 0.938... Training Loss 0.217...\n",
      "Step 31420 Training Accuracy 0.922... Training Loss 0.185...\n",
      "Step 31430 Training Accuracy 0.953... Training Loss 0.132...\n",
      "Step 31440 Training Accuracy 0.984... Training Loss 0.141...\n",
      "Step 31450 Training Accuracy 0.922... Training Loss 0.193...\n",
      "Step 31460 Training Accuracy 0.828... Training Loss 0.360...\n",
      "Step 31470 Training Accuracy 0.906... Training Loss 0.267...\n",
      "Step 31480 Training Accuracy 0.922... Training Loss 0.202...\n",
      "Step 31490 Training Accuracy 0.906... Training Loss 0.293...\n",
      "Step 31500 Training Accuracy 0.891... Training Loss 0.282...\n",
      "Step 31510 Training Accuracy 0.906... Training Loss 0.303...\n",
      "Step 31520 Training Accuracy 0.922... Training Loss 0.152...\n",
      "Step 31530 Training Accuracy 0.938... Training Loss 0.154...\n",
      "Step 31540 Training Accuracy 0.922... Training Loss 0.244...\n",
      "Step 31550 Training Accuracy 0.875... Training Loss 0.470...\n",
      "Step 31560 Training Accuracy 0.906... Training Loss 0.172...\n",
      "Step 31570 Training Accuracy 0.875... Training Loss 0.319...\n",
      "Step 31580 Training Accuracy 0.891... Training Loss 0.360...\n",
      "Step 31590 Training Accuracy 0.859... Training Loss 0.334...\n",
      "Step 31600 Training Accuracy 0.875... Training Loss 0.304...\n",
      "Step 31610 Training Accuracy 0.938... Training Loss 0.259...\n",
      "Step 31620 Training Accuracy 0.891... Training Loss 0.413...\n",
      "Step 31630 Training Accuracy 1.000... Training Loss 0.123...\n",
      "Step 31640 Training Accuracy 0.875... Training Loss 0.260...\n",
      "Step 31650 Training Accuracy 0.969... Training Loss 0.098...\n",
      "Step 31660 Training Accuracy 0.906... Training Loss 0.247...\n",
      "Step 31670 Training Accuracy 0.953... Training Loss 0.154...\n",
      "Step 31680 Training Accuracy 0.953... Training Loss 0.148...\n",
      "Step 31690 Training Accuracy 0.938... Training Loss 0.222...\n",
      "Step 31700 Training Accuracy 0.938... Training Loss 0.288...\n",
      "Step 31710 Training Accuracy 0.938... Training Loss 0.176...\n",
      "Step 31720 Training Accuracy 0.938... Training Loss 0.171...\n",
      "Step 31730 Training Accuracy 0.906... Training Loss 0.212...\n",
      "Step 31740 Training Accuracy 0.922... Training Loss 0.284...\n",
      "Step 31750 Training Accuracy 0.906... Training Loss 0.253...\n",
      "Step 31760 Training Accuracy 0.906... Training Loss 0.314...\n",
      "Step 31770 Training Accuracy 0.875... Training Loss 0.218...\n",
      "Step 31780 Training Accuracy 0.953... Training Loss 0.275...\n",
      "Step 31790 Training Accuracy 0.875... Training Loss 0.409...\n",
      "Step 31800 Training Accuracy 0.953... Training Loss 0.253...\n",
      "Step 31810 Training Accuracy 0.906... Training Loss 0.282...\n",
      "Step 31820 Training Accuracy 0.953... Training Loss 0.161...\n",
      "Step 31830 Training Accuracy 0.938... Training Loss 0.209...\n",
      "Step 31840 Training Accuracy 0.906... Training Loss 0.215...\n",
      "Step 31850 Training Accuracy 0.891... Training Loss 0.291...\n",
      "Step 31860 Training Accuracy 0.859... Training Loss 0.446...\n",
      "Step 31870 Training Accuracy 0.969... Training Loss 0.153...\n",
      "Step 31880 Training Accuracy 0.922... Training Loss 0.310...\n",
      "Step 31890 Training Accuracy 0.875... Training Loss 0.369...\n",
      "Step 31900 Training Accuracy 0.922... Training Loss 0.161...\n",
      "Step 31910 Training Accuracy 0.906... Training Loss 0.413...\n",
      "Step 31920 Training Accuracy 0.969... Training Loss 0.145...\n",
      "Step 31930 Training Accuracy 0.891... Training Loss 0.295...\n",
      "Step 31940 Training Accuracy 0.875... Training Loss 0.327...\n",
      "Step 31950 Training Accuracy 0.969... Training Loss 0.088...\n",
      "Step 31960 Training Accuracy 0.906... Training Loss 0.258...\n",
      "Step 31970 Training Accuracy 0.953... Training Loss 0.225...\n",
      "Step 31980 Training Accuracy 0.859... Training Loss 0.281...\n",
      "Step 31990 Training Accuracy 0.906... Training Loss 0.385...\n",
      "Step 32000 Training Accuracy 0.953... Training Loss 0.196...\n",
      "Writing checkpoint at step 32000\n",
      "Step 32010 Training Accuracy 0.859... Training Loss 0.204...\n",
      "Step 32020 Training Accuracy 0.922... Training Loss 0.238...\n",
      "Step 32030 Training Accuracy 0.922... Training Loss 0.287...\n",
      "Step 32040 Training Accuracy 0.891... Training Loss 0.286...\n",
      "Step 32050 Training Accuracy 0.938... Training Loss 0.194...\n",
      "Step 32060 Training Accuracy 0.984... Training Loss 0.107...\n",
      "Step 32070 Training Accuracy 0.922... Training Loss 0.249...\n",
      "Step 32080 Training Accuracy 0.938... Training Loss 0.151...\n",
      "Step 32090 Training Accuracy 0.859... Training Loss 0.348...\n",
      "Step 32100 Training Accuracy 0.953... Training Loss 0.174...\n",
      "Step 32110 Training Accuracy 0.953... Training Loss 0.177...\n",
      "Step 32120 Training Accuracy 0.938... Training Loss 0.243...\n",
      "Step 32130 Training Accuracy 0.969... Training Loss 0.179...\n",
      "Step 32140 Training Accuracy 0.984... Training Loss 0.101...\n",
      "Step 32150 Training Accuracy 0.969... Training Loss 0.134...\n",
      "Step 32160 Training Accuracy 0.969... Training Loss 0.145...\n",
      "Step 32170 Training Accuracy 0.891... Training Loss 0.378...\n",
      "Step 32180 Training Accuracy 0.938... Training Loss 0.144...\n",
      "Step 32190 Training Accuracy 0.953... Training Loss 0.159...\n",
      "Step 32200 Training Accuracy 0.906... Training Loss 0.293...\n",
      "Step 32210 Training Accuracy 0.859... Training Loss 0.407...\n",
      "Step 32220 Training Accuracy 0.906... Training Loss 0.321...\n",
      "Step 32230 Training Accuracy 0.922... Training Loss 0.266...\n",
      "Step 32240 Training Accuracy 0.906... Training Loss 0.169...\n",
      "Step 32250 Training Accuracy 0.953... Training Loss 0.143...\n",
      "Step 32260 Training Accuracy 0.969... Training Loss 0.108...\n",
      "Step 32270 Training Accuracy 0.906... Training Loss 0.270...\n",
      "Step 32280 Training Accuracy 0.984... Training Loss 0.108...\n",
      "Step 32290 Training Accuracy 0.938... Training Loss 0.123...\n",
      "Step 32300 Training Accuracy 0.875... Training Loss 0.467...\n",
      "Step 32310 Training Accuracy 0.953... Training Loss 0.168...\n",
      "Step 32320 Training Accuracy 0.969... Training Loss 0.320...\n",
      "Step 32330 Training Accuracy 0.906... Training Loss 0.307...\n",
      "Step 32340 Training Accuracy 0.953... Training Loss 0.114...\n",
      "Step 32350 Training Accuracy 0.938... Training Loss 0.147...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 32360 Training Accuracy 0.938... Training Loss 0.220...\n",
      "Step 32370 Training Accuracy 0.969... Training Loss 0.133...\n",
      "Step 32380 Training Accuracy 0.844... Training Loss 0.423...\n",
      "Step 32390 Training Accuracy 0.969... Training Loss 0.119...\n",
      "Step 32400 Training Accuracy 0.953... Training Loss 0.237...\n",
      "Step 32410 Training Accuracy 0.953... Training Loss 0.262...\n",
      "Step 32420 Training Accuracy 0.922... Training Loss 0.262...\n",
      "Step 32430 Training Accuracy 0.875... Training Loss 0.273...\n",
      "Step 32440 Training Accuracy 0.938... Training Loss 0.219...\n",
      "Step 32450 Training Accuracy 0.953... Training Loss 0.208...\n",
      "Step 32460 Training Accuracy 0.891... Training Loss 0.360...\n",
      "Step 32470 Training Accuracy 0.969... Training Loss 0.198...\n",
      "Step 32480 Training Accuracy 0.938... Training Loss 0.288...\n",
      "Step 32490 Training Accuracy 0.938... Training Loss 0.139...\n",
      "Step 32500 Training Accuracy 0.906... Training Loss 0.393...\n",
      "Step 32510 Training Accuracy 0.938... Training Loss 0.160...\n",
      "Step 32520 Training Accuracy 0.922... Training Loss 0.296...\n",
      "Step 32530 Training Accuracy 0.922... Training Loss 0.343...\n",
      "Step 32540 Training Accuracy 0.969... Training Loss 0.127...\n",
      "Step 32550 Training Accuracy 0.844... Training Loss 0.382...\n",
      "Step 32560 Training Accuracy 0.922... Training Loss 0.186...\n",
      "Step 32570 Training Accuracy 0.922... Training Loss 0.383...\n",
      "Step 32580 Training Accuracy 0.953... Training Loss 0.176...\n",
      "Step 32590 Training Accuracy 0.969... Training Loss 0.156...\n",
      "Step 32600 Training Accuracy 0.938... Training Loss 0.201...\n",
      "Step 32610 Training Accuracy 0.953... Training Loss 0.218...\n",
      "Step 32620 Training Accuracy 0.859... Training Loss 0.378...\n",
      "Step 32630 Training Accuracy 0.906... Training Loss 0.361...\n",
      "Step 32640 Training Accuracy 0.906... Training Loss 0.243...\n",
      "Step 32650 Training Accuracy 0.953... Training Loss 0.199...\n",
      "Step 32660 Training Accuracy 0.938... Training Loss 0.122...\n",
      "Step 32670 Training Accuracy 0.938... Training Loss 0.160...\n",
      "Step 32680 Training Accuracy 0.953... Training Loss 0.334...\n",
      "Step 32690 Training Accuracy 0.906... Training Loss 0.340...\n",
      "Step 32700 Training Accuracy 0.922... Training Loss 0.287...\n",
      "Step 32710 Training Accuracy 0.922... Training Loss 0.206...\n",
      "Step 32720 Training Accuracy 0.797... Training Loss 0.360...\n",
      "Step 32730 Training Accuracy 0.922... Training Loss 0.223...\n",
      "Step 32740 Training Accuracy 0.953... Training Loss 0.280...\n",
      "Step 32750 Training Accuracy 0.906... Training Loss 0.180...\n",
      "Step 32760 Training Accuracy 0.922... Training Loss 0.201...\n",
      "Step 32770 Training Accuracy 0.953... Training Loss 0.147...\n",
      "Step 32780 Training Accuracy 0.875... Training Loss 0.418...\n",
      "Step 32790 Training Accuracy 0.906... Training Loss 0.305...\n",
      "Step 32800 Training Accuracy 0.891... Training Loss 0.168...\n",
      "Step 32810 Training Accuracy 0.969... Training Loss 0.133...\n",
      "Step 32820 Training Accuracy 0.938... Training Loss 0.168...\n",
      "Step 32830 Training Accuracy 0.906... Training Loss 0.203...\n",
      "Step 32840 Training Accuracy 0.875... Training Loss 0.225...\n",
      "Step 32850 Training Accuracy 0.891... Training Loss 0.354...\n",
      "Step 32860 Training Accuracy 0.891... Training Loss 0.237...\n",
      "Step 32870 Training Accuracy 0.906... Training Loss 0.168...\n",
      "Step 32880 Training Accuracy 0.938... Training Loss 0.195...\n",
      "Step 32890 Training Accuracy 0.938... Training Loss 0.218...\n",
      "Step 32900 Training Accuracy 0.922... Training Loss 0.209...\n",
      "Step 32910 Training Accuracy 0.922... Training Loss 0.158...\n",
      "Step 32920 Training Accuracy 0.875... Training Loss 0.273...\n",
      "Step 32930 Training Accuracy 0.984... Training Loss 0.167...\n",
      "Step 32940 Training Accuracy 0.875... Training Loss 0.421...\n",
      "Step 32950 Training Accuracy 0.906... Training Loss 0.225...\n",
      "Step 32960 Training Accuracy 0.984... Training Loss 0.111...\n",
      "Step 32970 Training Accuracy 0.984... Training Loss 0.209...\n",
      "Step 32980 Training Accuracy 0.906... Training Loss 0.180...\n",
      "Step 32990 Training Accuracy 0.938... Training Loss 0.250...\n",
      "Step 33000 Training Accuracy 0.984... Training Loss 0.101...\n",
      "Writing checkpoint at step 33000\n",
      "Step 33010 Training Accuracy 0.922... Training Loss 0.284...\n",
      "Step 33020 Training Accuracy 0.953... Training Loss 0.144...\n",
      "Step 33030 Training Accuracy 0.953... Training Loss 0.165...\n",
      "Step 33040 Training Accuracy 0.953... Training Loss 0.182...\n",
      "Step 33050 Training Accuracy 0.969... Training Loss 0.128...\n",
      "Step 33060 Training Accuracy 0.953... Training Loss 0.247...\n",
      "Step 33070 Training Accuracy 0.922... Training Loss 0.406...\n",
      "Step 33080 Training Accuracy 0.953... Training Loss 0.128...\n",
      "Step 33090 Training Accuracy 0.938... Training Loss 0.118...\n",
      "Step 33100 Training Accuracy 0.984... Training Loss 0.069...\n",
      "Step 33110 Training Accuracy 0.906... Training Loss 0.203...\n",
      "Step 33120 Training Accuracy 0.922... Training Loss 0.199...\n",
      "Step 33130 Training Accuracy 0.844... Training Loss 0.372...\n",
      "Step 33140 Training Accuracy 0.906... Training Loss 0.196...\n",
      "Step 33150 Training Accuracy 0.922... Training Loss 0.218...\n",
      "Step 33160 Training Accuracy 0.891... Training Loss 0.387...\n",
      "Step 33170 Training Accuracy 0.906... Training Loss 0.210...\n",
      "Step 33180 Training Accuracy 0.922... Training Loss 0.232...\n",
      "Step 33190 Training Accuracy 0.984... Training Loss 0.134...\n",
      "Step 33200 Training Accuracy 0.844... Training Loss 0.366...\n",
      "Step 33210 Training Accuracy 0.906... Training Loss 0.216...\n",
      "Step 33220 Training Accuracy 0.969... Training Loss 0.096...\n",
      "Step 33230 Training Accuracy 0.859... Training Loss 0.440...\n",
      "Step 33240 Training Accuracy 0.922... Training Loss 0.236...\n",
      "Step 33250 Training Accuracy 0.844... Training Loss 0.404...\n",
      "Step 33260 Training Accuracy 0.938... Training Loss 0.211...\n",
      "Step 33270 Training Accuracy 0.922... Training Loss 0.182...\n",
      "Step 33280 Training Accuracy 0.922... Training Loss 0.179...\n",
      "Step 33290 Training Accuracy 0.891... Training Loss 0.438...\n",
      "Step 33300 Training Accuracy 0.922... Training Loss 0.159...\n",
      "Step 33310 Training Accuracy 0.922... Training Loss 0.267...\n",
      "Step 33320 Training Accuracy 0.922... Training Loss 0.281...\n",
      "Step 33330 Training Accuracy 0.953... Training Loss 0.183...\n",
      "Step 33340 Training Accuracy 0.969... Training Loss 0.180...\n",
      "Step 33350 Training Accuracy 0.875... Training Loss 0.236...\n",
      "Step 33360 Training Accuracy 0.938... Training Loss 0.145...\n",
      "Step 33370 Training Accuracy 0.922... Training Loss 0.291...\n",
      "Step 33380 Training Accuracy 0.906... Training Loss 0.211...\n",
      "Step 33390 Training Accuracy 0.969... Training Loss 0.172...\n",
      "Step 33400 Training Accuracy 0.953... Training Loss 0.202...\n",
      "Step 33410 Training Accuracy 0.891... Training Loss 0.196...\n",
      "Step 33420 Training Accuracy 0.922... Training Loss 0.108...\n",
      "Step 33430 Training Accuracy 0.984... Training Loss 0.132...\n",
      "Step 33440 Training Accuracy 0.844... Training Loss 0.385...\n",
      "Step 33450 Training Accuracy 0.875... Training Loss 0.553...\n",
      "Step 33460 Training Accuracy 0.984... Training Loss 0.136...\n",
      "Step 33470 Training Accuracy 0.906... Training Loss 0.304...\n",
      "Step 33480 Training Accuracy 0.891... Training Loss 0.321...\n",
      "Step 33490 Training Accuracy 0.875... Training Loss 0.257...\n",
      "Step 33500 Training Accuracy 0.906... Training Loss 0.225...\n",
      "Step 33510 Training Accuracy 0.922... Training Loss 0.211...\n",
      "Step 33520 Training Accuracy 0.938... Training Loss 0.162...\n",
      "Step 33530 Training Accuracy 0.906... Training Loss 0.139...\n",
      "Step 33540 Training Accuracy 0.969... Training Loss 0.100...\n",
      "Step 33550 Training Accuracy 0.922... Training Loss 0.272...\n",
      "Step 33560 Training Accuracy 0.938... Training Loss 0.221...\n",
      "Step 33570 Training Accuracy 0.938... Training Loss 0.184...\n",
      "Step 33580 Training Accuracy 0.922... Training Loss 0.150...\n",
      "Step 33590 Training Accuracy 0.922... Training Loss 0.207...\n",
      "Step 33600 Training Accuracy 0.844... Training Loss 0.481...\n",
      "Step 33610 Training Accuracy 0.938... Training Loss 0.228...\n",
      "Step 33620 Training Accuracy 0.938... Training Loss 0.187...\n",
      "Step 33630 Training Accuracy 0.953... Training Loss 0.286...\n",
      "Step 33640 Training Accuracy 0.922... Training Loss 0.443...\n",
      "Step 33650 Training Accuracy 0.984... Training Loss 0.100...\n",
      "Step 33660 Training Accuracy 0.844... Training Loss 0.281...\n",
      "Step 33670 Training Accuracy 0.922... Training Loss 0.250...\n",
      "Step 33680 Training Accuracy 0.969... Training Loss 0.092...\n",
      "Step 33690 Training Accuracy 0.922... Training Loss 0.299...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 33700 Training Accuracy 0.891... Training Loss 0.210...\n",
      "Step 33710 Training Accuracy 0.875... Training Loss 0.268...\n",
      "Step 33720 Training Accuracy 0.906... Training Loss 0.394...\n",
      "Step 33730 Training Accuracy 0.891... Training Loss 0.411...\n",
      "Step 33740 Training Accuracy 0.906... Training Loss 0.221...\n",
      "Step 33750 Training Accuracy 0.953... Training Loss 0.212...\n",
      "Step 33760 Training Accuracy 0.969... Training Loss 0.153...\n",
      "Step 33770 Training Accuracy 0.891... Training Loss 0.180...\n",
      "Step 33780 Training Accuracy 0.938... Training Loss 0.157...\n",
      "Step 33790 Training Accuracy 0.969... Training Loss 0.162...\n",
      "Step 33800 Training Accuracy 0.891... Training Loss 0.246...\n",
      "Step 33810 Training Accuracy 0.906... Training Loss 0.192...\n",
      "Step 33820 Training Accuracy 0.938... Training Loss 0.235...\n",
      "Step 33830 Training Accuracy 0.953... Training Loss 0.190...\n",
      "Step 33840 Training Accuracy 0.938... Training Loss 0.341...\n",
      "Step 33850 Training Accuracy 0.906... Training Loss 0.225...\n",
      "Step 33860 Training Accuracy 0.953... Training Loss 0.220...\n",
      "Step 33870 Training Accuracy 0.891... Training Loss 0.287...\n",
      "Step 33880 Training Accuracy 0.875... Training Loss 0.377...\n",
      "Step 33890 Training Accuracy 0.969... Training Loss 0.319...\n",
      "Step 33900 Training Accuracy 0.953... Training Loss 0.115...\n",
      "Step 33910 Training Accuracy 0.938... Training Loss 0.167...\n",
      "Step 33920 Training Accuracy 0.969... Training Loss 0.100...\n",
      "Step 33930 Training Accuracy 0.891... Training Loss 0.385...\n",
      "Step 33940 Training Accuracy 0.953... Training Loss 0.194...\n",
      "Step 33950 Training Accuracy 0.922... Training Loss 0.184...\n",
      "Step 33960 Training Accuracy 0.969... Training Loss 0.198...\n",
      "Step 33970 Training Accuracy 0.922... Training Loss 0.219...\n",
      "Step 33980 Training Accuracy 0.938... Training Loss 0.225...\n",
      "Step 33990 Training Accuracy 0.984... Training Loss 0.135...\n",
      "Step 34000 Training Accuracy 0.906... Training Loss 0.227...\n",
      "Writing checkpoint at step 34000\n",
      "Step 34010 Training Accuracy 0.969... Training Loss 0.180...\n",
      "Step 34020 Training Accuracy 0.922... Training Loss 0.187...\n",
      "Step 34030 Training Accuracy 0.922... Training Loss 0.245...\n",
      "Step 34040 Training Accuracy 0.953... Training Loss 0.224...\n",
      "Step 34050 Training Accuracy 0.969... Training Loss 0.127...\n",
      "Step 34060 Training Accuracy 0.938... Training Loss 0.271...\n",
      "Step 34070 Training Accuracy 0.891... Training Loss 0.342...\n",
      "Step 34080 Training Accuracy 0.891... Training Loss 0.340...\n",
      "Step 34090 Training Accuracy 0.906... Training Loss 0.247...\n",
      "Step 34100 Training Accuracy 0.969... Training Loss 0.297...\n",
      "Step 34110 Training Accuracy 0.953... Training Loss 0.213...\n",
      "Step 34120 Training Accuracy 0.875... Training Loss 0.134...\n",
      "Step 34130 Training Accuracy 0.906... Training Loss 0.334...\n",
      "Step 34140 Training Accuracy 0.906... Training Loss 0.256...\n",
      "Step 34150 Training Accuracy 0.984... Training Loss 0.115...\n",
      "Step 34160 Training Accuracy 0.938... Training Loss 0.273...\n",
      "Step 34170 Training Accuracy 0.938... Training Loss 0.224...\n",
      "Step 34180 Training Accuracy 0.969... Training Loss 0.147...\n",
      "Step 34190 Training Accuracy 0.953... Training Loss 0.090...\n",
      "Step 34200 Training Accuracy 0.922... Training Loss 0.381...\n",
      "Step 34210 Training Accuracy 0.922... Training Loss 0.188...\n",
      "Step 34220 Training Accuracy 0.984... Training Loss 0.073...\n",
      "Step 34230 Training Accuracy 0.906... Training Loss 0.329...\n",
      "Step 34240 Training Accuracy 0.984... Training Loss 0.065...\n",
      "Step 34250 Training Accuracy 0.969... Training Loss 0.149...\n",
      "Step 34260 Training Accuracy 0.969... Training Loss 0.163...\n",
      "Step 34270 Training Accuracy 0.938... Training Loss 0.093...\n",
      "Step 34280 Training Accuracy 0.938... Training Loss 0.290...\n",
      "Step 34290 Training Accuracy 0.828... Training Loss 0.560...\n",
      "Step 34300 Training Accuracy 0.938... Training Loss 0.109...\n",
      "Step 34310 Training Accuracy 0.984... Training Loss 0.204...\n",
      "Step 34320 Training Accuracy 0.922... Training Loss 0.176...\n",
      "Step 34330 Training Accuracy 0.922... Training Loss 0.261...\n",
      "Step 34340 Training Accuracy 0.953... Training Loss 0.116...\n",
      "Step 34350 Training Accuracy 0.906... Training Loss 0.130...\n",
      "Step 34360 Training Accuracy 0.922... Training Loss 0.338...\n",
      "Step 34370 Training Accuracy 0.906... Training Loss 0.263...\n",
      "Step 34380 Training Accuracy 0.859... Training Loss 0.387...\n",
      "Step 34390 Training Accuracy 0.922... Training Loss 0.274...\n",
      "Step 34400 Training Accuracy 0.859... Training Loss 0.362...\n",
      "Step 34410 Training Accuracy 0.891... Training Loss 0.264...\n",
      "Step 34420 Training Accuracy 0.906... Training Loss 0.165...\n",
      "Step 34430 Training Accuracy 1.000... Training Loss 0.091...\n",
      "Step 34440 Training Accuracy 0.953... Training Loss 0.227...\n",
      "Step 34450 Training Accuracy 0.938... Training Loss 0.203...\n",
      "Step 34460 Training Accuracy 0.922... Training Loss 0.272...\n",
      "Step 34470 Training Accuracy 0.969... Training Loss 0.138...\n",
      "Step 34480 Training Accuracy 0.984... Training Loss 0.073...\n",
      "Step 34490 Training Accuracy 0.969... Training Loss 0.216...\n",
      "Step 34500 Training Accuracy 0.938... Training Loss 0.231...\n",
      "Step 34510 Training Accuracy 0.922... Training Loss 0.262...\n",
      "Step 34520 Training Accuracy 0.953... Training Loss 0.215...\n",
      "Step 34530 Training Accuracy 0.969... Training Loss 0.131...\n",
      "Step 34540 Training Accuracy 0.953... Training Loss 0.189...\n",
      "Step 34550 Training Accuracy 0.922... Training Loss 0.362...\n",
      "Step 34560 Training Accuracy 0.938... Training Loss 0.201...\n",
      "Step 34570 Training Accuracy 0.922... Training Loss 0.305...\n",
      "Step 34580 Training Accuracy 0.953... Training Loss 0.221...\n",
      "Step 34590 Training Accuracy 0.922... Training Loss 0.466...\n",
      "Step 34600 Training Accuracy 0.953... Training Loss 0.194...\n",
      "Step 34610 Training Accuracy 0.969... Training Loss 0.138...\n",
      "Step 34620 Training Accuracy 0.953... Training Loss 0.182...\n",
      "Step 34630 Training Accuracy 0.984... Training Loss 0.121...\n",
      "Step 34640 Training Accuracy 0.938... Training Loss 0.189...\n",
      "Step 34650 Training Accuracy 0.922... Training Loss 0.264...\n",
      "Step 34660 Training Accuracy 0.969... Training Loss 0.157...\n",
      "Step 34670 Training Accuracy 0.906... Training Loss 0.388...\n",
      "Step 34680 Training Accuracy 0.906... Training Loss 0.344...\n",
      "Step 34690 Training Accuracy 0.906... Training Loss 0.320...\n",
      "Step 34700 Training Accuracy 0.953... Training Loss 0.171...\n",
      "Step 34710 Training Accuracy 0.922... Training Loss 0.207...\n",
      "Step 34720 Training Accuracy 0.875... Training Loss 0.365...\n",
      "Step 34730 Training Accuracy 0.906... Training Loss 0.183...\n",
      "Step 34740 Training Accuracy 0.906... Training Loss 0.288...\n",
      "Step 34750 Training Accuracy 0.953... Training Loss 0.091...\n",
      "Step 34760 Training Accuracy 0.969... Training Loss 0.129...\n",
      "Step 34770 Training Accuracy 0.953... Training Loss 0.177...\n",
      "Step 34780 Training Accuracy 0.922... Training Loss 0.634...\n",
      "Step 34790 Training Accuracy 0.938... Training Loss 0.108...\n",
      "Step 34800 Training Accuracy 0.969... Training Loss 0.065...\n",
      "Step 34810 Training Accuracy 0.938... Training Loss 0.147...\n",
      "Step 34820 Training Accuracy 0.938... Training Loss 0.118...\n",
      "Step 34830 Training Accuracy 0.906... Training Loss 0.108...\n",
      "Step 34840 Training Accuracy 0.953... Training Loss 0.130...\n",
      "Step 34850 Training Accuracy 0.953... Training Loss 0.203...\n",
      "Step 34860 Training Accuracy 0.969... Training Loss 0.105...\n",
      "Step 34870 Training Accuracy 0.953... Training Loss 0.071...\n",
      "Step 34880 Training Accuracy 0.938... Training Loss 0.221...\n",
      "Step 34890 Training Accuracy 0.938... Training Loss 0.162...\n",
      "Step 34900 Training Accuracy 0.906... Training Loss 0.190...\n",
      "Step 34910 Training Accuracy 0.906... Training Loss 0.370...\n",
      "Step 34920 Training Accuracy 0.953... Training Loss 0.220...\n",
      "Step 34930 Training Accuracy 0.938... Training Loss 0.181...\n",
      "Step 34940 Training Accuracy 0.984... Training Loss 0.098...\n",
      "Step 34950 Training Accuracy 0.906... Training Loss 0.422...\n",
      "Step 34960 Training Accuracy 0.938... Training Loss 0.275...\n",
      "Step 34970 Training Accuracy 0.906... Training Loss 0.265...\n",
      "Step 34980 Training Accuracy 0.922... Training Loss 0.185...\n",
      "Step 34990 Training Accuracy 0.953... Training Loss 0.189...\n",
      "Step 35000 Training Accuracy 0.938... Training Loss 0.224...\n",
      "Writing checkpoint at step 35000\n",
      "Step 35010 Training Accuracy 0.906... Training Loss 0.287...\n",
      "Step 35020 Training Accuracy 0.938... Training Loss 0.275...\n",
      "Step 35030 Training Accuracy 0.922... Training Loss 0.279...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 35040 Training Accuracy 0.969... Training Loss 0.044...\n",
      "Step 35050 Training Accuracy 0.906... Training Loss 0.285...\n",
      "Step 35060 Training Accuracy 0.922... Training Loss 0.187...\n",
      "Step 35070 Training Accuracy 0.922... Training Loss 0.249...\n",
      "Step 35080 Training Accuracy 0.984... Training Loss 0.093...\n",
      "Step 35090 Training Accuracy 0.969... Training Loss 0.063...\n",
      "Step 35100 Training Accuracy 0.984... Training Loss 0.096...\n",
      "Step 35110 Training Accuracy 0.938... Training Loss 0.325...\n",
      "Step 35120 Training Accuracy 0.984... Training Loss 0.090...\n",
      "Step 35130 Training Accuracy 0.969... Training Loss 0.079...\n",
      "Step 35140 Training Accuracy 0.969... Training Loss 0.106...\n",
      "Step 35150 Training Accuracy 0.875... Training Loss 0.329...\n",
      "Step 35160 Training Accuracy 0.953... Training Loss 0.246...\n",
      "Step 35170 Training Accuracy 0.938... Training Loss 0.238...\n",
      "Step 35180 Training Accuracy 0.844... Training Loss 0.357...\n",
      "Step 35190 Training Accuracy 0.938... Training Loss 0.198...\n",
      "Step 35200 Training Accuracy 0.906... Training Loss 0.208...\n",
      "Step 35210 Training Accuracy 0.891... Training Loss 0.244...\n",
      "Step 35220 Training Accuracy 0.969... Training Loss 0.053...\n",
      "Step 35230 Training Accuracy 0.938... Training Loss 0.167...\n",
      "Step 35240 Training Accuracy 0.984... Training Loss 0.118...\n",
      "Step 35250 Training Accuracy 0.891... Training Loss 0.383...\n",
      "Step 35260 Training Accuracy 0.938... Training Loss 0.284...\n",
      "Step 35270 Training Accuracy 0.922... Training Loss 0.300...\n",
      "Step 35280 Training Accuracy 0.938... Training Loss 0.227...\n",
      "Step 35290 Training Accuracy 0.938... Training Loss 0.182...\n",
      "Step 35300 Training Accuracy 0.859... Training Loss 0.519...\n",
      "Step 35310 Training Accuracy 0.922... Training Loss 0.232...\n",
      "Step 35320 Training Accuracy 0.922... Training Loss 0.355...\n",
      "Step 35330 Training Accuracy 0.969... Training Loss 0.152...\n",
      "Step 35340 Training Accuracy 0.922... Training Loss 0.226...\n",
      "Step 35350 Training Accuracy 0.922... Training Loss 0.362...\n",
      "Step 35360 Training Accuracy 0.969... Training Loss 0.212...\n",
      "Step 35370 Training Accuracy 0.922... Training Loss 0.214...\n",
      "Step 35380 Training Accuracy 0.922... Training Loss 0.298...\n",
      "Step 35390 Training Accuracy 0.922... Training Loss 0.280...\n",
      "Step 35400 Training Accuracy 0.969... Training Loss 0.136...\n",
      "Step 35410 Training Accuracy 0.953... Training Loss 0.095...\n",
      "Step 35420 Training Accuracy 0.859... Training Loss 0.377...\n",
      "Step 35430 Training Accuracy 0.938... Training Loss 0.172...\n",
      "Step 35440 Training Accuracy 0.938... Training Loss 0.137...\n",
      "Step 35450 Training Accuracy 0.984... Training Loss 0.088...\n",
      "Step 35460 Training Accuracy 0.906... Training Loss 0.176...\n",
      "Step 35470 Training Accuracy 0.922... Training Loss 0.211...\n",
      "Step 35480 Training Accuracy 0.938... Training Loss 0.112...\n",
      "Step 35490 Training Accuracy 0.984... Training Loss 0.042...\n",
      "Step 35500 Training Accuracy 0.906... Training Loss 0.309...\n",
      "Step 35510 Training Accuracy 0.953... Training Loss 0.202...\n",
      "Step 35520 Training Accuracy 0.969... Training Loss 0.089...\n",
      "Step 35530 Training Accuracy 0.953... Training Loss 0.152...\n",
      "Step 35540 Training Accuracy 0.953... Training Loss 0.288...\n",
      "Step 35550 Training Accuracy 0.906... Training Loss 0.352...\n",
      "Step 35560 Training Accuracy 0.938... Training Loss 0.196...\n",
      "Step 35570 Training Accuracy 0.969... Training Loss 0.106...\n",
      "Step 35580 Training Accuracy 0.969... Training Loss 0.170...\n",
      "Step 35590 Training Accuracy 0.891... Training Loss 0.141...\n",
      "Step 35600 Training Accuracy 0.953... Training Loss 0.122...\n",
      "Step 35610 Training Accuracy 0.906... Training Loss 0.307...\n",
      "Step 35620 Training Accuracy 0.906... Training Loss 0.250...\n",
      "Step 35630 Training Accuracy 0.953... Training Loss 0.195...\n",
      "Step 35640 Training Accuracy 0.938... Training Loss 0.283...\n",
      "Step 35650 Training Accuracy 0.969... Training Loss 0.087...\n",
      "Step 35660 Training Accuracy 0.891... Training Loss 0.186...\n",
      "Step 35670 Training Accuracy 0.953... Training Loss 0.174...\n",
      "Step 35680 Training Accuracy 0.969... Training Loss 0.128...\n",
      "Step 35690 Training Accuracy 0.906... Training Loss 0.290...\n",
      "Step 35700 Training Accuracy 0.922... Training Loss 0.202...\n",
      "Step 35710 Training Accuracy 0.922... Training Loss 0.244...\n",
      "Step 35720 Training Accuracy 0.984... Training Loss 0.174...\n",
      "Step 35730 Training Accuracy 0.891... Training Loss 0.366...\n",
      "Step 35740 Training Accuracy 0.906... Training Loss 0.178...\n",
      "Step 35750 Training Accuracy 0.875... Training Loss 0.418...\n",
      "Step 35760 Training Accuracy 0.953... Training Loss 0.101...\n",
      "Step 35770 Training Accuracy 0.938... Training Loss 0.216...\n",
      "Step 35780 Training Accuracy 0.906... Training Loss 0.294...\n",
      "Step 35790 Training Accuracy 0.938... Training Loss 0.246...\n",
      "Step 35800 Training Accuracy 0.891... Training Loss 0.472...\n",
      "Step 35810 Training Accuracy 0.938... Training Loss 0.182...\n",
      "Step 35820 Training Accuracy 0.953... Training Loss 0.147...\n",
      "Step 35830 Training Accuracy 0.969... Training Loss 0.136...\n",
      "Step 35840 Training Accuracy 0.875... Training Loss 0.339...\n",
      "Step 35850 Training Accuracy 0.922... Training Loss 0.270...\n",
      "Step 35860 Training Accuracy 0.938... Training Loss 0.137...\n",
      "Step 35870 Training Accuracy 0.969... Training Loss 0.070...\n",
      "Step 35880 Training Accuracy 0.906... Training Loss 0.171...\n",
      "Step 35890 Training Accuracy 0.953... Training Loss 0.164...\n",
      "Step 35900 Training Accuracy 0.969... Training Loss 0.114...\n",
      "Step 35910 Training Accuracy 0.891... Training Loss 0.410...\n",
      "Step 35920 Training Accuracy 0.953... Training Loss 0.239...\n",
      "Step 35930 Training Accuracy 0.938... Training Loss 0.226...\n",
      "Step 35940 Training Accuracy 0.953... Training Loss 0.159...\n",
      "Step 35950 Training Accuracy 0.938... Training Loss 0.142...\n",
      "Step 35960 Training Accuracy 0.953... Training Loss 0.100...\n",
      "Step 35970 Training Accuracy 0.875... Training Loss 0.468...\n",
      "Step 35980 Training Accuracy 0.922... Training Loss 0.222...\n",
      "Step 35990 Training Accuracy 0.906... Training Loss 0.179...\n",
      "Step 36000 Training Accuracy 0.953... Training Loss 0.133...\n",
      "Writing checkpoint at step 36000\n",
      "Step 36010 Training Accuracy 0.984... Training Loss 0.055...\n",
      "Step 36020 Training Accuracy 0.938... Training Loss 0.188...\n",
      "Step 36030 Training Accuracy 0.938... Training Loss 0.190...\n",
      "Step 36040 Training Accuracy 0.875... Training Loss 0.296...\n",
      "Step 36050 Training Accuracy 0.906... Training Loss 0.295...\n",
      "Step 36060 Training Accuracy 0.875... Training Loss 0.331...\n",
      "Step 36070 Training Accuracy 0.938... Training Loss 0.241...\n",
      "Step 36080 Training Accuracy 0.938... Training Loss 0.126...\n",
      "Step 36090 Training Accuracy 0.969... Training Loss 0.139...\n",
      "Step 36100 Training Accuracy 0.953... Training Loss 0.199...\n",
      "Step 36110 Training Accuracy 0.938... Training Loss 0.283...\n",
      "Step 36120 Training Accuracy 0.969... Training Loss 0.051...\n",
      "Step 36130 Training Accuracy 0.953... Training Loss 0.144...\n",
      "Step 36140 Training Accuracy 0.938... Training Loss 0.217...\n",
      "Step 36150 Training Accuracy 0.953... Training Loss 0.110...\n",
      "Step 36160 Training Accuracy 0.969... Training Loss 0.155...\n",
      "Step 36170 Training Accuracy 0.922... Training Loss 0.198...\n",
      "Step 36180 Training Accuracy 0.875... Training Loss 0.193...\n",
      "Step 36190 Training Accuracy 0.875... Training Loss 0.216...\n",
      "Step 36200 Training Accuracy 0.938... Training Loss 0.291...\n",
      "Step 36210 Training Accuracy 0.969... Training Loss 0.203...\n",
      "Step 36220 Training Accuracy 0.953... Training Loss 0.104...\n",
      "Step 36230 Training Accuracy 0.891... Training Loss 0.304...\n",
      "Step 36240 Training Accuracy 0.938... Training Loss 0.269...\n",
      "Step 36250 Training Accuracy 0.953... Training Loss 0.185...\n",
      "Step 36260 Training Accuracy 0.953... Training Loss 0.092...\n",
      "Step 36270 Training Accuracy 0.859... Training Loss 0.120...\n",
      "Step 36280 Training Accuracy 0.953... Training Loss 0.232...\n",
      "Step 36290 Training Accuracy 0.906... Training Loss 0.291...\n",
      "Step 36300 Training Accuracy 0.891... Training Loss 0.296...\n",
      "Step 36310 Training Accuracy 0.906... Training Loss 0.129...\n",
      "Step 36320 Training Accuracy 0.922... Training Loss 0.191...\n",
      "Step 36330 Training Accuracy 0.953... Training Loss 0.215...\n",
      "Step 36340 Training Accuracy 0.953... Training Loss 0.310...\n",
      "Step 36350 Training Accuracy 0.938... Training Loss 0.141...\n",
      "Step 36360 Training Accuracy 0.922... Training Loss 0.339...\n",
      "Step 36370 Training Accuracy 0.953... Training Loss 0.136...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 36380 Training Accuracy 0.844... Training Loss 0.450...\n",
      "Step 36390 Training Accuracy 0.922... Training Loss 0.184...\n",
      "Step 36400 Training Accuracy 0.922... Training Loss 0.194...\n",
      "Step 36410 Training Accuracy 0.891... Training Loss 0.171...\n",
      "Step 36420 Training Accuracy 0.953... Training Loss 0.184...\n",
      "Step 36430 Training Accuracy 0.953... Training Loss 0.080...\n",
      "Step 36440 Training Accuracy 0.953... Training Loss 0.185...\n",
      "Step 36450 Training Accuracy 0.984... Training Loss 0.087...\n",
      "Step 36460 Training Accuracy 0.906... Training Loss 0.311...\n",
      "Step 36470 Training Accuracy 0.969... Training Loss 0.058...\n",
      "Step 36480 Training Accuracy 0.875... Training Loss 0.194...\n",
      "Step 36490 Training Accuracy 0.938... Training Loss 0.195...\n",
      "Step 36500 Training Accuracy 0.922... Training Loss 0.194...\n",
      "Step 36510 Training Accuracy 0.984... Training Loss 0.274...\n",
      "Step 36520 Training Accuracy 0.922... Training Loss 0.202...\n",
      "Step 36530 Training Accuracy 0.938... Training Loss 0.227...\n",
      "Step 36540 Training Accuracy 0.953... Training Loss 0.225...\n",
      "Step 36550 Training Accuracy 0.953... Training Loss 0.150...\n",
      "Step 36560 Training Accuracy 0.906... Training Loss 0.251...\n",
      "Step 36570 Training Accuracy 0.891... Training Loss 0.231...\n",
      "Step 36580 Training Accuracy 0.938... Training Loss 0.240...\n",
      "Step 36590 Training Accuracy 0.922... Training Loss 0.221...\n",
      "Step 36600 Training Accuracy 0.984... Training Loss 0.130...\n",
      "Step 36610 Training Accuracy 0.922... Training Loss 0.300...\n",
      "Step 36620 Training Accuracy 0.938... Training Loss 0.313...\n",
      "Step 36630 Training Accuracy 0.938... Training Loss 0.192...\n",
      "Step 36640 Training Accuracy 0.953... Training Loss 0.204...\n",
      "Step 36650 Training Accuracy 0.969... Training Loss 0.173...\n",
      "Step 36660 Training Accuracy 0.953... Training Loss 0.367...\n",
      "Step 36670 Training Accuracy 0.891... Training Loss 0.306...\n",
      "Step 36680 Training Accuracy 0.922... Training Loss 0.253...\n",
      "Step 36690 Training Accuracy 0.953... Training Loss 0.102...\n",
      "Step 36700 Training Accuracy 0.938... Training Loss 0.201...\n",
      "Step 36710 Training Accuracy 0.938... Training Loss 0.297...\n",
      "Step 36720 Training Accuracy 0.938... Training Loss 0.268...\n",
      "Step 36730 Training Accuracy 0.891... Training Loss 0.147...\n",
      "Step 36740 Training Accuracy 0.953... Training Loss 0.170...\n",
      "Step 36750 Training Accuracy 0.969... Training Loss 0.120...\n",
      "Step 36760 Training Accuracy 0.953... Training Loss 0.113...\n",
      "Step 36770 Training Accuracy 0.984... Training Loss 0.172...\n",
      "Step 36780 Training Accuracy 0.922... Training Loss 0.225...\n",
      "Step 36790 Training Accuracy 0.953... Training Loss 0.219...\n",
      "Step 36800 Training Accuracy 0.938... Training Loss 0.231...\n",
      "Step 36810 Training Accuracy 0.953... Training Loss 0.153...\n",
      "Step 36820 Training Accuracy 0.953... Training Loss 0.141...\n",
      "Step 36830 Training Accuracy 0.938... Training Loss 0.291...\n",
      "Step 36840 Training Accuracy 0.906... Training Loss 0.338...\n",
      "Step 36850 Training Accuracy 0.906... Training Loss 0.167...\n",
      "Step 36860 Training Accuracy 0.891... Training Loss 0.262...\n",
      "Step 36870 Training Accuracy 0.953... Training Loss 0.253...\n",
      "Step 36880 Training Accuracy 0.953... Training Loss 0.137...\n",
      "Step 36890 Training Accuracy 0.922... Training Loss 0.201...\n",
      "Step 36900 Training Accuracy 0.969... Training Loss 0.128...\n",
      "Step 36910 Training Accuracy 0.844... Training Loss 0.376...\n",
      "Step 36920 Training Accuracy 0.906... Training Loss 0.251...\n",
      "Step 36930 Training Accuracy 0.906... Training Loss 0.249...\n",
      "Step 36940 Training Accuracy 0.922... Training Loss 0.296...\n",
      "Step 36950 Training Accuracy 0.953... Training Loss 0.255...\n",
      "Step 36960 Training Accuracy 0.969... Training Loss 0.119...\n",
      "Step 36970 Training Accuracy 0.969... Training Loss 0.096...\n",
      "Step 36980 Training Accuracy 0.938... Training Loss 0.214...\n",
      "Step 36990 Training Accuracy 0.891... Training Loss 0.355...\n",
      "Step 37000 Training Accuracy 0.953... Training Loss 0.161...\n",
      "Writing checkpoint at step 37000\n",
      "Step 37010 Training Accuracy 0.984... Training Loss 0.104...\n",
      "Step 37020 Training Accuracy 0.969... Training Loss 0.211...\n",
      "Step 37030 Training Accuracy 0.969... Training Loss 0.148...\n",
      "Step 37040 Training Accuracy 0.906... Training Loss 0.310...\n",
      "Step 37050 Training Accuracy 0.953... Training Loss 0.137...\n",
      "Step 37060 Training Accuracy 0.953... Training Loss 0.169...\n",
      "Step 37070 Training Accuracy 0.969... Training Loss 0.152...\n",
      "Step 37080 Training Accuracy 0.953... Training Loss 0.089...\n",
      "Step 37090 Training Accuracy 0.922... Training Loss 0.232...\n",
      "Step 37100 Training Accuracy 0.969... Training Loss 0.133...\n",
      "Step 37110 Training Accuracy 0.922... Training Loss 0.292...\n",
      "Step 37120 Training Accuracy 0.953... Training Loss 0.162...\n",
      "Step 37130 Training Accuracy 0.953... Training Loss 0.140...\n",
      "Step 37140 Training Accuracy 0.922... Training Loss 0.187...\n",
      "Step 37150 Training Accuracy 0.969... Training Loss 0.149...\n",
      "Step 37160 Training Accuracy 0.969... Training Loss 0.108...\n",
      "Step 37170 Training Accuracy 0.922... Training Loss 0.222...\n",
      "Step 37180 Training Accuracy 0.891... Training Loss 0.265...\n",
      "Step 37190 Training Accuracy 0.938... Training Loss 0.276...\n",
      "Step 37200 Training Accuracy 0.953... Training Loss 0.211...\n",
      "Step 37210 Training Accuracy 0.906... Training Loss 0.261...\n",
      "Step 37220 Training Accuracy 0.953... Training Loss 0.111...\n",
      "Step 37230 Training Accuracy 0.938... Training Loss 0.131...\n",
      "Step 37240 Training Accuracy 0.922... Training Loss 0.310...\n",
      "Step 37250 Training Accuracy 0.938... Training Loss 0.122...\n",
      "Step 37260 Training Accuracy 0.938... Training Loss 0.314...\n",
      "Step 37270 Training Accuracy 0.922... Training Loss 0.259...\n",
      "Step 37280 Training Accuracy 0.938... Training Loss 0.164...\n",
      "Step 37290 Training Accuracy 0.953... Training Loss 0.177...\n",
      "Step 37300 Training Accuracy 0.938... Training Loss 0.154...\n",
      "Step 37310 Training Accuracy 0.969... Training Loss 0.118...\n",
      "Step 37320 Training Accuracy 0.891... Training Loss 0.171...\n",
      "Step 37330 Training Accuracy 0.953... Training Loss 0.228...\n",
      "Step 37340 Training Accuracy 0.938... Training Loss 0.206...\n",
      "Step 37350 Training Accuracy 0.938... Training Loss 0.231...\n",
      "Step 37360 Training Accuracy 0.953... Training Loss 0.120...\n",
      "Step 37370 Training Accuracy 0.906... Training Loss 0.193...\n",
      "Step 37380 Training Accuracy 0.906... Training Loss 0.307...\n",
      "Step 37390 Training Accuracy 0.953... Training Loss 0.163...\n",
      "Step 37400 Training Accuracy 0.906... Training Loss 0.317...\n",
      "Step 37410 Training Accuracy 0.984... Training Loss 0.149...\n",
      "Step 37420 Training Accuracy 0.906... Training Loss 0.152...\n",
      "Step 37430 Training Accuracy 0.938... Training Loss 0.134...\n",
      "Step 37440 Training Accuracy 0.953... Training Loss 0.256...\n",
      "Step 37450 Training Accuracy 0.922... Training Loss 0.247...\n",
      "Step 37460 Training Accuracy 0.891... Training Loss 0.232...\n",
      "Step 37470 Training Accuracy 0.938... Training Loss 0.205...\n",
      "Step 37480 Training Accuracy 0.969... Training Loss 0.112...\n",
      "Step 37490 Training Accuracy 0.953... Training Loss 0.130...\n",
      "Step 37500 Training Accuracy 0.938... Training Loss 0.252...\n",
      "Step 37510 Training Accuracy 0.969... Training Loss 0.115...\n",
      "Step 37520 Training Accuracy 0.938... Training Loss 0.110...\n",
      "Step 37530 Training Accuracy 0.938... Training Loss 0.182...\n",
      "Step 37540 Training Accuracy 0.953... Training Loss 0.218...\n",
      "Step 37550 Training Accuracy 0.969... Training Loss 0.143...\n",
      "Step 37560 Training Accuracy 0.922... Training Loss 0.127...\n",
      "Step 37570 Training Accuracy 1.000... Training Loss 0.023...\n",
      "Step 37580 Training Accuracy 0.969... Training Loss 0.133...\n",
      "Step 37590 Training Accuracy 0.969... Training Loss 0.109...\n",
      "Step 37600 Training Accuracy 0.922... Training Loss 0.244...\n",
      "Step 37610 Training Accuracy 0.953... Training Loss 0.243...\n",
      "Step 37620 Training Accuracy 0.922... Training Loss 0.165...\n",
      "Step 37630 Training Accuracy 0.953... Training Loss 0.235...\n",
      "Step 37640 Training Accuracy 0.969... Training Loss 0.111...\n",
      "Step 37650 Training Accuracy 0.953... Training Loss 0.120...\n",
      "Step 37660 Training Accuracy 0.938... Training Loss 0.232...\n",
      "Step 37670 Training Accuracy 0.906... Training Loss 0.241...\n",
      "Step 37680 Training Accuracy 0.984... Training Loss 0.054...\n",
      "Step 37690 Training Accuracy 0.906... Training Loss 0.394...\n",
      "Step 37700 Training Accuracy 0.984... Training Loss 0.112...\n",
      "Step 37710 Training Accuracy 0.953... Training Loss 0.149...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 37720 Training Accuracy 0.938... Training Loss 0.135...\n",
      "Step 37730 Training Accuracy 0.984... Training Loss 0.085...\n",
      "Step 37740 Training Accuracy 0.969... Training Loss 0.118...\n",
      "Step 37750 Training Accuracy 0.969... Training Loss 0.143...\n",
      "Step 37760 Training Accuracy 0.969... Training Loss 0.116...\n",
      "Step 37770 Training Accuracy 0.969... Training Loss 0.234...\n",
      "Step 37780 Training Accuracy 0.938... Training Loss 0.230...\n",
      "Step 37790 Training Accuracy 0.922... Training Loss 0.253...\n",
      "Step 37800 Training Accuracy 0.891... Training Loss 0.203...\n",
      "Step 37810 Training Accuracy 0.953... Training Loss 0.185...\n",
      "Step 37820 Training Accuracy 0.953... Training Loss 0.148...\n",
      "Step 37830 Training Accuracy 0.922... Training Loss 0.172...\n",
      "Step 37840 Training Accuracy 0.938... Training Loss 0.120...\n",
      "Step 37850 Training Accuracy 0.938... Training Loss 0.304...\n",
      "Step 37860 Training Accuracy 0.969... Training Loss 0.227...\n",
      "Step 37870 Training Accuracy 0.969... Training Loss 0.083...\n",
      "Step 37880 Training Accuracy 0.984... Training Loss 0.204...\n",
      "Step 37890 Training Accuracy 0.953... Training Loss 0.115...\n",
      "Step 37900 Training Accuracy 0.922... Training Loss 0.146...\n",
      "Step 37910 Training Accuracy 0.953... Training Loss 0.142...\n",
      "Step 37920 Training Accuracy 0.969... Training Loss 0.125...\n",
      "Step 37930 Training Accuracy 0.969... Training Loss 0.106...\n",
      "Step 37940 Training Accuracy 0.922... Training Loss 0.164...\n",
      "Step 37950 Training Accuracy 0.938... Training Loss 0.257...\n",
      "Step 37960 Training Accuracy 0.922... Training Loss 0.305...\n",
      "Step 37970 Training Accuracy 0.953... Training Loss 0.198...\n",
      "Step 37980 Training Accuracy 0.953... Training Loss 0.153...\n",
      "Step 37990 Training Accuracy 0.953... Training Loss 0.211...\n",
      "Step 38000 Training Accuracy 0.984... Training Loss 0.115...\n",
      "Writing checkpoint at step 38000\n",
      "Step 38010 Training Accuracy 0.938... Training Loss 0.137...\n",
      "Step 38020 Training Accuracy 0.953... Training Loss 0.083...\n",
      "Step 38030 Training Accuracy 0.922... Training Loss 0.098...\n",
      "Step 38040 Training Accuracy 0.969... Training Loss 0.160...\n",
      "Step 38050 Training Accuracy 0.938... Training Loss 0.205...\n",
      "Step 38060 Training Accuracy 0.984... Training Loss 0.117...\n",
      "Step 38070 Training Accuracy 0.906... Training Loss 0.158...\n",
      "Step 38080 Training Accuracy 0.906... Training Loss 0.301...\n",
      "Step 38090 Training Accuracy 0.953... Training Loss 0.098...\n",
      "Step 38100 Training Accuracy 0.938... Training Loss 0.125...\n",
      "Step 38110 Training Accuracy 0.953... Training Loss 0.152...\n",
      "Step 38120 Training Accuracy 0.922... Training Loss 0.208...\n",
      "Step 38130 Training Accuracy 0.938... Training Loss 0.185...\n",
      "Step 38140 Training Accuracy 0.984... Training Loss 0.108...\n",
      "Step 38150 Training Accuracy 0.922... Training Loss 0.188...\n",
      "Step 38160 Training Accuracy 0.938... Training Loss 0.193...\n",
      "Step 38170 Training Accuracy 0.938... Training Loss 0.260...\n",
      "Step 38180 Training Accuracy 0.922... Training Loss 0.358...\n",
      "Step 38190 Training Accuracy 0.969... Training Loss 0.180...\n",
      "Step 38200 Training Accuracy 0.891... Training Loss 0.103...\n",
      "Step 38210 Training Accuracy 0.922... Training Loss 0.169...\n",
      "Step 38220 Training Accuracy 0.969... Training Loss 0.148...\n",
      "Step 38230 Training Accuracy 0.969... Training Loss 0.129...\n",
      "Step 38240 Training Accuracy 0.984... Training Loss 0.124...\n",
      "Step 38250 Training Accuracy 0.953... Training Loss 0.150...\n",
      "Step 38260 Training Accuracy 0.891... Training Loss 0.354...\n",
      "Step 38270 Training Accuracy 0.953... Training Loss 0.084...\n",
      "Step 38280 Training Accuracy 0.969... Training Loss 0.112...\n",
      "Step 38290 Training Accuracy 0.922... Training Loss 0.297...\n",
      "Step 38300 Training Accuracy 0.938... Training Loss 0.220...\n",
      "Step 38310 Training Accuracy 0.953... Training Loss 0.224...\n",
      "Step 38320 Training Accuracy 0.938... Training Loss 0.296...\n",
      "Step 38330 Training Accuracy 0.969... Training Loss 0.097...\n",
      "Step 38340 Training Accuracy 0.906... Training Loss 0.108...\n",
      "Step 38350 Training Accuracy 0.906... Training Loss 0.490...\n",
      "Step 38360 Training Accuracy 0.969... Training Loss 0.141...\n",
      "Step 38370 Training Accuracy 0.922... Training Loss 0.302...\n",
      "Step 38380 Training Accuracy 0.875... Training Loss 0.279...\n",
      "Step 38390 Training Accuracy 0.938... Training Loss 0.138...\n",
      "Step 38400 Training Accuracy 0.938... Training Loss 0.156...\n",
      "Step 38410 Training Accuracy 0.969... Training Loss 0.085...\n",
      "Step 38420 Training Accuracy 0.969... Training Loss 0.205...\n",
      "Step 38430 Training Accuracy 0.922... Training Loss 0.221...\n",
      "Step 38440 Training Accuracy 0.906... Training Loss 0.277...\n",
      "Step 38450 Training Accuracy 0.906... Training Loss 0.288...\n",
      "Step 38460 Training Accuracy 0.938... Training Loss 0.198...\n",
      "Step 38470 Training Accuracy 0.969... Training Loss 0.212...\n",
      "Step 38480 Training Accuracy 0.938... Training Loss 0.260...\n",
      "Step 38490 Training Accuracy 0.922... Training Loss 0.311...\n",
      "Step 38500 Training Accuracy 1.000... Training Loss 0.043...\n",
      "Step 38510 Training Accuracy 0.969... Training Loss 0.117...\n",
      "Step 38520 Training Accuracy 0.938... Training Loss 0.157...\n",
      "Step 38530 Training Accuracy 0.906... Training Loss 0.327...\n",
      "Step 38540 Training Accuracy 0.953... Training Loss 0.222...\n",
      "Step 38550 Training Accuracy 0.969... Training Loss 0.133...\n",
      "Step 38560 Training Accuracy 0.984... Training Loss 0.126...\n",
      "Step 38570 Training Accuracy 0.969... Training Loss 0.098...\n",
      "Step 38580 Training Accuracy 0.953... Training Loss 0.050...\n",
      "Step 38590 Training Accuracy 0.953... Training Loss 0.141...\n",
      "Step 38600 Training Accuracy 0.891... Training Loss 0.241...\n",
      "Step 38610 Training Accuracy 0.938... Training Loss 0.195...\n",
      "Step 38620 Training Accuracy 0.953... Training Loss 0.145...\n",
      "Step 38630 Training Accuracy 0.891... Training Loss 0.242...\n",
      "Step 38640 Training Accuracy 0.953... Training Loss 0.244...\n",
      "Step 38650 Training Accuracy 0.938... Training Loss 0.167...\n",
      "Step 38660 Training Accuracy 0.953... Training Loss 0.244...\n",
      "Step 38670 Training Accuracy 0.938... Training Loss 0.191...\n",
      "Step 38680 Training Accuracy 0.906... Training Loss 0.356...\n",
      "Step 38690 Training Accuracy 0.953... Training Loss 0.163...\n",
      "Step 38700 Training Accuracy 0.953... Training Loss 0.140...\n",
      "Step 38710 Training Accuracy 0.906... Training Loss 0.293...\n",
      "Step 38720 Training Accuracy 0.922... Training Loss 0.162...\n",
      "Step 38730 Training Accuracy 0.906... Training Loss 0.191...\n",
      "Step 38740 Training Accuracy 0.828... Training Loss 0.442...\n",
      "Step 38750 Training Accuracy 0.938... Training Loss 0.286...\n",
      "Step 38760 Training Accuracy 0.938... Training Loss 0.136...\n",
      "Step 38770 Training Accuracy 0.938... Training Loss 0.174...\n",
      "Step 38780 Training Accuracy 0.953... Training Loss 0.131...\n",
      "Step 38790 Training Accuracy 0.891... Training Loss 0.282...\n",
      "Step 38800 Training Accuracy 0.969... Training Loss 0.158...\n",
      "Step 38810 Training Accuracy 0.922... Training Loss 0.258...\n",
      "Step 38820 Training Accuracy 0.969... Training Loss 0.110...\n",
      "Step 38830 Training Accuracy 0.922... Training Loss 0.170...\n",
      "Step 38840 Training Accuracy 0.969... Training Loss 0.107...\n",
      "Step 38850 Training Accuracy 0.938... Training Loss 0.115...\n",
      "Step 38860 Training Accuracy 0.922... Training Loss 0.195...\n",
      "Step 38870 Training Accuracy 0.953... Training Loss 0.214...\n",
      "Step 38880 Training Accuracy 0.938... Training Loss 0.184...\n",
      "Step 38890 Training Accuracy 0.906... Training Loss 0.327...\n",
      "Step 38900 Training Accuracy 0.938... Training Loss 0.157...\n",
      "Step 38910 Training Accuracy 0.984... Training Loss 0.184...\n",
      "Step 38920 Training Accuracy 0.906... Training Loss 0.107...\n",
      "Step 38930 Training Accuracy 0.891... Training Loss 0.228...\n",
      "Step 38940 Training Accuracy 0.969... Training Loss 0.106...\n",
      "Step 38950 Training Accuracy 0.922... Training Loss 0.242...\n",
      "Step 38960 Training Accuracy 0.938... Training Loss 0.340...\n",
      "Step 38970 Training Accuracy 0.938... Training Loss 0.186...\n",
      "Step 38980 Training Accuracy 0.875... Training Loss 0.245...\n",
      "Step 38990 Training Accuracy 0.906... Training Loss 0.241...\n",
      "Step 39000 Training Accuracy 0.969... Training Loss 0.132...\n",
      "Writing checkpoint at step 39000\n",
      "Step 39010 Training Accuracy 0.984... Training Loss 0.079...\n",
      "Step 39020 Training Accuracy 0.953... Training Loss 0.201...\n",
      "Step 39030 Training Accuracy 0.891... Training Loss 0.418...\n",
      "Step 39040 Training Accuracy 0.938... Training Loss 0.156...\n",
      "Step 39050 Training Accuracy 0.984... Training Loss 0.073...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 39060 Training Accuracy 0.906... Training Loss 0.310...\n",
      "Step 39070 Training Accuracy 0.984... Training Loss 0.089...\n",
      "Step 39080 Training Accuracy 0.969... Training Loss 0.144...\n",
      "Step 39090 Training Accuracy 0.969... Training Loss 0.126...\n",
      "Step 39100 Training Accuracy 0.922... Training Loss 0.166...\n",
      "Step 39110 Training Accuracy 0.922... Training Loss 0.107...\n",
      "Step 39120 Training Accuracy 0.938... Training Loss 0.171...\n",
      "Step 39130 Training Accuracy 0.969... Training Loss 0.121...\n",
      "Step 39140 Training Accuracy 0.953... Training Loss 0.179...\n",
      "Step 39150 Training Accuracy 0.938... Training Loss 0.137...\n",
      "Step 39160 Training Accuracy 0.953... Training Loss 0.177...\n",
      "Step 39170 Training Accuracy 0.969... Training Loss 0.120...\n",
      "Step 39180 Training Accuracy 0.906... Training Loss 0.264...\n",
      "Step 39190 Training Accuracy 0.891... Training Loss 0.264...\n",
      "Step 39200 Training Accuracy 0.984... Training Loss 0.044...\n",
      "Step 39210 Training Accuracy 0.938... Training Loss 0.092...\n",
      "Step 39220 Training Accuracy 0.953... Training Loss 0.332...\n",
      "Step 39230 Training Accuracy 0.984... Training Loss 0.066...\n",
      "Step 39240 Training Accuracy 0.891... Training Loss 0.394...\n",
      "Step 39250 Training Accuracy 0.969... Training Loss 0.135...\n",
      "Step 39260 Training Accuracy 0.938... Training Loss 0.139...\n",
      "Step 39270 Training Accuracy 0.906... Training Loss 0.258...\n",
      "Step 39280 Training Accuracy 0.984... Training Loss 0.080...\n",
      "Step 39290 Training Accuracy 0.969... Training Loss 0.257...\n",
      "Step 39300 Training Accuracy 0.984... Training Loss 0.116...\n",
      "Step 39310 Training Accuracy 0.969... Training Loss 0.172...\n",
      "Step 39320 Training Accuracy 0.984... Training Loss 0.093...\n",
      "Step 39330 Training Accuracy 0.969... Training Loss 0.112...\n",
      "Step 39340 Training Accuracy 0.969... Training Loss 0.047...\n",
      "Step 39350 Training Accuracy 0.969... Training Loss 0.173...\n",
      "Step 39360 Training Accuracy 0.953... Training Loss 0.108...\n",
      "Step 39370 Training Accuracy 0.922... Training Loss 0.227...\n",
      "Step 39380 Training Accuracy 0.984... Training Loss 0.130...\n",
      "Step 39390 Training Accuracy 0.984... Training Loss 0.093...\n",
      "Step 39400 Training Accuracy 0.984... Training Loss 0.060...\n",
      "Step 39410 Training Accuracy 0.891... Training Loss 0.226...\n",
      "Step 39420 Training Accuracy 0.969... Training Loss 0.182...\n",
      "Step 39430 Training Accuracy 0.953... Training Loss 0.074...\n",
      "Step 39440 Training Accuracy 0.984... Training Loss 0.036...\n",
      "Step 39450 Training Accuracy 0.984... Training Loss 0.075...\n",
      "Step 39460 Training Accuracy 0.969... Training Loss 0.123...\n",
      "Step 39470 Training Accuracy 0.938... Training Loss 0.184...\n",
      "Step 39480 Training Accuracy 0.891... Training Loss 0.251...\n",
      "Step 39490 Training Accuracy 0.953... Training Loss 0.144...\n",
      "Step 39500 Training Accuracy 0.891... Training Loss 0.162...\n",
      "Step 39510 Training Accuracy 0.891... Training Loss 0.239...\n",
      "Step 39520 Training Accuracy 0.938... Training Loss 0.242...\n",
      "Step 39530 Training Accuracy 0.922... Training Loss 0.413...\n",
      "Step 39540 Training Accuracy 0.938... Training Loss 0.182...\n",
      "Step 39550 Training Accuracy 0.922... Training Loss 0.339...\n",
      "Step 39560 Training Accuracy 0.891... Training Loss 0.207...\n",
      "Step 39570 Training Accuracy 0.953... Training Loss 0.170...\n",
      "Step 39580 Training Accuracy 0.969... Training Loss 0.164...\n",
      "Step 39590 Training Accuracy 0.906... Training Loss 0.171...\n",
      "Step 39600 Training Accuracy 0.969... Training Loss 0.085...\n",
      "Step 39610 Training Accuracy 0.922... Training Loss 0.200...\n",
      "Step 39620 Training Accuracy 0.906... Training Loss 0.182...\n",
      "Step 39630 Training Accuracy 0.938... Training Loss 0.229...\n",
      "Step 39640 Training Accuracy 0.953... Training Loss 0.156...\n",
      "Step 39650 Training Accuracy 0.938... Training Loss 0.206...\n",
      "Step 39660 Training Accuracy 0.984... Training Loss 0.111...\n",
      "Step 39670 Training Accuracy 0.922... Training Loss 0.197...\n",
      "Step 39680 Training Accuracy 0.953... Training Loss 0.114...\n",
      "Step 39690 Training Accuracy 0.922... Training Loss 0.230...\n",
      "Step 39700 Training Accuracy 0.938... Training Loss 0.148...\n",
      "Step 39710 Training Accuracy 0.938... Training Loss 0.132...\n",
      "Step 39720 Training Accuracy 0.938... Training Loss 0.237...\n",
      "Step 39730 Training Accuracy 0.938... Training Loss 0.137...\n",
      "Step 39740 Training Accuracy 0.922... Training Loss 0.156...\n",
      "Step 39750 Training Accuracy 0.922... Training Loss 0.204...\n",
      "Step 39760 Training Accuracy 0.891... Training Loss 0.387...\n",
      "Step 39770 Training Accuracy 0.922... Training Loss 0.172...\n",
      "Step 39780 Training Accuracy 0.984... Training Loss 0.118...\n",
      "Step 39790 Training Accuracy 0.938... Training Loss 0.161...\n",
      "Step 39800 Training Accuracy 0.953... Training Loss 0.105...\n",
      "Step 39810 Training Accuracy 0.938... Training Loss 0.137...\n",
      "Step 39820 Training Accuracy 0.953... Training Loss 0.185...\n",
      "Step 39830 Training Accuracy 0.984... Training Loss 0.048...\n",
      "Step 39840 Training Accuracy 0.969... Training Loss 0.120...\n",
      "Step 39850 Training Accuracy 0.938... Training Loss 0.130...\n",
      "Step 39860 Training Accuracy 0.922... Training Loss 0.169...\n",
      "Step 39870 Training Accuracy 0.984... Training Loss 0.128...\n",
      "Step 39880 Training Accuracy 0.953... Training Loss 0.137...\n",
      "Step 39890 Training Accuracy 0.938... Training Loss 0.195...\n",
      "Step 39900 Training Accuracy 0.938... Training Loss 0.187...\n",
      "Step 39910 Training Accuracy 0.922... Training Loss 0.174...\n",
      "Step 39920 Training Accuracy 0.891... Training Loss 0.241...\n",
      "Step 39930 Training Accuracy 0.984... Training Loss 0.148...\n",
      "Step 39940 Training Accuracy 0.922... Training Loss 0.267...\n",
      "Step 39950 Training Accuracy 0.938... Training Loss 0.186...\n",
      "Step 39960 Training Accuracy 0.906... Training Loss 0.316...\n",
      "Step 39970 Training Accuracy 0.984... Training Loss 0.105...\n",
      "Step 39980 Training Accuracy 0.938... Training Loss 0.153...\n",
      "Step 39990 Training Accuracy 0.953... Training Loss 0.103...\n",
      "Step 40000 Training Accuracy 0.953... Training Loss 0.235...\n",
      "Writing checkpoint at step 40000\n",
      "Step 40010 Training Accuracy 0.984... Training Loss 0.129...\n",
      "Step 40020 Training Accuracy 0.938... Training Loss 0.175...\n",
      "Step 40030 Training Accuracy 0.969... Training Loss 0.162...\n",
      "Step 40040 Training Accuracy 0.938... Training Loss 0.151...\n",
      "Step 40050 Training Accuracy 0.938... Training Loss 0.153...\n",
      "Step 40060 Training Accuracy 0.891... Training Loss 0.241...\n",
      "Step 40070 Training Accuracy 0.953... Training Loss 0.146...\n",
      "Step 40080 Training Accuracy 1.000... Training Loss 0.048...\n",
      "Step 40090 Training Accuracy 0.891... Training Loss 0.274...\n",
      "Step 40100 Training Accuracy 0.938... Training Loss 0.207...\n",
      "Step 40110 Training Accuracy 0.922... Training Loss 0.286...\n",
      "Step 40120 Training Accuracy 0.938... Training Loss 0.262...\n",
      "Step 40130 Training Accuracy 0.969... Training Loss 0.176...\n",
      "Step 40140 Training Accuracy 0.953... Training Loss 0.127...\n",
      "Step 40150 Training Accuracy 0.891... Training Loss 0.275...\n",
      "Step 40160 Training Accuracy 0.875... Training Loss 0.480...\n",
      "Step 40170 Training Accuracy 0.922... Training Loss 0.254...\n",
      "Step 40180 Training Accuracy 0.906... Training Loss 0.245...\n",
      "Step 40190 Training Accuracy 0.953... Training Loss 0.175...\n",
      "Step 40200 Training Accuracy 0.906... Training Loss 0.402...\n",
      "Step 40210 Training Accuracy 0.984... Training Loss 0.123...\n",
      "Step 40220 Training Accuracy 0.969... Training Loss 0.095...\n",
      "Step 40230 Training Accuracy 0.953... Training Loss 0.165...\n",
      "Step 40240 Training Accuracy 0.922... Training Loss 0.235...\n",
      "Step 40250 Training Accuracy 0.953... Training Loss 0.147...\n",
      "Step 40260 Training Accuracy 0.969... Training Loss 0.199...\n",
      "Step 40270 Training Accuracy 0.938... Training Loss 0.188...\n",
      "Step 40280 Training Accuracy 0.922... Training Loss 0.219...\n",
      "Step 40290 Training Accuracy 0.953... Training Loss 0.230...\n",
      "Step 40300 Training Accuracy 0.938... Training Loss 0.090...\n",
      "Step 40310 Training Accuracy 0.906... Training Loss 0.239...\n",
      "Step 40320 Training Accuracy 0.953... Training Loss 0.152...\n",
      "Step 40330 Training Accuracy 0.906... Training Loss 0.143...\n",
      "Step 40340 Training Accuracy 0.953... Training Loss 0.111...\n",
      "Step 40350 Training Accuracy 0.984... Training Loss 0.098...\n",
      "Step 40360 Training Accuracy 0.922... Training Loss 0.239...\n",
      "Step 40370 Training Accuracy 0.984... Training Loss 0.080...\n",
      "Step 40380 Training Accuracy 0.953... Training Loss 0.230...\n",
      "Step 40390 Training Accuracy 0.984... Training Loss 0.187...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 40400 Training Accuracy 0.969... Training Loss 0.109...\n",
      "Step 40410 Training Accuracy 0.984... Training Loss 0.135...\n",
      "Step 40420 Training Accuracy 0.938... Training Loss 0.129...\n",
      "Step 40430 Training Accuracy 0.938... Training Loss 0.136...\n",
      "Step 40440 Training Accuracy 0.938... Training Loss 0.276...\n",
      "Step 40450 Training Accuracy 0.906... Training Loss 0.453...\n",
      "Step 40460 Training Accuracy 0.984... Training Loss 0.078...\n",
      "Step 40470 Training Accuracy 0.938... Training Loss 0.108...\n",
      "Step 40480 Training Accuracy 0.938... Training Loss 0.104...\n",
      "Step 40490 Training Accuracy 0.969... Training Loss 0.123...\n",
      "Step 40500 Training Accuracy 0.969... Training Loss 0.094...\n",
      "Step 40510 Training Accuracy 0.938... Training Loss 0.164...\n",
      "Step 40520 Training Accuracy 0.969... Training Loss 0.043...\n",
      "Step 40530 Training Accuracy 0.953... Training Loss 0.159...\n",
      "Step 40540 Training Accuracy 0.938... Training Loss 0.186...\n",
      "Step 40550 Training Accuracy 0.922... Training Loss 0.436...\n",
      "Step 40560 Training Accuracy 0.922... Training Loss 0.216...\n",
      "Step 40570 Training Accuracy 0.984... Training Loss 0.068...\n",
      "Step 40580 Training Accuracy 0.938... Training Loss 0.090...\n",
      "Step 40590 Training Accuracy 0.828... Training Loss 0.624...\n",
      "Step 40600 Training Accuracy 0.906... Training Loss 0.247...\n",
      "Step 40610 Training Accuracy 0.953... Training Loss 0.261...\n",
      "Step 40620 Training Accuracy 0.953... Training Loss 0.275...\n",
      "Step 40630 Training Accuracy 0.938... Training Loss 0.145...\n",
      "Step 40640 Training Accuracy 0.906... Training Loss 0.306...\n",
      "Step 40650 Training Accuracy 0.922... Training Loss 0.122...\n",
      "Step 40660 Training Accuracy 0.969... Training Loss 0.134...\n",
      "Step 40670 Training Accuracy 0.906... Training Loss 0.217...\n",
      "Step 40680 Training Accuracy 0.969... Training Loss 0.147...\n",
      "Step 40690 Training Accuracy 0.938... Training Loss 0.134...\n",
      "Step 40700 Training Accuracy 0.969... Training Loss 0.110...\n",
      "Step 40710 Training Accuracy 0.953... Training Loss 0.148...\n",
      "Step 40720 Training Accuracy 0.969... Training Loss 0.099...\n",
      "Step 40730 Training Accuracy 1.000... Training Loss 0.041...\n",
      "Step 40740 Training Accuracy 0.938... Training Loss 0.290...\n",
      "Step 40750 Training Accuracy 0.969... Training Loss 0.128...\n",
      "Step 40760 Training Accuracy 0.938... Training Loss 0.115...\n",
      "Step 40770 Training Accuracy 0.953... Training Loss 0.157...\n",
      "Step 40780 Training Accuracy 0.953... Training Loss 0.120...\n",
      "Step 40790 Training Accuracy 0.969... Training Loss 0.204...\n",
      "Step 40800 Training Accuracy 1.000... Training Loss 0.053...\n",
      "Step 40810 Training Accuracy 0.828... Training Loss 0.366...\n",
      "Step 40820 Training Accuracy 0.969... Training Loss 0.093...\n",
      "Step 40830 Training Accuracy 0.953... Training Loss 0.176...\n",
      "Step 40840 Training Accuracy 0.953... Training Loss 0.117...\n",
      "Step 40850 Training Accuracy 0.938... Training Loss 0.207...\n",
      "Step 40860 Training Accuracy 0.953... Training Loss 0.188...\n",
      "Step 40870 Training Accuracy 0.906... Training Loss 0.305...\n",
      "Step 40880 Training Accuracy 0.906... Training Loss 0.310...\n",
      "Step 40890 Training Accuracy 0.969... Training Loss 0.045...\n",
      "Step 40900 Training Accuracy 0.891... Training Loss 0.285...\n",
      "Step 40910 Training Accuracy 0.891... Training Loss 0.285...\n",
      "Step 40920 Training Accuracy 0.953... Training Loss 0.136...\n",
      "Step 40930 Training Accuracy 0.938... Training Loss 0.110...\n",
      "Step 40940 Training Accuracy 0.891... Training Loss 0.255...\n",
      "Step 40950 Training Accuracy 0.969... Training Loss 0.086...\n",
      "Step 40960 Training Accuracy 0.969... Training Loss 0.230...\n",
      "Step 40970 Training Accuracy 1.000... Training Loss 0.115...\n",
      "Step 40980 Training Accuracy 0.938... Training Loss 0.221...\n",
      "Step 40990 Training Accuracy 1.000... Training Loss 0.057...\n",
      "Step 41000 Training Accuracy 0.875... Training Loss 0.285...\n",
      "Writing checkpoint at step 41000\n",
      "Step 41010 Training Accuracy 0.953... Training Loss 0.191...\n",
      "Step 41020 Training Accuracy 0.938... Training Loss 0.234...\n",
      "Step 41030 Training Accuracy 1.000... Training Loss 0.092...\n",
      "Step 41040 Training Accuracy 0.938... Training Loss 0.149...\n",
      "Step 41050 Training Accuracy 0.906... Training Loss 0.209...\n",
      "Step 41060 Training Accuracy 0.953... Training Loss 0.193...\n",
      "Step 41070 Training Accuracy 0.969... Training Loss 0.217...\n",
      "Step 41080 Training Accuracy 0.906... Training Loss 0.182...\n",
      "Step 41090 Training Accuracy 0.969... Training Loss 0.225...\n",
      "Step 41100 Training Accuracy 0.938... Training Loss 0.161...\n",
      "Step 41110 Training Accuracy 0.922... Training Loss 0.284...\n",
      "Step 41120 Training Accuracy 0.906... Training Loss 0.292...\n",
      "Step 41130 Training Accuracy 0.922... Training Loss 0.184...\n",
      "Step 41140 Training Accuracy 0.953... Training Loss 0.140...\n",
      "Step 41150 Training Accuracy 0.891... Training Loss 0.241...\n",
      "Step 41160 Training Accuracy 0.906... Training Loss 0.237...\n",
      "Step 41170 Training Accuracy 0.938... Training Loss 0.244...\n",
      "Step 41180 Training Accuracy 0.984... Training Loss 0.084...\n",
      "Step 41190 Training Accuracy 0.938... Training Loss 0.142...\n",
      "Step 41200 Training Accuracy 0.969... Training Loss 0.075...\n",
      "Step 41210 Training Accuracy 0.969... Training Loss 0.120...\n",
      "Step 41220 Training Accuracy 0.969... Training Loss 0.057...\n",
      "Step 41230 Training Accuracy 0.984... Training Loss 0.061...\n",
      "Step 41240 Training Accuracy 0.875... Training Loss 0.178...\n",
      "Step 41250 Training Accuracy 0.922... Training Loss 0.106...\n",
      "Step 41260 Training Accuracy 0.953... Training Loss 0.132...\n",
      "Step 41270 Training Accuracy 1.000... Training Loss 0.095...\n",
      "Step 41280 Training Accuracy 0.938... Training Loss 0.141...\n",
      "Step 41290 Training Accuracy 0.953... Training Loss 0.223...\n",
      "Step 41300 Training Accuracy 0.922... Training Loss 0.130...\n",
      "Step 41310 Training Accuracy 0.969... Training Loss 0.102...\n",
      "Step 41320 Training Accuracy 0.969... Training Loss 0.061...\n",
      "Step 41330 Training Accuracy 0.938... Training Loss 0.307...\n",
      "Step 41340 Training Accuracy 0.922... Training Loss 0.262...\n",
      "Step 41350 Training Accuracy 0.922... Training Loss 0.220...\n",
      "Step 41360 Training Accuracy 0.938... Training Loss 0.222...\n",
      "Step 41370 Training Accuracy 0.984... Training Loss 0.136...\n",
      "Step 41380 Training Accuracy 0.969... Training Loss 0.111...\n",
      "Step 41390 Training Accuracy 0.969... Training Loss 0.092...\n",
      "Step 41400 Training Accuracy 0.953... Training Loss 0.117...\n",
      "Step 41410 Training Accuracy 0.953... Training Loss 0.042...\n",
      "Step 41420 Training Accuracy 0.969... Training Loss 0.094...\n",
      "Step 41430 Training Accuracy 0.906... Training Loss 0.243...\n",
      "Step 41440 Training Accuracy 0.922... Training Loss 0.158...\n",
      "Step 41450 Training Accuracy 0.969... Training Loss 0.131...\n",
      "Step 41460 Training Accuracy 0.953... Training Loss 0.067...\n",
      "Step 41470 Training Accuracy 0.969... Training Loss 0.185...\n",
      "Step 41480 Training Accuracy 0.969... Training Loss 0.087...\n",
      "Step 41490 Training Accuracy 0.984... Training Loss 0.198...\n",
      "Step 41500 Training Accuracy 0.938... Training Loss 0.185...\n",
      "Step 41510 Training Accuracy 0.922... Training Loss 0.245...\n",
      "Step 41520 Training Accuracy 0.969... Training Loss 0.148...\n",
      "Step 41530 Training Accuracy 0.953... Training Loss 0.131...\n",
      "Step 41540 Training Accuracy 0.969... Training Loss 0.185...\n",
      "Step 41550 Training Accuracy 0.969... Training Loss 0.117...\n",
      "Step 41560 Training Accuracy 0.969... Training Loss 0.182...\n",
      "Step 41570 Training Accuracy 0.938... Training Loss 0.224...\n",
      "Step 41580 Training Accuracy 0.953... Training Loss 0.072...\n",
      "Step 41590 Training Accuracy 0.891... Training Loss 0.217...\n",
      "Step 41600 Training Accuracy 0.969... Training Loss 0.118...\n",
      "Step 41610 Training Accuracy 0.969... Training Loss 0.066...\n",
      "Step 41620 Training Accuracy 0.984... Training Loss 0.057...\n",
      "Step 41630 Training Accuracy 0.953... Training Loss 0.146...\n",
      "Step 41640 Training Accuracy 0.859... Training Loss 0.348...\n",
      "Step 41650 Training Accuracy 0.969... Training Loss 0.117...\n",
      "Step 41660 Training Accuracy 0.953... Training Loss 0.103...\n",
      "Step 41670 Training Accuracy 0.984... Training Loss 0.103...\n",
      "Step 41680 Training Accuracy 0.969... Training Loss 0.140...\n",
      "Step 41690 Training Accuracy 0.969... Training Loss 0.166...\n",
      "Step 41700 Training Accuracy 0.953... Training Loss 0.228...\n",
      "Step 41710 Training Accuracy 0.953... Training Loss 0.167...\n",
      "Step 41720 Training Accuracy 0.922... Training Loss 0.151...\n",
      "Step 41730 Training Accuracy 0.922... Training Loss 0.163...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 41740 Training Accuracy 0.922... Training Loss 0.253...\n",
      "Step 41750 Training Accuracy 0.984... Training Loss 0.048...\n",
      "Step 41760 Training Accuracy 1.000... Training Loss 0.031...\n",
      "Step 41770 Training Accuracy 0.922... Training Loss 0.223...\n",
      "Step 41780 Training Accuracy 0.938... Training Loss 0.100...\n",
      "Step 41790 Training Accuracy 0.984... Training Loss 0.127...\n",
      "Step 41800 Training Accuracy 0.969... Training Loss 0.100...\n",
      "Step 41810 Training Accuracy 0.953... Training Loss 0.266...\n",
      "Step 41820 Training Accuracy 0.938... Training Loss 0.316...\n",
      "Step 41830 Training Accuracy 0.938... Training Loss 0.190...\n",
      "Step 41840 Training Accuracy 0.969... Training Loss 0.125...\n",
      "Step 41850 Training Accuracy 0.969... Training Loss 0.171...\n",
      "Step 41860 Training Accuracy 1.000... Training Loss 0.087...\n",
      "Step 41870 Training Accuracy 0.891... Training Loss 0.275...\n",
      "Step 41880 Training Accuracy 0.969... Training Loss 0.164...\n",
      "Step 41890 Training Accuracy 0.969... Training Loss 0.088...\n",
      "Step 41900 Training Accuracy 0.906... Training Loss 0.235...\n",
      "Step 41910 Training Accuracy 0.953... Training Loss 0.244...\n",
      "Step 41920 Training Accuracy 1.000... Training Loss 0.061...\n",
      "Step 41930 Training Accuracy 0.938... Training Loss 0.074...\n",
      "Step 41940 Training Accuracy 0.969... Training Loss 0.086...\n",
      "Step 41950 Training Accuracy 0.938... Training Loss 0.253...\n",
      "Step 41960 Training Accuracy 0.938... Training Loss 0.149...\n",
      "Step 41970 Training Accuracy 0.938... Training Loss 0.167...\n",
      "Step 41980 Training Accuracy 0.891... Training Loss 0.313...\n",
      "Step 41990 Training Accuracy 0.984... Training Loss 0.073...\n",
      "Step 42000 Training Accuracy 0.875... Training Loss 0.221...\n",
      "Writing checkpoint at step 42000\n",
      "Step 42010 Training Accuracy 0.969... Training Loss 0.080...\n",
      "Step 42020 Training Accuracy 0.953... Training Loss 0.125...\n",
      "Step 42030 Training Accuracy 0.984... Training Loss 0.055...\n",
      "Step 42040 Training Accuracy 0.891... Training Loss 0.287...\n",
      "Step 42050 Training Accuracy 0.938... Training Loss 0.241...\n",
      "Step 42060 Training Accuracy 0.984... Training Loss 0.100...\n",
      "Step 42070 Training Accuracy 0.984... Training Loss 0.033...\n",
      "Step 42080 Training Accuracy 0.922... Training Loss 0.197...\n",
      "Step 42090 Training Accuracy 0.938... Training Loss 0.185...\n",
      "Step 42100 Training Accuracy 0.984... Training Loss 0.091...\n",
      "Step 42110 Training Accuracy 0.922... Training Loss 0.215...\n",
      "Step 42120 Training Accuracy 0.906... Training Loss 0.165...\n",
      "Step 42130 Training Accuracy 0.938... Training Loss 0.359...\n",
      "Step 42140 Training Accuracy 0.969... Training Loss 0.124...\n",
      "Step 42150 Training Accuracy 0.906... Training Loss 0.253...\n",
      "Step 42160 Training Accuracy 0.953... Training Loss 0.264...\n",
      "Step 42170 Training Accuracy 0.938... Training Loss 0.153...\n",
      "Step 42180 Training Accuracy 0.969... Training Loss 0.289...\n",
      "Step 42190 Training Accuracy 0.875... Training Loss 0.423...\n",
      "Step 42200 Training Accuracy 0.984... Training Loss 0.081...\n",
      "Step 42210 Training Accuracy 0.938... Training Loss 0.112...\n",
      "Step 42220 Training Accuracy 0.906... Training Loss 0.224...\n",
      "Step 42230 Training Accuracy 0.922... Training Loss 0.295...\n",
      "Step 42240 Training Accuracy 0.922... Training Loss 0.232...\n",
      "Step 42250 Training Accuracy 0.938... Training Loss 0.139...\n",
      "Step 42260 Training Accuracy 0.922... Training Loss 0.241...\n",
      "Step 42270 Training Accuracy 0.938... Training Loss 0.207...\n",
      "Step 42280 Training Accuracy 0.953... Training Loss 0.214...\n",
      "Step 42290 Training Accuracy 0.922... Training Loss 0.154...\n",
      "Step 42300 Training Accuracy 0.906... Training Loss 0.256...\n",
      "Step 42310 Training Accuracy 0.938... Training Loss 0.101...\n",
      "Step 42320 Training Accuracy 0.984... Training Loss 0.101...\n",
      "Step 42330 Training Accuracy 0.938... Training Loss 0.163...\n",
      "Step 42340 Training Accuracy 0.953... Training Loss 0.199...\n",
      "Step 42350 Training Accuracy 0.922... Training Loss 0.066...\n",
      "Step 42360 Training Accuracy 0.969... Training Loss 0.118...\n",
      "Step 42370 Training Accuracy 0.922... Training Loss 0.171...\n",
      "Step 42380 Training Accuracy 0.938... Training Loss 0.243...\n",
      "Step 42390 Training Accuracy 0.938... Training Loss 0.195...\n",
      "Step 42400 Training Accuracy 0.969... Training Loss 0.151...\n",
      "Step 42410 Training Accuracy 0.953... Training Loss 0.141...\n",
      "Step 42420 Training Accuracy 0.969... Training Loss 0.079...\n",
      "Step 42430 Training Accuracy 0.875... Training Loss 0.253...\n",
      "Step 42440 Training Accuracy 0.969... Training Loss 0.125...\n",
      "Step 42450 Training Accuracy 0.969... Training Loss 0.148...\n",
      "Step 42460 Training Accuracy 0.938... Training Loss 0.145...\n",
      "Step 42470 Training Accuracy 0.969... Training Loss 0.131...\n",
      "Step 42480 Training Accuracy 0.938... Training Loss 0.204...\n",
      "Step 42490 Training Accuracy 0.938... Training Loss 0.294...\n",
      "Step 42500 Training Accuracy 0.922... Training Loss 0.125...\n",
      "Step 42510 Training Accuracy 0.922... Training Loss 0.226...\n",
      "Step 42520 Training Accuracy 0.906... Training Loss 0.221...\n",
      "Step 42530 Training Accuracy 0.969... Training Loss 0.081...\n",
      "Step 42540 Training Accuracy 0.984... Training Loss 0.129...\n",
      "Step 42550 Training Accuracy 0.938... Training Loss 0.166...\n",
      "Step 42560 Training Accuracy 0.969... Training Loss 0.068...\n",
      "Step 42570 Training Accuracy 0.922... Training Loss 0.300...\n",
      "Step 42580 Training Accuracy 0.922... Training Loss 0.280...\n",
      "Step 42590 Training Accuracy 0.969... Training Loss 0.092...\n",
      "Step 42600 Training Accuracy 0.953... Training Loss 0.161...\n",
      "Step 42610 Training Accuracy 0.953... Training Loss 0.154...\n",
      "Step 42620 Training Accuracy 0.984... Training Loss 0.072...\n",
      "Step 42630 Training Accuracy 0.953... Training Loss 0.076...\n",
      "Step 42640 Training Accuracy 1.000... Training Loss 0.127...\n",
      "Step 42650 Training Accuracy 0.953... Training Loss 0.095...\n",
      "Step 42660 Training Accuracy 0.984... Training Loss 0.144...\n",
      "Step 42670 Training Accuracy 0.875... Training Loss 0.208...\n",
      "Step 42680 Training Accuracy 0.875... Training Loss 0.276...\n",
      "Step 42690 Training Accuracy 0.906... Training Loss 0.395...\n",
      "Step 42700 Training Accuracy 0.953... Training Loss 0.228...\n",
      "Step 42710 Training Accuracy 1.000... Training Loss 0.079...\n",
      "Step 42720 Training Accuracy 0.875... Training Loss 0.260...\n",
      "Step 42730 Training Accuracy 0.938... Training Loss 0.189...\n",
      "Step 42740 Training Accuracy 0.953... Training Loss 0.195...\n",
      "Step 42750 Training Accuracy 0.891... Training Loss 0.232...\n",
      "Step 42760 Training Accuracy 0.875... Training Loss 0.193...\n",
      "Step 42770 Training Accuracy 0.922... Training Loss 0.249...\n",
      "Step 42780 Training Accuracy 0.984... Training Loss 0.067...\n",
      "Step 42790 Training Accuracy 0.953... Training Loss 0.274...\n",
      "Step 42800 Training Accuracy 0.953... Training Loss 0.229...\n",
      "Step 42810 Training Accuracy 0.953... Training Loss 0.315...\n",
      "Step 42820 Training Accuracy 0.969... Training Loss 0.095...\n",
      "Step 42830 Training Accuracy 0.953... Training Loss 0.362...\n",
      "Step 42840 Training Accuracy 0.906... Training Loss 0.331...\n",
      "Step 42850 Training Accuracy 0.969... Training Loss 0.091...\n",
      "Step 42860 Training Accuracy 0.922... Training Loss 0.181...\n",
      "Step 42870 Training Accuracy 0.953... Training Loss 0.151...\n",
      "Step 42880 Training Accuracy 0.969... Training Loss 0.140...\n",
      "Step 42890 Training Accuracy 0.938... Training Loss 0.317...\n",
      "Step 42900 Training Accuracy 0.859... Training Loss 0.238...\n",
      "Step 42910 Training Accuracy 0.953... Training Loss 0.211...\n",
      "Step 42920 Training Accuracy 0.922... Training Loss 0.223...\n",
      "Step 42930 Training Accuracy 0.938... Training Loss 0.175...\n",
      "Step 42940 Training Accuracy 0.969... Training Loss 0.274...\n",
      "Step 42950 Training Accuracy 0.953... Training Loss 0.243...\n",
      "Step 42960 Training Accuracy 0.891... Training Loss 0.311...\n",
      "Step 42970 Training Accuracy 0.984... Training Loss 0.074...\n",
      "Step 42980 Training Accuracy 1.000... Training Loss 0.060...\n",
      "Step 42990 Training Accuracy 0.938... Training Loss 0.213...\n",
      "Step 43000 Training Accuracy 0.922... Training Loss 0.282...\n",
      "Writing checkpoint at step 43000\n",
      "Step 43010 Training Accuracy 0.906... Training Loss 0.198...\n",
      "Step 43020 Training Accuracy 0.938... Training Loss 0.174...\n",
      "Step 43030 Training Accuracy 0.922... Training Loss 0.246...\n",
      "Step 43040 Training Accuracy 1.000... Training Loss 0.071...\n",
      "Step 43050 Training Accuracy 0.891... Training Loss 0.262...\n",
      "Step 43060 Training Accuracy 0.938... Training Loss 0.243...\n",
      "Step 43070 Training Accuracy 0.938... Training Loss 0.065...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 43080 Training Accuracy 0.984... Training Loss 0.152...\n",
      "Step 43090 Training Accuracy 0.906... Training Loss 0.210...\n",
      "Step 43100 Training Accuracy 0.969... Training Loss 0.159...\n",
      "Step 43110 Training Accuracy 0.953... Training Loss 0.175...\n",
      "Step 43120 Training Accuracy 0.953... Training Loss 0.203...\n",
      "Step 43130 Training Accuracy 0.969... Training Loss 0.146...\n",
      "Step 43140 Training Accuracy 0.969... Training Loss 0.138...\n",
      "Step 43150 Training Accuracy 0.906... Training Loss 0.270...\n",
      "Step 43160 Training Accuracy 0.984... Training Loss 0.067...\n",
      "Step 43170 Training Accuracy 0.969... Training Loss 0.083...\n",
      "Step 43180 Training Accuracy 0.984... Training Loss 0.100...\n",
      "Step 43190 Training Accuracy 0.969... Training Loss 0.193...\n",
      "Step 43200 Training Accuracy 0.906... Training Loss 0.129...\n",
      "Step 43210 Training Accuracy 0.922... Training Loss 0.236...\n",
      "Step 43220 Training Accuracy 0.922... Training Loss 0.210...\n",
      "Step 43230 Training Accuracy 0.969... Training Loss 0.128...\n",
      "Step 43240 Training Accuracy 0.984... Training Loss 0.057...\n",
      "Step 43250 Training Accuracy 0.984... Training Loss 0.110...\n",
      "Step 43260 Training Accuracy 0.938... Training Loss 0.280...\n",
      "Step 43270 Training Accuracy 0.938... Training Loss 0.099...\n",
      "Step 43280 Training Accuracy 0.969... Training Loss 0.107...\n",
      "Step 43290 Training Accuracy 0.922... Training Loss 0.180...\n",
      "Step 43300 Training Accuracy 0.953... Training Loss 0.178...\n",
      "Step 43310 Training Accuracy 0.984... Training Loss 0.038...\n",
      "Step 43320 Training Accuracy 0.891... Training Loss 0.233...\n",
      "Step 43330 Training Accuracy 0.969... Training Loss 0.170...\n",
      "Step 43340 Training Accuracy 0.969... Training Loss 0.101...\n",
      "Step 43350 Training Accuracy 0.938... Training Loss 0.167...\n",
      "Step 43360 Training Accuracy 0.953... Training Loss 0.136...\n",
      "Step 43370 Training Accuracy 0.938... Training Loss 0.092...\n",
      "Step 43380 Training Accuracy 0.938... Training Loss 0.218...\n",
      "Step 43390 Training Accuracy 0.938... Training Loss 0.224...\n",
      "Step 43400 Training Accuracy 0.891... Training Loss 0.323...\n",
      "Step 43410 Training Accuracy 0.969... Training Loss 0.075...\n",
      "Step 43420 Training Accuracy 0.953... Training Loss 0.159...\n",
      "Step 43430 Training Accuracy 0.953... Training Loss 0.079...\n",
      "Step 43440 Training Accuracy 0.969... Training Loss 0.075...\n",
      "Step 43450 Training Accuracy 0.938... Training Loss 0.170...\n",
      "Step 43460 Training Accuracy 0.953... Training Loss 0.195...\n",
      "Step 43470 Training Accuracy 1.000... Training Loss 0.061...\n",
      "Step 43480 Training Accuracy 0.969... Training Loss 0.119...\n",
      "Step 43490 Training Accuracy 0.875... Training Loss 0.188...\n",
      "Step 43500 Training Accuracy 0.984... Training Loss 0.046...\n",
      "Step 43510 Training Accuracy 0.938... Training Loss 0.069...\n",
      "Step 43520 Training Accuracy 0.984... Training Loss 0.041...\n",
      "Step 43530 Training Accuracy 0.953... Training Loss 0.093...\n",
      "Step 43540 Training Accuracy 0.906... Training Loss 0.287...\n",
      "Step 43550 Training Accuracy 0.969... Training Loss 0.107...\n",
      "Step 43560 Training Accuracy 0.953... Training Loss 0.108...\n",
      "Step 43570 Training Accuracy 0.953... Training Loss 0.136...\n",
      "Step 43580 Training Accuracy 0.891... Training Loss 0.409...\n",
      "Step 43590 Training Accuracy 0.922... Training Loss 0.181...\n",
      "Step 43600 Training Accuracy 0.953... Training Loss 0.119...\n",
      "Step 43610 Training Accuracy 0.938... Training Loss 0.176...\n",
      "Step 43620 Training Accuracy 0.938... Training Loss 0.211...\n",
      "Step 43630 Training Accuracy 0.953... Training Loss 0.117...\n",
      "Step 43640 Training Accuracy 0.969... Training Loss 0.117...\n",
      "Step 43650 Training Accuracy 0.938... Training Loss 0.160...\n",
      "Step 43660 Training Accuracy 0.922... Training Loss 0.177...\n",
      "Step 43670 Training Accuracy 0.984... Training Loss 0.178...\n",
      "Step 43680 Training Accuracy 0.922... Training Loss 0.215...\n",
      "Step 43690 Training Accuracy 0.953... Training Loss 0.067...\n",
      "Step 43700 Training Accuracy 1.000... Training Loss 0.039...\n",
      "Step 43710 Training Accuracy 0.953... Training Loss 0.251...\n",
      "Step 43720 Training Accuracy 0.953... Training Loss 0.097...\n",
      "Step 43730 Training Accuracy 0.953... Training Loss 0.215...\n",
      "Step 43740 Training Accuracy 0.984... Training Loss 0.072...\n",
      "Step 43750 Training Accuracy 0.984... Training Loss 0.049...\n",
      "Step 43760 Training Accuracy 0.969... Training Loss 0.085...\n",
      "Step 43770 Training Accuracy 0.938... Training Loss 0.128...\n",
      "Step 43780 Training Accuracy 0.938... Training Loss 0.178...\n",
      "Step 43790 Training Accuracy 0.922... Training Loss 0.114...\n",
      "Step 43800 Training Accuracy 0.938... Training Loss 0.203...\n",
      "Step 43810 Training Accuracy 0.969... Training Loss 0.113...\n",
      "Step 43820 Training Accuracy 0.906... Training Loss 0.193...\n",
      "Step 43830 Training Accuracy 0.953... Training Loss 0.223...\n",
      "Step 43840 Training Accuracy 0.859... Training Loss 0.594...\n",
      "Step 43850 Training Accuracy 0.938... Training Loss 0.096...\n",
      "Step 43860 Training Accuracy 0.953... Training Loss 0.272...\n",
      "Step 43870 Training Accuracy 0.953... Training Loss 0.113...\n",
      "Step 43880 Training Accuracy 0.922... Training Loss 0.241...\n",
      "Step 43890 Training Accuracy 1.000... Training Loss 0.104...\n",
      "Step 43900 Training Accuracy 1.000... Training Loss 0.019...\n",
      "Step 43910 Training Accuracy 0.969... Training Loss 0.099...\n",
      "Step 43920 Training Accuracy 0.969... Training Loss 0.116...\n",
      "Step 43930 Training Accuracy 0.953... Training Loss 0.157...\n",
      "Step 43940 Training Accuracy 0.953... Training Loss 0.141...\n",
      "Step 43950 Training Accuracy 0.969... Training Loss 0.056...\n",
      "Step 43960 Training Accuracy 0.969... Training Loss 0.049...\n",
      "Step 43970 Training Accuracy 0.969... Training Loss 0.113...\n",
      "Step 43980 Training Accuracy 0.984... Training Loss 0.047...\n",
      "Step 43990 Training Accuracy 0.969... Training Loss 0.078...\n",
      "Step 44000 Training Accuracy 0.984... Training Loss 0.053...\n",
      "Writing checkpoint at step 44000\n",
      "Step 44010 Training Accuracy 0.984... Training Loss 0.165...\n",
      "Step 44020 Training Accuracy 0.969... Training Loss 0.052...\n",
      "Step 44030 Training Accuracy 0.938... Training Loss 0.239...\n",
      "Step 44040 Training Accuracy 0.969... Training Loss 0.129...\n",
      "Step 44050 Training Accuracy 0.922... Training Loss 0.228...\n",
      "Step 44060 Training Accuracy 0.953... Training Loss 0.068...\n",
      "Step 44070 Training Accuracy 0.938... Training Loss 0.117...\n",
      "Step 44080 Training Accuracy 0.953... Training Loss 0.141...\n",
      "Step 44090 Training Accuracy 0.953... Training Loss 0.174...\n",
      "Step 44100 Training Accuracy 0.953... Training Loss 0.109...\n",
      "Step 44110 Training Accuracy 0.969... Training Loss 0.066...\n",
      "Step 44120 Training Accuracy 0.938... Training Loss 0.237...\n",
      "Step 44130 Training Accuracy 0.938... Training Loss 0.168...\n",
      "Step 44140 Training Accuracy 0.969... Training Loss 0.139...\n",
      "Step 44150 Training Accuracy 0.922... Training Loss 0.156...\n",
      "Step 44160 Training Accuracy 0.922... Training Loss 0.328...\n",
      "Step 44170 Training Accuracy 0.953... Training Loss 0.107...\n",
      "Step 44180 Training Accuracy 0.938... Training Loss 0.099...\n",
      "Step 44190 Training Accuracy 0.953... Training Loss 0.247...\n",
      "Step 44200 Training Accuracy 0.984... Training Loss 0.088...\n",
      "Step 44210 Training Accuracy 0.938... Training Loss 0.206...\n",
      "Step 44220 Training Accuracy 0.969... Training Loss 0.088...\n",
      "Step 44230 Training Accuracy 0.969... Training Loss 0.063...\n",
      "Step 44240 Training Accuracy 1.000... Training Loss 0.045...\n",
      "Step 44250 Training Accuracy 0.938... Training Loss 0.185...\n",
      "Step 44260 Training Accuracy 0.984... Training Loss 0.134...\n",
      "Step 44270 Training Accuracy 0.938... Training Loss 0.170...\n",
      "Step 44280 Training Accuracy 0.906... Training Loss 0.227...\n",
      "Step 44290 Training Accuracy 0.984... Training Loss 0.058...\n",
      "Step 44300 Training Accuracy 0.953... Training Loss 0.191...\n",
      "Step 44310 Training Accuracy 1.000... Training Loss 0.034...\n",
      "Step 44320 Training Accuracy 0.906... Training Loss 0.148...\n",
      "Step 44330 Training Accuracy 0.953... Training Loss 0.161...\n",
      "Step 44340 Training Accuracy 0.969... Training Loss 0.105...\n",
      "Step 44350 Training Accuracy 0.969... Training Loss 0.212...\n",
      "Step 44360 Training Accuracy 0.938... Training Loss 0.181...\n",
      "Step 44370 Training Accuracy 0.891... Training Loss 0.276...\n",
      "Step 44380 Training Accuracy 0.984... Training Loss 0.097...\n",
      "Step 44390 Training Accuracy 0.922... Training Loss 0.155...\n",
      "Step 44400 Training Accuracy 0.984... Training Loss 0.140...\n",
      "Step 44410 Training Accuracy 0.938... Training Loss 0.184...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 44420 Training Accuracy 0.875... Training Loss 0.250...\n",
      "Step 44430 Training Accuracy 0.938... Training Loss 0.260...\n",
      "Step 44440 Training Accuracy 0.922... Training Loss 0.189...\n",
      "Step 44450 Training Accuracy 0.938... Training Loss 0.130...\n",
      "Step 44460 Training Accuracy 0.953... Training Loss 0.074...\n",
      "Step 44470 Training Accuracy 0.969... Training Loss 0.053...\n",
      "Step 44480 Training Accuracy 0.969... Training Loss 0.157...\n",
      "Step 44490 Training Accuracy 0.984... Training Loss 0.085...\n",
      "Step 44500 Training Accuracy 0.891... Training Loss 0.225...\n",
      "Step 44510 Training Accuracy 0.969... Training Loss 0.261...\n",
      "Step 44520 Training Accuracy 0.953... Training Loss 0.110...\n",
      "Step 44530 Training Accuracy 0.938... Training Loss 0.329...\n",
      "Step 44540 Training Accuracy 0.984... Training Loss 0.097...\n",
      "Step 44550 Training Accuracy 0.953... Training Loss 0.064...\n",
      "Step 44560 Training Accuracy 0.953... Training Loss 0.178...\n",
      "Step 44570 Training Accuracy 0.969... Training Loss 0.087...\n",
      "Step 44580 Training Accuracy 0.922... Training Loss 0.232...\n",
      "Step 44590 Training Accuracy 0.953... Training Loss 0.114...\n",
      "Step 44600 Training Accuracy 0.984... Training Loss 0.057...\n",
      "Step 44610 Training Accuracy 0.953... Training Loss 0.166...\n",
      "Step 44620 Training Accuracy 0.969... Training Loss 0.112...\n",
      "Step 44630 Training Accuracy 0.984... Training Loss 0.161...\n",
      "Step 44640 Training Accuracy 0.922... Training Loss 0.180...\n",
      "Step 44650 Training Accuracy 0.984... Training Loss 0.046...\n",
      "Step 44660 Training Accuracy 0.922... Training Loss 0.231...\n",
      "Step 44670 Training Accuracy 0.922... Training Loss 0.266...\n",
      "Step 44680 Training Accuracy 0.953... Training Loss 0.235...\n",
      "Step 44690 Training Accuracy 0.984... Training Loss 0.073...\n",
      "Step 44700 Training Accuracy 0.969... Training Loss 0.069...\n",
      "Step 44710 Training Accuracy 0.969... Training Loss 0.109...\n",
      "Step 44720 Training Accuracy 0.969... Training Loss 0.152...\n",
      "Step 44730 Training Accuracy 0.891... Training Loss 0.461...\n",
      "Step 44740 Training Accuracy 0.953... Training Loss 0.092...\n",
      "Step 44750 Training Accuracy 0.953... Training Loss 0.165...\n",
      "Step 44760 Training Accuracy 0.984... Training Loss 0.094...\n",
      "Step 44770 Training Accuracy 0.984... Training Loss 0.145...\n",
      "Step 44780 Training Accuracy 0.938... Training Loss 0.125...\n",
      "Step 44790 Training Accuracy 0.953... Training Loss 0.185...\n",
      "Step 44800 Training Accuracy 0.938... Training Loss 0.147...\n",
      "Step 44810 Training Accuracy 0.953... Training Loss 0.170...\n",
      "Step 44820 Training Accuracy 0.984... Training Loss 0.060...\n",
      "Step 44830 Training Accuracy 0.984... Training Loss 0.042...\n",
      "Step 44840 Training Accuracy 0.984... Training Loss 0.098...\n",
      "Step 44850 Training Accuracy 0.922... Training Loss 0.164...\n",
      "Step 44860 Training Accuracy 0.891... Training Loss 0.318...\n",
      "Step 44870 Training Accuracy 0.938... Training Loss 0.203...\n",
      "Step 44880 Training Accuracy 0.922... Training Loss 0.316...\n",
      "Step 44890 Training Accuracy 0.938... Training Loss 0.099...\n",
      "Step 44900 Training Accuracy 0.969... Training Loss 0.188...\n",
      "Step 44910 Training Accuracy 0.969... Training Loss 0.095...\n",
      "Step 44920 Training Accuracy 0.969... Training Loss 0.073...\n",
      "Step 44930 Training Accuracy 0.969... Training Loss 0.219...\n",
      "Step 44940 Training Accuracy 1.000... Training Loss 0.025...\n",
      "Step 44950 Training Accuracy 0.938... Training Loss 0.106...\n",
      "Step 44960 Training Accuracy 0.938... Training Loss 0.070...\n",
      "Step 44970 Training Accuracy 0.938... Training Loss 0.201...\n",
      "Step 44980 Training Accuracy 0.859... Training Loss 0.295...\n",
      "Step 44990 Training Accuracy 0.953... Training Loss 0.224...\n",
      "Step 45000 Training Accuracy 0.938... Training Loss 0.169...\n",
      "Writing checkpoint at step 45000\n",
      "Step 45010 Training Accuracy 0.922... Training Loss 0.165...\n",
      "Step 45020 Training Accuracy 0.938... Training Loss 0.207...\n",
      "Step 45030 Training Accuracy 0.938... Training Loss 0.157...\n",
      "Step 45040 Training Accuracy 0.938... Training Loss 0.133...\n",
      "Step 45050 Training Accuracy 0.969... Training Loss 0.191...\n",
      "Step 45060 Training Accuracy 0.922... Training Loss 0.353...\n",
      "Step 45070 Training Accuracy 1.000... Training Loss 0.060...\n",
      "Step 45080 Training Accuracy 0.984... Training Loss 0.092...\n",
      "Step 45090 Training Accuracy 0.969... Training Loss 0.106...\n",
      "Step 45100 Training Accuracy 0.953... Training Loss 0.154...\n",
      "Step 45110 Training Accuracy 0.969... Training Loss 0.230...\n",
      "Step 45120 Training Accuracy 0.969... Training Loss 0.113...\n",
      "Step 45130 Training Accuracy 0.953... Training Loss 0.203...\n",
      "Step 45140 Training Accuracy 0.953... Training Loss 0.177...\n",
      "Step 45150 Training Accuracy 0.938... Training Loss 0.181...\n",
      "Step 45160 Training Accuracy 0.953... Training Loss 0.189...\n",
      "Step 45170 Training Accuracy 0.922... Training Loss 0.131...\n",
      "Step 45180 Training Accuracy 0.938... Training Loss 0.172...\n",
      "Step 45190 Training Accuracy 0.938... Training Loss 0.100...\n",
      "Step 45200 Training Accuracy 0.938... Training Loss 0.123...\n",
      "Step 45210 Training Accuracy 0.906... Training Loss 0.228...\n",
      "Step 45220 Training Accuracy 0.906... Training Loss 0.241...\n",
      "Step 45230 Training Accuracy 0.938... Training Loss 0.344...\n",
      "Step 45240 Training Accuracy 0.969... Training Loss 0.073...\n",
      "Step 45250 Training Accuracy 0.938... Training Loss 0.214...\n",
      "Step 45260 Training Accuracy 0.906... Training Loss 0.265...\n",
      "Step 45270 Training Accuracy 0.953... Training Loss 0.198...\n",
      "Step 45280 Training Accuracy 0.938... Training Loss 0.154...\n",
      "Step 45290 Training Accuracy 0.922... Training Loss 0.187...\n",
      "Step 45300 Training Accuracy 0.969... Training Loss 0.099...\n",
      "Step 45310 Training Accuracy 0.938... Training Loss 0.327...\n",
      "Step 45320 Training Accuracy 0.938... Training Loss 0.150...\n",
      "Step 45330 Training Accuracy 0.922... Training Loss 0.154...\n",
      "Step 45340 Training Accuracy 1.000... Training Loss 0.065...\n",
      "Step 45350 Training Accuracy 0.969... Training Loss 0.226...\n",
      "Step 45360 Training Accuracy 0.953... Training Loss 0.171...\n",
      "Step 45370 Training Accuracy 0.953... Training Loss 0.174...\n",
      "Step 45380 Training Accuracy 0.969... Training Loss 0.191...\n",
      "Step 45390 Training Accuracy 0.938... Training Loss 0.137...\n",
      "Step 45400 Training Accuracy 0.984... Training Loss 0.114...\n",
      "Step 45410 Training Accuracy 1.000... Training Loss 0.068...\n",
      "Step 45420 Training Accuracy 0.891... Training Loss 0.224...\n",
      "Step 45430 Training Accuracy 0.953... Training Loss 0.113...\n",
      "Step 45440 Training Accuracy 0.969... Training Loss 0.068...\n",
      "Step 45450 Training Accuracy 0.969... Training Loss 0.191...\n",
      "Step 45460 Training Accuracy 0.891... Training Loss 0.176...\n",
      "Step 45470 Training Accuracy 0.984... Training Loss 0.036...\n",
      "Step 45480 Training Accuracy 0.953... Training Loss 0.147...\n",
      "Step 45490 Training Accuracy 1.000... Training Loss 0.052...\n",
      "Step 45500 Training Accuracy 0.922... Training Loss 0.174...\n",
      "Step 45510 Training Accuracy 0.938... Training Loss 0.166...\n",
      "Step 45520 Training Accuracy 0.953... Training Loss 0.097...\n",
      "Step 45530 Training Accuracy 0.906... Training Loss 0.131...\n",
      "Step 45540 Training Accuracy 0.953... Training Loss 0.130...\n",
      "Step 45550 Training Accuracy 1.000... Training Loss 0.024...\n",
      "Step 45560 Training Accuracy 0.969... Training Loss 0.132...\n",
      "Step 45570 Training Accuracy 0.969... Training Loss 0.131...\n",
      "Step 45580 Training Accuracy 0.953... Training Loss 0.145...\n",
      "Step 45590 Training Accuracy 0.906... Training Loss 0.321...\n",
      "Step 45600 Training Accuracy 0.969... Training Loss 0.123...\n",
      "Step 45610 Training Accuracy 0.938... Training Loss 0.188...\n",
      "Step 45620 Training Accuracy 0.938... Training Loss 0.097...\n",
      "Step 45630 Training Accuracy 0.969... Training Loss 0.052...\n",
      "Step 45640 Training Accuracy 0.953... Training Loss 0.181...\n",
      "Step 45650 Training Accuracy 0.984... Training Loss 0.064...\n",
      "Step 45660 Training Accuracy 0.938... Training Loss 0.115...\n",
      "Step 45670 Training Accuracy 0.953... Training Loss 0.161...\n",
      "Step 45680 Training Accuracy 0.953... Training Loss 0.100...\n",
      "Step 45690 Training Accuracy 0.906... Training Loss 0.360...\n",
      "Step 45700 Training Accuracy 0.969... Training Loss 0.072...\n",
      "Step 45710 Training Accuracy 0.922... Training Loss 0.245...\n",
      "Step 45720 Training Accuracy 0.969... Training Loss 0.146...\n",
      "Step 45730 Training Accuracy 0.953... Training Loss 0.176...\n",
      "Step 45740 Training Accuracy 0.938... Training Loss 0.293...\n",
      "Step 45750 Training Accuracy 0.969... Training Loss 0.069...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 45760 Training Accuracy 0.922... Training Loss 0.301...\n",
      "Step 45770 Training Accuracy 0.953... Training Loss 0.226...\n",
      "Step 45780 Training Accuracy 0.984... Training Loss 0.111...\n",
      "Step 45790 Training Accuracy 0.984... Training Loss 0.037...\n",
      "Step 45800 Training Accuracy 0.969... Training Loss 0.154...\n",
      "Step 45810 Training Accuracy 0.953... Training Loss 0.101...\n",
      "Step 45820 Training Accuracy 0.922... Training Loss 0.223...\n",
      "Step 45830 Training Accuracy 0.953... Training Loss 0.112...\n",
      "Step 45840 Training Accuracy 0.969... Training Loss 0.051...\n",
      "Step 45850 Training Accuracy 0.953... Training Loss 0.144...\n",
      "Step 45860 Training Accuracy 0.984... Training Loss 0.142...\n",
      "Step 45870 Training Accuracy 0.938... Training Loss 0.098...\n",
      "Step 45880 Training Accuracy 0.938... Training Loss 0.335...\n",
      "Step 45890 Training Accuracy 0.922... Training Loss 0.407...\n",
      "Step 45900 Training Accuracy 0.984... Training Loss 0.015...\n",
      "Step 45910 Training Accuracy 0.922... Training Loss 0.258...\n",
      "Step 45920 Training Accuracy 0.953... Training Loss 0.143...\n",
      "Step 45930 Training Accuracy 0.922... Training Loss 0.242...\n",
      "Step 45940 Training Accuracy 0.938... Training Loss 0.105...\n",
      "Step 45950 Training Accuracy 0.984... Training Loss 0.050...\n",
      "Step 45960 Training Accuracy 0.984... Training Loss 0.045...\n",
      "Step 45970 Training Accuracy 0.969... Training Loss 0.222...\n",
      "Step 45980 Training Accuracy 0.906... Training Loss 0.239...\n",
      "Step 45990 Training Accuracy 1.000... Training Loss 0.032...\n",
      "Step 46000 Training Accuracy 0.875... Training Loss 0.316...\n",
      "Writing checkpoint at step 46000\n",
      "Step 46010 Training Accuracy 0.984... Training Loss 0.143...\n",
      "Step 46020 Training Accuracy 0.969... Training Loss 0.056...\n",
      "Step 46030 Training Accuracy 0.906... Training Loss 0.181...\n",
      "Step 46040 Training Accuracy 0.953... Training Loss 0.186...\n",
      "Step 46050 Training Accuracy 0.922... Training Loss 0.147...\n",
      "Step 46060 Training Accuracy 0.922... Training Loss 0.115...\n",
      "Step 46070 Training Accuracy 0.984... Training Loss 0.122...\n",
      "Step 46080 Training Accuracy 0.969... Training Loss 0.070...\n",
      "Step 46090 Training Accuracy 0.984... Training Loss 0.105...\n",
      "Step 46100 Training Accuracy 0.922... Training Loss 0.329...\n",
      "Step 46110 Training Accuracy 1.000... Training Loss 0.076...\n",
      "Step 46120 Training Accuracy 0.984... Training Loss 0.052...\n",
      "Step 46130 Training Accuracy 0.984... Training Loss 0.052...\n",
      "Step 46140 Training Accuracy 0.938... Training Loss 0.200...\n",
      "Step 46150 Training Accuracy 0.969... Training Loss 0.108...\n",
      "Step 46160 Training Accuracy 0.969... Training Loss 0.097...\n",
      "Step 46170 Training Accuracy 0.906... Training Loss 0.313...\n",
      "Step 46180 Training Accuracy 0.969... Training Loss 0.146...\n",
      "Step 46190 Training Accuracy 0.953... Training Loss 0.181...\n",
      "Step 46200 Training Accuracy 0.969... Training Loss 0.099...\n",
      "Step 46210 Training Accuracy 0.953... Training Loss 0.050...\n",
      "Step 46220 Training Accuracy 0.953... Training Loss 0.078...\n",
      "Step 46230 Training Accuracy 0.969... Training Loss 0.142...\n",
      "Step 46240 Training Accuracy 0.953... Training Loss 0.201...\n",
      "Step 46250 Training Accuracy 0.906... Training Loss 0.316...\n",
      "Step 46260 Training Accuracy 0.953... Training Loss 0.077...\n",
      "Step 46270 Training Accuracy 0.906... Training Loss 0.330...\n",
      "Step 46280 Training Accuracy 0.953... Training Loss 0.174...\n",
      "Step 46290 Training Accuracy 0.922... Training Loss 0.186...\n",
      "Step 46300 Training Accuracy 0.922... Training Loss 0.288...\n",
      "Step 46310 Training Accuracy 0.938... Training Loss 0.207...\n",
      "Step 46320 Training Accuracy 0.922... Training Loss 0.350...\n",
      "Step 46330 Training Accuracy 0.922... Training Loss 0.127...\n",
      "Step 46340 Training Accuracy 0.984... Training Loss 0.049...\n",
      "Step 46350 Training Accuracy 0.969... Training Loss 0.091...\n",
      "Step 46360 Training Accuracy 0.938... Training Loss 0.168...\n",
      "Step 46370 Training Accuracy 0.953... Training Loss 0.097...\n",
      "Step 46380 Training Accuracy 0.953... Training Loss 0.137...\n",
      "Step 46390 Training Accuracy 0.984... Training Loss 0.080...\n",
      "Step 46400 Training Accuracy 0.938... Training Loss 0.136...\n",
      "Step 46410 Training Accuracy 0.969... Training Loss 0.125...\n",
      "Step 46420 Training Accuracy 0.984... Training Loss 0.033...\n",
      "Step 46430 Training Accuracy 0.984... Training Loss 0.105...\n",
      "Step 46440 Training Accuracy 0.969... Training Loss 0.051...\n",
      "Step 46450 Training Accuracy 0.938... Training Loss 0.215...\n",
      "Step 46460 Training Accuracy 0.953... Training Loss 0.145...\n",
      "Step 46470 Training Accuracy 0.984... Training Loss 0.139...\n",
      "Step 46480 Training Accuracy 0.938... Training Loss 0.131...\n",
      "Step 46490 Training Accuracy 0.953... Training Loss 0.141...\n",
      "Step 46500 Training Accuracy 1.000... Training Loss 0.056...\n",
      "Step 46510 Training Accuracy 0.922... Training Loss 0.213...\n",
      "Step 46520 Training Accuracy 0.906... Training Loss 0.301...\n",
      "Step 46530 Training Accuracy 0.953... Training Loss 0.174...\n",
      "Step 46540 Training Accuracy 0.984... Training Loss 0.045...\n",
      "Step 46550 Training Accuracy 0.938... Training Loss 0.114...\n",
      "Step 46560 Training Accuracy 0.984... Training Loss 0.159...\n",
      "Step 46570 Training Accuracy 0.953... Training Loss 0.093...\n",
      "Step 46580 Training Accuracy 0.953... Training Loss 0.103...\n",
      "Step 46590 Training Accuracy 0.969... Training Loss 0.065...\n",
      "Step 46600 Training Accuracy 0.953... Training Loss 0.270...\n",
      "Step 46610 Training Accuracy 0.938... Training Loss 0.133...\n",
      "Step 46620 Training Accuracy 0.953... Training Loss 0.175...\n",
      "Step 46630 Training Accuracy 1.000... Training Loss 0.037...\n",
      "Step 46640 Training Accuracy 0.906... Training Loss 0.223...\n",
      "Step 46650 Training Accuracy 0.984... Training Loss 0.120...\n",
      "Step 46660 Training Accuracy 0.953... Training Loss 0.122...\n",
      "Step 46670 Training Accuracy 0.969... Training Loss 0.152...\n",
      "Step 46680 Training Accuracy 0.984... Training Loss 0.178...\n",
      "Step 46690 Training Accuracy 1.000... Training Loss 0.051...\n",
      "Step 46700 Training Accuracy 0.953... Training Loss 0.081...\n",
      "Step 46710 Training Accuracy 0.844... Training Loss 0.325...\n",
      "Step 46720 Training Accuracy 0.906... Training Loss 0.142...\n",
      "Step 46730 Training Accuracy 0.969... Training Loss 0.102...\n",
      "Step 46740 Training Accuracy 0.969... Training Loss 0.085...\n",
      "Step 46750 Training Accuracy 0.984... Training Loss 0.177...\n",
      "Step 46760 Training Accuracy 0.953... Training Loss 0.150...\n",
      "Step 46770 Training Accuracy 0.969... Training Loss 0.129...\n",
      "Step 46780 Training Accuracy 0.953... Training Loss 0.141...\n",
      "Step 46790 Training Accuracy 0.984... Training Loss 0.149...\n",
      "Step 46800 Training Accuracy 0.922... Training Loss 0.137...\n",
      "Step 46810 Training Accuracy 0.938... Training Loss 0.094...\n",
      "Step 46820 Training Accuracy 0.969... Training Loss 0.122...\n",
      "Step 46830 Training Accuracy 0.984... Training Loss 0.067...\n",
      "Step 46840 Training Accuracy 0.969... Training Loss 0.100...\n",
      "Step 46850 Training Accuracy 0.922... Training Loss 0.077...\n",
      "Step 46860 Training Accuracy 0.984... Training Loss 0.044...\n",
      "Step 46870 Training Accuracy 0.969... Training Loss 0.040...\n",
      "Step 46880 Training Accuracy 0.969... Training Loss 0.063...\n",
      "Step 46890 Training Accuracy 0.969... Training Loss 0.077...\n",
      "Step 46900 Training Accuracy 0.938... Training Loss 0.127...\n",
      "Step 46910 Training Accuracy 0.953... Training Loss 0.173...\n",
      "Step 46920 Training Accuracy 0.938... Training Loss 0.162...\n",
      "Step 46930 Training Accuracy 0.969... Training Loss 0.086...\n",
      "Step 46940 Training Accuracy 0.969... Training Loss 0.295...\n",
      "Step 46950 Training Accuracy 0.938... Training Loss 0.262...\n",
      "Step 46960 Training Accuracy 0.953... Training Loss 0.156...\n",
      "Step 46970 Training Accuracy 0.969... Training Loss 0.228...\n",
      "Step 46980 Training Accuracy 0.922... Training Loss 0.209...\n",
      "Step 46990 Training Accuracy 0.984... Training Loss 0.048...\n",
      "Step 47000 Training Accuracy 0.969... Training Loss 0.151...\n",
      "Writing checkpoint at step 47000\n",
      "Step 47010 Training Accuracy 0.953... Training Loss 0.178...\n",
      "Step 47020 Training Accuracy 0.984... Training Loss 0.130...\n",
      "Step 47030 Training Accuracy 0.969... Training Loss 0.083...\n",
      "Step 47040 Training Accuracy 0.938... Training Loss 0.077...\n",
      "Step 47050 Training Accuracy 0.938... Training Loss 0.290...\n",
      "Step 47060 Training Accuracy 0.953... Training Loss 0.070...\n",
      "Step 47070 Training Accuracy 0.969... Training Loss 0.232...\n",
      "Step 47080 Training Accuracy 0.984... Training Loss 0.051...\n",
      "Step 47090 Training Accuracy 0.953... Training Loss 0.089...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 47100 Training Accuracy 0.953... Training Loss 0.095...\n",
      "Step 47110 Training Accuracy 0.891... Training Loss 0.188...\n",
      "Step 47120 Training Accuracy 0.953... Training Loss 0.109...\n",
      "Step 47130 Training Accuracy 0.938... Training Loss 0.079...\n",
      "Step 47140 Training Accuracy 0.953... Training Loss 0.119...\n",
      "Step 47150 Training Accuracy 0.953... Training Loss 0.130...\n",
      "Step 47160 Training Accuracy 0.969... Training Loss 0.075...\n",
      "Step 47170 Training Accuracy 0.984... Training Loss 0.091...\n",
      "Step 47180 Training Accuracy 0.953... Training Loss 0.130...\n",
      "Step 47190 Training Accuracy 0.984... Training Loss 0.045...\n",
      "Step 47200 Training Accuracy 0.906... Training Loss 0.255...\n",
      "Step 47210 Training Accuracy 0.906... Training Loss 0.399...\n",
      "Step 47220 Training Accuracy 0.938... Training Loss 0.100...\n",
      "Step 47230 Training Accuracy 0.969... Training Loss 0.078...\n",
      "Step 47240 Training Accuracy 0.938... Training Loss 0.142...\n",
      "Step 47250 Training Accuracy 0.984... Training Loss 0.083...\n",
      "Step 47260 Training Accuracy 0.938... Training Loss 0.137...\n",
      "Step 47270 Training Accuracy 0.984... Training Loss 0.038...\n",
      "Step 47280 Training Accuracy 0.953... Training Loss 0.147...\n",
      "Step 47290 Training Accuracy 0.953... Training Loss 0.127...\n",
      "Step 47300 Training Accuracy 0.953... Training Loss 0.104...\n",
      "Step 47310 Training Accuracy 0.969... Training Loss 0.093...\n",
      "Step 47320 Training Accuracy 0.969... Training Loss 0.063...\n",
      "Step 47330 Training Accuracy 0.969... Training Loss 0.101...\n",
      "Step 47340 Training Accuracy 0.984... Training Loss 0.031...\n",
      "Step 47350 Training Accuracy 0.969... Training Loss 0.109...\n",
      "Step 47360 Training Accuracy 0.969... Training Loss 0.092...\n",
      "Step 47370 Training Accuracy 0.984... Training Loss 0.058...\n",
      "Step 47380 Training Accuracy 0.953... Training Loss 0.186...\n",
      "Step 47390 Training Accuracy 1.000... Training Loss 0.078...\n",
      "Step 47400 Training Accuracy 0.953... Training Loss 0.188...\n",
      "Step 47410 Training Accuracy 0.953... Training Loss 0.154...\n",
      "Step 47420 Training Accuracy 0.984... Training Loss 0.119...\n",
      "Step 47430 Training Accuracy 0.938... Training Loss 0.117...\n",
      "Step 47440 Training Accuracy 0.969... Training Loss 0.152...\n",
      "Step 47450 Training Accuracy 0.984... Training Loss 0.126...\n",
      "Step 47460 Training Accuracy 0.891... Training Loss 0.275...\n",
      "Step 47470 Training Accuracy 0.984... Training Loss 0.055...\n",
      "Step 47480 Training Accuracy 0.984... Training Loss 0.113...\n",
      "Step 47490 Training Accuracy 0.953... Training Loss 0.134...\n",
      "Step 47500 Training Accuracy 0.922... Training Loss 0.144...\n",
      "Step 47510 Training Accuracy 0.953... Training Loss 0.161...\n",
      "Step 47520 Training Accuracy 0.938... Training Loss 0.197...\n",
      "Step 47530 Training Accuracy 0.922... Training Loss 0.168...\n",
      "Step 47540 Training Accuracy 0.938... Training Loss 0.141...\n",
      "Step 47550 Training Accuracy 0.953... Training Loss 0.091...\n",
      "Step 47560 Training Accuracy 0.844... Training Loss 0.269...\n",
      "Step 47570 Training Accuracy 0.953... Training Loss 0.137...\n",
      "Step 47580 Training Accuracy 0.922... Training Loss 0.209...\n",
      "Step 47590 Training Accuracy 0.984... Training Loss 0.179...\n",
      "Step 47600 Training Accuracy 0.969... Training Loss 0.058...\n",
      "Step 47610 Training Accuracy 0.875... Training Loss 0.303...\n",
      "Step 47620 Training Accuracy 0.938... Training Loss 0.117...\n",
      "Step 47630 Training Accuracy 0.953... Training Loss 0.079...\n",
      "Step 47640 Training Accuracy 0.969... Training Loss 0.131...\n",
      "Step 47650 Training Accuracy 0.969... Training Loss 0.044...\n",
      "Step 47660 Training Accuracy 0.969... Training Loss 0.070...\n",
      "Step 47670 Training Accuracy 0.953... Training Loss 0.213...\n",
      "Step 47680 Training Accuracy 0.984... Training Loss 0.102...\n",
      "Step 47690 Training Accuracy 0.906... Training Loss 0.328...\n",
      "Step 47700 Training Accuracy 0.938... Training Loss 0.175...\n",
      "Step 47710 Training Accuracy 0.953... Training Loss 0.144...\n",
      "Step 47720 Training Accuracy 0.984... Training Loss 0.061...\n",
      "Step 47730 Training Accuracy 0.938... Training Loss 0.113...\n",
      "Step 47740 Training Accuracy 0.938... Training Loss 0.085...\n",
      "Step 47750 Training Accuracy 0.953... Training Loss 0.150...\n",
      "Step 47760 Training Accuracy 0.969... Training Loss 0.146...\n",
      "Step 47770 Training Accuracy 0.984... Training Loss 0.077...\n",
      "Step 47780 Training Accuracy 0.984... Training Loss 0.056...\n",
      "Step 47790 Training Accuracy 0.891... Training Loss 0.193...\n",
      "Step 47800 Training Accuracy 1.000... Training Loss 0.029...\n",
      "Step 47810 Training Accuracy 0.953... Training Loss 0.082...\n",
      "Step 47820 Training Accuracy 0.953... Training Loss 0.061...\n",
      "Step 47830 Training Accuracy 0.922... Training Loss 0.148...\n",
      "Step 47840 Training Accuracy 0.922... Training Loss 0.158...\n",
      "Step 47850 Training Accuracy 0.891... Training Loss 0.360...\n",
      "Step 47860 Training Accuracy 0.953... Training Loss 0.171...\n",
      "Step 47870 Training Accuracy 0.969... Training Loss 0.081...\n",
      "Step 47880 Training Accuracy 0.969... Training Loss 0.078...\n",
      "Step 47890 Training Accuracy 0.969... Training Loss 0.144...\n",
      "Step 47900 Training Accuracy 0.969... Training Loss 0.095...\n",
      "Step 47910 Training Accuracy 0.984... Training Loss 0.057...\n",
      "Step 47920 Training Accuracy 0.953... Training Loss 0.144...\n",
      "Step 47930 Training Accuracy 0.922... Training Loss 0.214...\n",
      "Step 47940 Training Accuracy 0.891... Training Loss 0.280...\n",
      "Step 47950 Training Accuracy 0.969... Training Loss 0.161...\n",
      "Step 47960 Training Accuracy 0.953... Training Loss 0.155...\n",
      "Step 47970 Training Accuracy 0.953... Training Loss 0.125...\n",
      "Step 47980 Training Accuracy 0.969... Training Loss 0.137...\n",
      "Step 47990 Training Accuracy 1.000... Training Loss 0.036...\n",
      "Step 48000 Training Accuracy 0.938... Training Loss 0.147...\n",
      "Writing checkpoint at step 48000\n",
      "Step 48010 Training Accuracy 0.922... Training Loss 0.182...\n",
      "Step 48020 Training Accuracy 0.906... Training Loss 0.269...\n",
      "Step 48030 Training Accuracy 0.922... Training Loss 0.160...\n",
      "Step 48040 Training Accuracy 0.969... Training Loss 0.081...\n",
      "Step 48050 Training Accuracy 1.000... Training Loss 0.048...\n",
      "Step 48060 Training Accuracy 0.953... Training Loss 0.172...\n",
      "Step 48070 Training Accuracy 0.922... Training Loss 0.287...\n",
      "Step 48080 Training Accuracy 0.953... Training Loss 0.115...\n",
      "Step 48090 Training Accuracy 0.984... Training Loss 0.077...\n",
      "Step 48100 Training Accuracy 0.984... Training Loss 0.100...\n",
      "Step 48110 Training Accuracy 0.938... Training Loss 0.104...\n",
      "Step 48120 Training Accuracy 0.953... Training Loss 0.206...\n",
      "Step 48130 Training Accuracy 0.969... Training Loss 0.101...\n",
      "Step 48140 Training Accuracy 0.922... Training Loss 0.222...\n",
      "Step 48150 Training Accuracy 0.969... Training Loss 0.054...\n",
      "Step 48160 Training Accuracy 0.938... Training Loss 0.322...\n",
      "Step 48170 Training Accuracy 0.969... Training Loss 0.104...\n",
      "Step 48180 Training Accuracy 0.969... Training Loss 0.098...\n",
      "Step 48190 Training Accuracy 0.922... Training Loss 0.086...\n",
      "Step 48200 Training Accuracy 0.984... Training Loss 0.064...\n",
      "Step 48210 Training Accuracy 1.000... Training Loss 0.066...\n",
      "Step 48220 Training Accuracy 0.984... Training Loss 0.118...\n",
      "Step 48230 Training Accuracy 0.984... Training Loss 0.040...\n",
      "Step 48240 Training Accuracy 0.906... Training Loss 0.147...\n",
      "Step 48250 Training Accuracy 0.953... Training Loss 0.190...\n",
      "Step 48260 Training Accuracy 0.969... Training Loss 0.161...\n",
      "Step 48270 Training Accuracy 0.969... Training Loss 0.105...\n",
      "Step 48280 Training Accuracy 0.938... Training Loss 0.169...\n",
      "Step 48290 Training Accuracy 0.969... Training Loss 0.276...\n",
      "Step 48300 Training Accuracy 0.938... Training Loss 0.271...\n",
      "Step 48310 Training Accuracy 0.875... Training Loss 0.284...\n",
      "Step 48320 Training Accuracy 0.984... Training Loss 0.037...\n",
      "Step 48330 Training Accuracy 0.984... Training Loss 0.064...\n",
      "Step 48340 Training Accuracy 0.984... Training Loss 0.127...\n",
      "Step 48350 Training Accuracy 0.969... Training Loss 0.126...\n",
      "Step 48360 Training Accuracy 0.984... Training Loss 0.175...\n",
      "Step 48370 Training Accuracy 0.969... Training Loss 0.086...\n",
      "Step 48380 Training Accuracy 0.938... Training Loss 0.132...\n",
      "Step 48390 Training Accuracy 0.969... Training Loss 0.124...\n",
      "Step 48400 Training Accuracy 0.984... Training Loss 0.089...\n",
      "Step 48410 Training Accuracy 0.984... Training Loss 0.105...\n",
      "Step 48420 Training Accuracy 0.953... Training Loss 0.041...\n",
      "Step 48430 Training Accuracy 0.969... Training Loss 0.120...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 48440 Training Accuracy 0.953... Training Loss 0.107...\n",
      "Step 48450 Training Accuracy 1.000... Training Loss 0.046...\n",
      "Step 48460 Training Accuracy 0.922... Training Loss 0.229...\n",
      "Step 48470 Training Accuracy 0.922... Training Loss 0.122...\n",
      "Step 48480 Training Accuracy 0.953... Training Loss 0.125...\n",
      "Step 48490 Training Accuracy 0.969... Training Loss 0.073...\n",
      "Step 48500 Training Accuracy 0.938... Training Loss 0.322...\n",
      "Step 48510 Training Accuracy 0.953... Training Loss 0.090...\n",
      "Step 48520 Training Accuracy 0.969... Training Loss 0.124...\n",
      "Step 48530 Training Accuracy 0.938... Training Loss 0.077...\n",
      "Step 48540 Training Accuracy 0.984... Training Loss 0.053...\n",
      "Step 48550 Training Accuracy 1.000... Training Loss 0.047...\n",
      "Step 48560 Training Accuracy 0.969... Training Loss 0.063...\n",
      "Step 48570 Training Accuracy 0.938... Training Loss 0.143...\n",
      "Step 48580 Training Accuracy 0.953... Training Loss 0.135...\n",
      "Step 48590 Training Accuracy 0.984... Training Loss 0.128...\n",
      "Step 48600 Training Accuracy 0.969... Training Loss 0.049...\n",
      "Step 48610 Training Accuracy 0.984... Training Loss 0.100...\n",
      "Step 48620 Training Accuracy 0.969... Training Loss 0.060...\n",
      "Step 48630 Training Accuracy 0.938... Training Loss 0.112...\n",
      "Step 48640 Training Accuracy 0.938... Training Loss 0.207...\n",
      "Step 48650 Training Accuracy 0.953... Training Loss 0.184...\n",
      "Step 48660 Training Accuracy 0.969... Training Loss 0.090...\n",
      "Step 48670 Training Accuracy 0.922... Training Loss 0.328...\n",
      "Step 48680 Training Accuracy 1.000... Training Loss 0.025...\n",
      "Step 48690 Training Accuracy 0.906... Training Loss 0.154...\n",
      "Step 48700 Training Accuracy 0.938... Training Loss 0.117...\n",
      "Step 48710 Training Accuracy 0.969... Training Loss 0.085...\n",
      "Step 48720 Training Accuracy 0.953... Training Loss 0.171...\n",
      "Step 48730 Training Accuracy 0.938... Training Loss 0.171...\n",
      "Step 48740 Training Accuracy 0.953... Training Loss 0.220...\n",
      "Step 48750 Training Accuracy 0.984... Training Loss 0.031...\n",
      "Step 48760 Training Accuracy 0.891... Training Loss 0.278...\n",
      "Step 48770 Training Accuracy 0.984... Training Loss 0.177...\n",
      "Step 48780 Training Accuracy 0.969... Training Loss 0.143...\n",
      "Step 48790 Training Accuracy 0.938... Training Loss 0.142...\n",
      "Step 48800 Training Accuracy 0.969... Training Loss 0.077...\n",
      "Step 48810 Training Accuracy 0.922... Training Loss 0.169...\n",
      "Step 48820 Training Accuracy 1.000... Training Loss 0.052...\n",
      "Step 48830 Training Accuracy 0.938... Training Loss 0.149...\n",
      "Step 48840 Training Accuracy 0.984... Training Loss 0.027...\n",
      "Step 48850 Training Accuracy 0.984... Training Loss 0.125...\n",
      "Step 48860 Training Accuracy 0.938... Training Loss 0.106...\n",
      "Step 48870 Training Accuracy 0.922... Training Loss 0.207...\n",
      "Step 48880 Training Accuracy 1.000... Training Loss 0.035...\n",
      "Step 48890 Training Accuracy 0.953... Training Loss 0.201...\n",
      "Step 48900 Training Accuracy 0.938... Training Loss 0.079...\n",
      "Step 48910 Training Accuracy 0.984... Training Loss 0.067...\n",
      "Step 48920 Training Accuracy 0.938... Training Loss 0.191...\n",
      "Step 48930 Training Accuracy 0.969... Training Loss 0.118...\n",
      "Step 48940 Training Accuracy 0.984... Training Loss 0.138...\n",
      "Step 48950 Training Accuracy 0.969... Training Loss 0.035...\n",
      "Step 48960 Training Accuracy 1.000... Training Loss 0.022...\n",
      "Step 48970 Training Accuracy 0.891... Training Loss 0.362...\n",
      "Step 48980 Training Accuracy 1.000... Training Loss 0.043...\n",
      "Step 48990 Training Accuracy 0.969... Training Loss 0.100...\n",
      "Step 49000 Training Accuracy 1.000... Training Loss 0.068...\n",
      "Writing checkpoint at step 49000\n",
      "Step 49010 Training Accuracy 0.922... Training Loss 0.287...\n",
      "Step 49020 Training Accuracy 0.938... Training Loss 0.118...\n",
      "Step 49030 Training Accuracy 0.969... Training Loss 0.069...\n",
      "Step 49040 Training Accuracy 0.969... Training Loss 0.116...\n",
      "Step 49050 Training Accuracy 0.984... Training Loss 0.043...\n",
      "Step 49060 Training Accuracy 0.953... Training Loss 0.084...\n",
      "Step 49070 Training Accuracy 0.938... Training Loss 0.194...\n",
      "Step 49080 Training Accuracy 0.969... Training Loss 0.132...\n",
      "Step 49090 Training Accuracy 0.922... Training Loss 0.223...\n",
      "Step 49100 Training Accuracy 0.906... Training Loss 0.201...\n",
      "Step 49110 Training Accuracy 0.969... Training Loss 0.040...\n",
      "Step 49120 Training Accuracy 0.953... Training Loss 0.288...\n",
      "Step 49130 Training Accuracy 0.953... Training Loss 0.090...\n",
      "Step 49140 Training Accuracy 0.969... Training Loss 0.117...\n",
      "Step 49150 Training Accuracy 0.953... Training Loss 0.074...\n",
      "Step 49160 Training Accuracy 0.953... Training Loss 0.058...\n",
      "Step 49170 Training Accuracy 0.984... Training Loss 0.030...\n",
      "Step 49180 Training Accuracy 0.922... Training Loss 0.279...\n",
      "Step 49190 Training Accuracy 0.938... Training Loss 0.151...\n",
      "Step 49200 Training Accuracy 0.969... Training Loss 0.120...\n",
      "Step 49210 Training Accuracy 0.938... Training Loss 0.120...\n",
      "Step 49220 Training Accuracy 0.844... Training Loss 0.350...\n",
      "Step 49230 Training Accuracy 0.953... Training Loss 0.108...\n",
      "Step 49240 Training Accuracy 0.953... Training Loss 0.198...\n",
      "Step 49250 Training Accuracy 0.953... Training Loss 0.162...\n",
      "Step 49260 Training Accuracy 0.969... Training Loss 0.120...\n",
      "Step 49270 Training Accuracy 0.969... Training Loss 0.090...\n",
      "Step 49280 Training Accuracy 0.969... Training Loss 0.126...\n",
      "Step 49290 Training Accuracy 0.953... Training Loss 0.121...\n",
      "Step 49300 Training Accuracy 0.953... Training Loss 0.173...\n",
      "Step 49310 Training Accuracy 0.938... Training Loss 0.305...\n",
      "Step 49320 Training Accuracy 0.984... Training Loss 0.069...\n",
      "Step 49330 Training Accuracy 0.969... Training Loss 0.158...\n",
      "Step 49340 Training Accuracy 0.984... Training Loss 0.110...\n",
      "Step 49350 Training Accuracy 1.000... Training Loss 0.089...\n",
      "Step 49360 Training Accuracy 0.906... Training Loss 0.166...\n",
      "Step 49370 Training Accuracy 0.969... Training Loss 0.079...\n",
      "Step 49380 Training Accuracy 0.969... Training Loss 0.113...\n",
      "Step 49390 Training Accuracy 0.953... Training Loss 0.211...\n",
      "Step 49400 Training Accuracy 0.969... Training Loss 0.085...\n",
      "Step 49410 Training Accuracy 0.969... Training Loss 0.112...\n",
      "Step 49420 Training Accuracy 0.906... Training Loss 0.247...\n",
      "Step 49430 Training Accuracy 0.969... Training Loss 0.188...\n",
      "Step 49440 Training Accuracy 0.875... Training Loss 0.414...\n",
      "Step 49450 Training Accuracy 0.938... Training Loss 0.159...\n",
      "Step 49460 Training Accuracy 0.938... Training Loss 0.322...\n",
      "Step 49470 Training Accuracy 1.000... Training Loss 0.086...\n",
      "Step 49480 Training Accuracy 0.984... Training Loss 0.099...\n",
      "Step 49490 Training Accuracy 0.953... Training Loss 0.158...\n",
      "Step 49500 Training Accuracy 0.938... Training Loss 0.134...\n",
      "Step 49510 Training Accuracy 0.953... Training Loss 0.102...\n",
      "Step 49520 Training Accuracy 0.922... Training Loss 0.249...\n",
      "Step 49530 Training Accuracy 0.969... Training Loss 0.051...\n",
      "Step 49540 Training Accuracy 0.938... Training Loss 0.126...\n",
      "Step 49550 Training Accuracy 0.984... Training Loss 0.043...\n",
      "Step 49560 Training Accuracy 0.984... Training Loss 0.115...\n",
      "Step 49570 Training Accuracy 0.938... Training Loss 0.238...\n",
      "Step 49580 Training Accuracy 0.938... Training Loss 0.162...\n",
      "Step 49590 Training Accuracy 0.969... Training Loss 0.084...\n",
      "Step 49600 Training Accuracy 0.969... Training Loss 0.111...\n",
      "Step 49610 Training Accuracy 0.969... Training Loss 0.024...\n",
      "Step 49620 Training Accuracy 0.984... Training Loss 0.071...\n",
      "Step 49630 Training Accuracy 1.000... Training Loss 0.051...\n",
      "Step 49640 Training Accuracy 0.953... Training Loss 0.220...\n",
      "Step 49650 Training Accuracy 0.938... Training Loss 0.217...\n",
      "Step 49660 Training Accuracy 0.922... Training Loss 0.193...\n",
      "Step 49670 Training Accuracy 0.969... Training Loss 0.048...\n",
      "Step 49680 Training Accuracy 0.969... Training Loss 0.205...\n",
      "Step 49690 Training Accuracy 0.969... Training Loss 0.154...\n",
      "Step 49700 Training Accuracy 1.000... Training Loss 0.015...\n",
      "Step 49710 Training Accuracy 0.984... Training Loss 0.200...\n",
      "Step 49720 Training Accuracy 0.922... Training Loss 0.224...\n",
      "Step 49730 Training Accuracy 0.984... Training Loss 0.062...\n",
      "Step 49740 Training Accuracy 0.953... Training Loss 0.076...\n",
      "Step 49750 Training Accuracy 0.875... Training Loss 0.313...\n",
      "Step 49760 Training Accuracy 0.969... Training Loss 0.152...\n",
      "Step 49770 Training Accuracy 0.938... Training Loss 0.170...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 49780 Training Accuracy 0.984... Training Loss 0.127...\n",
      "Step 49790 Training Accuracy 0.922... Training Loss 0.137...\n",
      "Step 49800 Training Accuracy 0.969... Training Loss 0.173...\n",
      "Step 49810 Training Accuracy 0.938... Training Loss 0.190...\n",
      "Step 49820 Training Accuracy 0.922... Training Loss 0.130...\n",
      "Step 49830 Training Accuracy 0.953... Training Loss 0.119...\n",
      "Step 49840 Training Accuracy 0.938... Training Loss 0.106...\n",
      "Step 49850 Training Accuracy 0.859... Training Loss 0.460...\n",
      "Step 49860 Training Accuracy 0.984... Training Loss 0.076...\n",
      "Step 49870 Training Accuracy 0.922... Training Loss 0.245...\n",
      "Step 49880 Training Accuracy 0.969... Training Loss 0.082...\n",
      "Step 49890 Training Accuracy 0.969... Training Loss 0.135...\n",
      "Step 49900 Training Accuracy 0.969... Training Loss 0.064...\n",
      "Step 49910 Training Accuracy 0.953... Training Loss 0.143...\n",
      "Step 49920 Training Accuracy 0.969... Training Loss 0.038...\n",
      "Step 49930 Training Accuracy 0.969... Training Loss 0.091...\n",
      "Step 49940 Training Accuracy 0.984... Training Loss 0.022...\n",
      "Step 49950 Training Accuracy 0.922... Training Loss 0.219...\n",
      "Step 49960 Training Accuracy 0.969... Training Loss 0.081...\n",
      "Step 49970 Training Accuracy 0.953... Training Loss 0.111...\n",
      "Step 49980 Training Accuracy 1.000... Training Loss 0.052...\n",
      "Step 49990 Training Accuracy 1.000... Training Loss 0.036...\n",
      "Step 50000 Training Accuracy 0.922... Training Loss 0.272...\n",
      "Writing checkpoint at step 50000\n",
      "Step 50010 Training Accuracy 0.969... Training Loss 0.097...\n",
      "Step 50020 Training Accuracy 0.953... Training Loss 0.088...\n",
      "Step 50030 Training Accuracy 0.984... Training Loss 0.072...\n",
      "Step 50040 Training Accuracy 0.969... Training Loss 0.069...\n",
      "Step 50050 Training Accuracy 0.984... Training Loss 0.101...\n",
      "Step 50060 Training Accuracy 0.953... Training Loss 0.118...\n",
      "Step 50070 Training Accuracy 0.969... Training Loss 0.104...\n",
      "Step 50080 Training Accuracy 1.000... Training Loss 0.061...\n",
      "Step 50090 Training Accuracy 0.953... Training Loss 0.109...\n",
      "Step 50100 Training Accuracy 0.969... Training Loss 0.088...\n",
      "Step 50110 Training Accuracy 0.938... Training Loss 0.175...\n",
      "Step 50120 Training Accuracy 0.969... Training Loss 0.145...\n",
      "Step 50130 Training Accuracy 0.922... Training Loss 0.236...\n",
      "Step 50140 Training Accuracy 0.953... Training Loss 0.102...\n",
      "Step 50150 Training Accuracy 0.984... Training Loss 0.072...\n",
      "Step 50160 Training Accuracy 0.891... Training Loss 0.300...\n",
      "Step 50170 Training Accuracy 0.984... Training Loss 0.088...\n",
      "Step 50180 Training Accuracy 0.953... Training Loss 0.172...\n",
      "Step 50190 Training Accuracy 0.984... Training Loss 0.092...\n",
      "Step 50200 Training Accuracy 0.953... Training Loss 0.144...\n",
      "Step 50210 Training Accuracy 0.984... Training Loss 0.059...\n",
      "Step 50220 Training Accuracy 0.984... Training Loss 0.069...\n",
      "Step 50230 Training Accuracy 0.984... Training Loss 0.078...\n",
      "Step 50240 Training Accuracy 0.938... Training Loss 0.190...\n",
      "Step 50250 Training Accuracy 0.969... Training Loss 0.160...\n",
      "Step 50260 Training Accuracy 0.922... Training Loss 0.129...\n",
      "Step 50270 Training Accuracy 1.000... Training Loss 0.087...\n",
      "Step 50280 Training Accuracy 0.938... Training Loss 0.145...\n",
      "Step 50290 Training Accuracy 0.969... Training Loss 0.176...\n",
      "Step 50300 Training Accuracy 0.969... Training Loss 0.074...\n",
      "Step 50310 Training Accuracy 0.922... Training Loss 0.409...\n",
      "Step 50320 Training Accuracy 0.938... Training Loss 0.409...\n",
      "Step 50330 Training Accuracy 0.969... Training Loss 0.161...\n",
      "Step 50340 Training Accuracy 0.984... Training Loss 0.052...\n",
      "Step 50350 Training Accuracy 0.969... Training Loss 0.117...\n",
      "Step 50360 Training Accuracy 0.984... Training Loss 0.115...\n",
      "Step 50370 Training Accuracy 0.891... Training Loss 0.207...\n",
      "Step 50380 Training Accuracy 0.938... Training Loss 0.097...\n",
      "Step 50390 Training Accuracy 0.922... Training Loss 0.089...\n",
      "Step 50400 Training Accuracy 0.953... Training Loss 0.257...\n",
      "Step 50410 Training Accuracy 0.969... Training Loss 0.111...\n",
      "Step 50420 Training Accuracy 0.938... Training Loss 0.160...\n",
      "Step 50430 Training Accuracy 0.922... Training Loss 0.184...\n",
      "Step 50440 Training Accuracy 0.984... Training Loss 0.059...\n",
      "Step 50450 Training Accuracy 0.938... Training Loss 0.146...\n",
      "Step 50460 Training Accuracy 0.938... Training Loss 0.174...\n",
      "Step 50470 Training Accuracy 0.953... Training Loss 0.173...\n",
      "Step 50480 Training Accuracy 0.969... Training Loss 0.089...\n",
      "Step 50490 Training Accuracy 0.969... Training Loss 0.066...\n",
      "Step 50500 Training Accuracy 0.953... Training Loss 0.117...\n",
      "Step 50510 Training Accuracy 0.922... Training Loss 0.182...\n",
      "Step 50520 Training Accuracy 0.953... Training Loss 0.118...\n",
      "Step 50530 Training Accuracy 0.969... Training Loss 0.067...\n",
      "Step 50540 Training Accuracy 0.969... Training Loss 0.120...\n",
      "Step 50550 Training Accuracy 1.000... Training Loss 0.031...\n",
      "Step 50560 Training Accuracy 0.984... Training Loss 0.061...\n",
      "Step 50570 Training Accuracy 0.953... Training Loss 0.177...\n",
      "Step 50580 Training Accuracy 0.969... Training Loss 0.081...\n",
      "Step 50590 Training Accuracy 0.922... Training Loss 0.236...\n",
      "Step 50600 Training Accuracy 0.984... Training Loss 0.074...\n",
      "Step 50610 Training Accuracy 0.922... Training Loss 0.213...\n",
      "Step 50620 Training Accuracy 0.969... Training Loss 0.217...\n",
      "Step 50630 Training Accuracy 0.984... Training Loss 0.112...\n",
      "Step 50640 Training Accuracy 0.984... Training Loss 0.047...\n",
      "Step 50650 Training Accuracy 0.984... Training Loss 0.114...\n",
      "Step 50660 Training Accuracy 0.953... Training Loss 0.254...\n",
      "Step 50670 Training Accuracy 0.953... Training Loss 0.049...\n",
      "Step 50680 Training Accuracy 0.984... Training Loss 0.098...\n",
      "Step 50690 Training Accuracy 0.984... Training Loss 0.036...\n",
      "Step 50700 Training Accuracy 1.000... Training Loss 0.031...\n",
      "Step 50710 Training Accuracy 0.984... Training Loss 0.118...\n",
      "Step 50720 Training Accuracy 0.953... Training Loss 0.089...\n",
      "Step 50730 Training Accuracy 1.000... Training Loss 0.045...\n",
      "Step 50740 Training Accuracy 1.000... Training Loss 0.119...\n",
      "Step 50750 Training Accuracy 1.000... Training Loss 0.071...\n",
      "Step 50760 Training Accuracy 1.000... Training Loss 0.013...\n",
      "Step 50770 Training Accuracy 0.984... Training Loss 0.063...\n",
      "Step 50780 Training Accuracy 0.922... Training Loss 0.364...\n",
      "Step 50790 Training Accuracy 0.984... Training Loss 0.100...\n",
      "Step 50800 Training Accuracy 0.984... Training Loss 0.107...\n",
      "Step 50810 Training Accuracy 0.938... Training Loss 0.126...\n",
      "Step 50820 Training Accuracy 0.953... Training Loss 0.113...\n",
      "Step 50830 Training Accuracy 0.969... Training Loss 0.080...\n",
      "Step 50840 Training Accuracy 0.984... Training Loss 0.128...\n",
      "Step 50850 Training Accuracy 0.984... Training Loss 0.021...\n",
      "Step 50860 Training Accuracy 0.938... Training Loss 0.144...\n",
      "Step 50870 Training Accuracy 0.953... Training Loss 0.148...\n",
      "Step 50880 Training Accuracy 0.984... Training Loss 0.057...\n",
      "Step 50890 Training Accuracy 0.953... Training Loss 0.209...\n",
      "Step 50900 Training Accuracy 0.938... Training Loss 0.184...\n",
      "Step 50910 Training Accuracy 0.953... Training Loss 0.109...\n",
      "Step 50920 Training Accuracy 0.969... Training Loss 0.080...\n",
      "Step 50930 Training Accuracy 0.969... Training Loss 0.105...\n",
      "Step 50940 Training Accuracy 0.969... Training Loss 0.062...\n",
      "Step 50950 Training Accuracy 0.969... Training Loss 0.073...\n",
      "Step 50960 Training Accuracy 0.938... Training Loss 0.133...\n",
      "Step 50970 Training Accuracy 0.969... Training Loss 0.081...\n",
      "Step 50980 Training Accuracy 0.984... Training Loss 0.107...\n",
      "Step 50990 Training Accuracy 0.969... Training Loss 0.093...\n",
      "Step 51000 Training Accuracy 0.984... Training Loss 0.080...\n",
      "Writing checkpoint at step 51000\n",
      "Step 51010 Training Accuracy 0.969... Training Loss 0.092...\n",
      "Step 51020 Training Accuracy 1.000... Training Loss 0.085...\n",
      "Step 51030 Training Accuracy 0.938... Training Loss 0.235...\n",
      "Step 51040 Training Accuracy 0.969... Training Loss 0.079...\n",
      "Step 51050 Training Accuracy 0.953... Training Loss 0.082...\n",
      "Step 51060 Training Accuracy 0.969... Training Loss 0.087...\n",
      "Step 51070 Training Accuracy 0.938... Training Loss 0.110...\n",
      "Step 51080 Training Accuracy 1.000... Training Loss 0.182...\n",
      "Step 51090 Training Accuracy 0.984... Training Loss 0.060...\n",
      "Step 51100 Training Accuracy 0.969... Training Loss 0.030...\n",
      "Step 51110 Training Accuracy 0.984... Training Loss 0.074...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 51120 Training Accuracy 0.938... Training Loss 0.099...\n",
      "Step 51130 Training Accuracy 0.969... Training Loss 0.082...\n",
      "Step 51140 Training Accuracy 0.938... Training Loss 0.066...\n",
      "Step 51150 Training Accuracy 0.969... Training Loss 0.074...\n",
      "Step 51160 Training Accuracy 0.969... Training Loss 0.102...\n",
      "Step 51170 Training Accuracy 0.984... Training Loss 0.045...\n",
      "Step 51180 Training Accuracy 0.984... Training Loss 0.091...\n",
      "Step 51190 Training Accuracy 0.984... Training Loss 0.061...\n",
      "Step 51200 Training Accuracy 0.969... Training Loss 0.120...\n",
      "Step 51210 Training Accuracy 0.953... Training Loss 0.096...\n",
      "Step 51220 Training Accuracy 1.000... Training Loss 0.063...\n",
      "Step 51230 Training Accuracy 0.953... Training Loss 0.097...\n",
      "Step 51240 Training Accuracy 0.953... Training Loss 0.033...\n",
      "Step 51250 Training Accuracy 0.891... Training Loss 0.273...\n",
      "Step 51260 Training Accuracy 0.938... Training Loss 0.130...\n",
      "Step 51270 Training Accuracy 0.938... Training Loss 0.257...\n",
      "Step 51280 Training Accuracy 0.969... Training Loss 0.139...\n",
      "Step 51290 Training Accuracy 0.938... Training Loss 0.129...\n",
      "Step 51300 Training Accuracy 0.938... Training Loss 0.147...\n",
      "Step 51310 Training Accuracy 0.953... Training Loss 0.103...\n",
      "Step 51320 Training Accuracy 0.984... Training Loss 0.076...\n",
      "Step 51330 Training Accuracy 0.984... Training Loss 0.142...\n",
      "Step 51340 Training Accuracy 0.953... Training Loss 0.089...\n",
      "Step 51350 Training Accuracy 0.984... Training Loss 0.046...\n",
      "Step 51360 Training Accuracy 1.000... Training Loss 0.023...\n",
      "Step 51370 Training Accuracy 0.984... Training Loss 0.047...\n",
      "Step 51380 Training Accuracy 0.953... Training Loss 0.073...\n",
      "Step 51390 Training Accuracy 0.969... Training Loss 0.075...\n",
      "Step 51400 Training Accuracy 0.969... Training Loss 0.177...\n",
      "Step 51410 Training Accuracy 0.969... Training Loss 0.074...\n",
      "Step 51420 Training Accuracy 0.984... Training Loss 0.079...\n",
      "Step 51430 Training Accuracy 0.984... Training Loss 0.123...\n",
      "Step 51440 Training Accuracy 0.906... Training Loss 0.252...\n",
      "Step 51450 Training Accuracy 0.953... Training Loss 0.139...\n",
      "Step 51460 Training Accuracy 0.969... Training Loss 0.108...\n",
      "Step 51470 Training Accuracy 0.969... Training Loss 0.182...\n",
      "Step 51480 Training Accuracy 0.969... Training Loss 0.092...\n",
      "Step 51490 Training Accuracy 0.922... Training Loss 0.105...\n",
      "Step 51500 Training Accuracy 0.984... Training Loss 0.042...\n",
      "Step 51510 Training Accuracy 0.984... Training Loss 0.209...\n",
      "Step 51520 Training Accuracy 0.938... Training Loss 0.142...\n",
      "Step 51530 Training Accuracy 0.969... Training Loss 0.153...\n",
      "Step 51540 Training Accuracy 0.969... Training Loss 0.183...\n",
      "Step 51550 Training Accuracy 0.953... Training Loss 0.091...\n",
      "Step 51560 Training Accuracy 0.953... Training Loss 0.140...\n",
      "Step 51570 Training Accuracy 0.953... Training Loss 0.135...\n",
      "Step 51580 Training Accuracy 0.984... Training Loss 0.070...\n",
      "Step 51590 Training Accuracy 0.984... Training Loss 0.136...\n",
      "Step 51600 Training Accuracy 0.984... Training Loss 0.049...\n",
      "Step 51610 Training Accuracy 0.953... Training Loss 0.141...\n",
      "Step 51620 Training Accuracy 0.969... Training Loss 0.046...\n",
      "Step 51630 Training Accuracy 1.000... Training Loss 0.046...\n",
      "Step 51640 Training Accuracy 0.953... Training Loss 0.069...\n",
      "Step 51650 Training Accuracy 0.891... Training Loss 0.290...\n",
      "Step 51660 Training Accuracy 0.969... Training Loss 0.144...\n",
      "Step 51670 Training Accuracy 0.984... Training Loss 0.129...\n",
      "Step 51680 Training Accuracy 0.984... Training Loss 0.058...\n",
      "Step 51690 Training Accuracy 0.969... Training Loss 0.073...\n",
      "Step 51700 Training Accuracy 0.984... Training Loss 0.069...\n",
      "Step 51710 Training Accuracy 0.891... Training Loss 0.159...\n",
      "Step 51720 Training Accuracy 0.984... Training Loss 0.062...\n",
      "Step 51730 Training Accuracy 0.984... Training Loss 0.062...\n",
      "Step 51740 Training Accuracy 0.969... Training Loss 0.141...\n",
      "Step 51750 Training Accuracy 0.984... Training Loss 0.077...\n",
      "Step 51760 Training Accuracy 0.984... Training Loss 0.095...\n",
      "Step 51770 Training Accuracy 0.984... Training Loss 0.130...\n",
      "Step 51780 Training Accuracy 0.922... Training Loss 0.276...\n",
      "Step 51790 Training Accuracy 0.906... Training Loss 0.256...\n",
      "Step 51800 Training Accuracy 0.906... Training Loss 0.351...\n",
      "Step 51810 Training Accuracy 0.969... Training Loss 0.066...\n",
      "Step 51820 Training Accuracy 1.000... Training Loss 0.053...\n",
      "Step 51830 Training Accuracy 0.984... Training Loss 0.026...\n",
      "Step 51840 Training Accuracy 0.953... Training Loss 0.101...\n",
      "Step 51850 Training Accuracy 0.969... Training Loss 0.126...\n",
      "Step 51860 Training Accuracy 0.969... Training Loss 0.111...\n",
      "Step 51870 Training Accuracy 0.984... Training Loss 0.042...\n",
      "Step 51880 Training Accuracy 0.938... Training Loss 0.205...\n",
      "Step 51890 Training Accuracy 1.000... Training Loss 0.106...\n",
      "Step 51900 Training Accuracy 0.953... Training Loss 0.085...\n",
      "Step 51910 Training Accuracy 0.938... Training Loss 0.086...\n",
      "Step 51920 Training Accuracy 0.938... Training Loss 0.131...\n",
      "Step 51930 Training Accuracy 0.953... Training Loss 0.129...\n",
      "Step 51940 Training Accuracy 1.000... Training Loss 0.023...\n",
      "Step 51950 Training Accuracy 0.953... Training Loss 0.221...\n",
      "Step 51960 Training Accuracy 0.984... Training Loss 0.023...\n",
      "Step 51970 Training Accuracy 0.953... Training Loss 0.097...\n",
      "Step 51980 Training Accuracy 0.922... Training Loss 0.139...\n",
      "Step 51990 Training Accuracy 0.969... Training Loss 0.134...\n",
      "Step 52000 Training Accuracy 0.953... Training Loss 0.234...\n",
      "Writing checkpoint at step 52000\n",
      "Step 52010 Training Accuracy 0.906... Training Loss 0.231...\n",
      "Step 52020 Training Accuracy 0.953... Training Loss 0.223...\n",
      "Step 52030 Training Accuracy 0.969... Training Loss 0.069...\n",
      "Step 52040 Training Accuracy 0.969... Training Loss 0.111...\n",
      "Step 52050 Training Accuracy 0.984... Training Loss 0.102...\n",
      "Step 52060 Training Accuracy 0.984... Training Loss 0.075...\n",
      "Step 52070 Training Accuracy 0.953... Training Loss 0.130...\n",
      "Step 52080 Training Accuracy 0.938... Training Loss 0.138...\n",
      "Step 52090 Training Accuracy 0.938... Training Loss 0.086...\n",
      "Step 52100 Training Accuracy 0.922... Training Loss 0.287...\n",
      "Step 52110 Training Accuracy 0.984... Training Loss 0.036...\n",
      "Step 52120 Training Accuracy 0.984... Training Loss 0.108...\n",
      "Step 52130 Training Accuracy 0.953... Training Loss 0.147...\n",
      "Step 52140 Training Accuracy 1.000... Training Loss 0.040...\n",
      "Step 52150 Training Accuracy 0.969... Training Loss 0.132...\n",
      "Step 52160 Training Accuracy 0.953... Training Loss 0.203...\n",
      "Step 52170 Training Accuracy 0.969... Training Loss 0.116...\n",
      "Step 52180 Training Accuracy 0.969... Training Loss 0.211...\n",
      "Step 52190 Training Accuracy 0.953... Training Loss 0.091...\n",
      "Step 52200 Training Accuracy 0.969... Training Loss 0.096...\n",
      "Step 52210 Training Accuracy 0.984... Training Loss 0.056...\n",
      "Step 52220 Training Accuracy 0.906... Training Loss 0.273...\n",
      "Step 52230 Training Accuracy 0.984... Training Loss 0.051...\n",
      "Step 52240 Training Accuracy 0.922... Training Loss 0.121...\n",
      "Step 52250 Training Accuracy 0.953... Training Loss 0.142...\n",
      "Step 52260 Training Accuracy 0.969... Training Loss 0.051...\n",
      "Step 52270 Training Accuracy 1.000... Training Loss 0.055...\n",
      "Step 52280 Training Accuracy 0.969... Training Loss 0.118...\n",
      "Step 52290 Training Accuracy 0.953... Training Loss 0.080...\n",
      "Step 52300 Training Accuracy 0.984... Training Loss 0.092...\n",
      "Step 52310 Training Accuracy 0.969... Training Loss 0.084...\n",
      "Step 52320 Training Accuracy 0.891... Training Loss 0.135...\n",
      "Step 52330 Training Accuracy 0.938... Training Loss 0.221...\n",
      "Step 52340 Training Accuracy 0.906... Training Loss 0.210...\n",
      "Step 52350 Training Accuracy 0.938... Training Loss 0.232...\n",
      "Step 52360 Training Accuracy 0.922... Training Loss 0.260...\n",
      "Step 52370 Training Accuracy 0.984... Training Loss 0.067...\n",
      "Step 52380 Training Accuracy 0.969... Training Loss 0.175...\n",
      "Step 52390 Training Accuracy 0.938... Training Loss 0.156...\n",
      "Step 52400 Training Accuracy 0.922... Training Loss 0.239...\n",
      "Step 52410 Training Accuracy 0.953... Training Loss 0.143...\n",
      "Step 52420 Training Accuracy 0.953... Training Loss 0.205...\n",
      "Step 52430 Training Accuracy 0.969... Training Loss 0.075...\n",
      "Step 52440 Training Accuracy 0.938... Training Loss 0.063...\n",
      "Step 52450 Training Accuracy 0.938... Training Loss 0.156...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 52460 Training Accuracy 0.984... Training Loss 0.060...\n",
      "Step 52470 Training Accuracy 0.969... Training Loss 0.060...\n",
      "Step 52480 Training Accuracy 1.000... Training Loss 0.023...\n",
      "Step 52490 Training Accuracy 0.984... Training Loss 0.023...\n",
      "Step 52500 Training Accuracy 0.922... Training Loss 0.155...\n",
      "Step 52510 Training Accuracy 0.953... Training Loss 0.057...\n",
      "Step 52520 Training Accuracy 0.969... Training Loss 0.075...\n",
      "Step 52530 Training Accuracy 0.984... Training Loss 0.071...\n",
      "Step 52540 Training Accuracy 0.984... Training Loss 0.132...\n",
      "Step 52550 Training Accuracy 0.938... Training Loss 0.165...\n",
      "Step 52560 Training Accuracy 0.969... Training Loss 0.081...\n",
      "Step 52570 Training Accuracy 0.938... Training Loss 0.139...\n",
      "Step 52580 Training Accuracy 0.953... Training Loss 0.114...\n",
      "Step 52590 Training Accuracy 0.953... Training Loss 0.199...\n",
      "Step 52600 Training Accuracy 0.953... Training Loss 0.158...\n",
      "Step 52610 Training Accuracy 0.984... Training Loss 0.045...\n",
      "Step 52620 Training Accuracy 0.953... Training Loss 0.063...\n",
      "Step 52630 Training Accuracy 0.969... Training Loss 0.084...\n",
      "Step 52640 Training Accuracy 0.984... Training Loss 0.031...\n",
      "Step 52650 Training Accuracy 0.953... Training Loss 0.166...\n",
      "Step 52660 Training Accuracy 0.906... Training Loss 0.199...\n",
      "Step 52670 Training Accuracy 0.969... Training Loss 0.068...\n",
      "Step 52680 Training Accuracy 0.922... Training Loss 0.247...\n",
      "Step 52690 Training Accuracy 0.953... Training Loss 0.144...\n",
      "Step 52700 Training Accuracy 0.938... Training Loss 0.159...\n",
      "Step 52710 Training Accuracy 0.953... Training Loss 0.129...\n",
      "Step 52720 Training Accuracy 0.953... Training Loss 0.200...\n",
      "Step 52730 Training Accuracy 0.984... Training Loss 0.053...\n",
      "Step 52740 Training Accuracy 0.984... Training Loss 0.065...\n",
      "Step 52750 Training Accuracy 0.938... Training Loss 0.190...\n",
      "Step 52760 Training Accuracy 0.953... Training Loss 0.162...\n",
      "Step 52770 Training Accuracy 0.984... Training Loss 0.066...\n",
      "Step 52780 Training Accuracy 1.000... Training Loss 0.033...\n",
      "Step 52790 Training Accuracy 0.984... Training Loss 0.171...\n",
      "Step 52800 Training Accuracy 0.984... Training Loss 0.093...\n",
      "Step 52810 Training Accuracy 0.969... Training Loss 0.062...\n",
      "Step 52820 Training Accuracy 0.984... Training Loss 0.078...\n",
      "Step 52830 Training Accuracy 0.984... Training Loss 0.135...\n",
      "Step 52840 Training Accuracy 0.969... Training Loss 0.165...\n",
      "Step 52850 Training Accuracy 0.969... Training Loss 0.118...\n",
      "Step 52860 Training Accuracy 0.953... Training Loss 0.222...\n",
      "Step 52870 Training Accuracy 0.984... Training Loss 0.078...\n",
      "Step 52880 Training Accuracy 0.969... Training Loss 0.090...\n",
      "Step 52890 Training Accuracy 0.953... Training Loss 0.072...\n",
      "Step 52900 Training Accuracy 0.984... Training Loss 0.102...\n",
      "Step 52910 Training Accuracy 0.984... Training Loss 0.106...\n",
      "Step 52920 Training Accuracy 0.953... Training Loss 0.106...\n",
      "Step 52930 Training Accuracy 0.953... Training Loss 0.174...\n",
      "Step 52940 Training Accuracy 1.000... Training Loss 0.079...\n",
      "Step 52950 Training Accuracy 0.938... Training Loss 0.175...\n",
      "Step 52960 Training Accuracy 0.984... Training Loss 0.069...\n",
      "Step 52970 Training Accuracy 0.953... Training Loss 0.158...\n",
      "Step 52980 Training Accuracy 0.969... Training Loss 0.130...\n",
      "Step 52990 Training Accuracy 0.984... Training Loss 0.040...\n",
      "Step 53000 Training Accuracy 0.906... Training Loss 0.224...\n",
      "Writing checkpoint at step 53000\n",
      "Step 53010 Training Accuracy 0.969... Training Loss 0.098...\n",
      "Step 53020 Training Accuracy 0.922... Training Loss 0.351...\n",
      "Step 53030 Training Accuracy 0.922... Training Loss 0.141...\n",
      "Step 53040 Training Accuracy 0.922... Training Loss 0.148...\n",
      "Step 53050 Training Accuracy 0.984... Training Loss 0.158...\n",
      "Step 53060 Training Accuracy 0.984... Training Loss 0.072...\n",
      "Step 53070 Training Accuracy 0.984... Training Loss 0.069...\n",
      "Step 53080 Training Accuracy 0.891... Training Loss 0.295...\n",
      "Step 53090 Training Accuracy 1.000... Training Loss 0.069...\n",
      "Step 53100 Training Accuracy 0.969... Training Loss 0.045...\n",
      "Step 53110 Training Accuracy 0.969... Training Loss 0.040...\n",
      "Step 53120 Training Accuracy 0.969... Training Loss 0.160...\n",
      "Step 53130 Training Accuracy 0.953... Training Loss 0.107...\n",
      "Step 53140 Training Accuracy 0.953... Training Loss 0.141...\n",
      "Step 53150 Training Accuracy 0.938... Training Loss 0.128...\n",
      "Step 53160 Training Accuracy 0.969... Training Loss 0.073...\n",
      "Step 53170 Training Accuracy 0.969... Training Loss 0.063...\n",
      "Step 53180 Training Accuracy 0.953... Training Loss 0.140...\n",
      "Step 53190 Training Accuracy 0.984... Training Loss 0.079...\n",
      "Step 53200 Training Accuracy 0.953... Training Loss 0.083...\n",
      "Step 53210 Training Accuracy 0.984... Training Loss 0.133...\n",
      "Step 53220 Training Accuracy 0.984... Training Loss 0.180...\n",
      "Step 53230 Training Accuracy 0.938... Training Loss 0.085...\n",
      "Step 53240 Training Accuracy 0.953... Training Loss 0.100...\n",
      "Step 53250 Training Accuracy 0.969... Training Loss 0.067...\n",
      "Step 53260 Training Accuracy 1.000... Training Loss 0.033...\n",
      "Step 53270 Training Accuracy 0.984... Training Loss 0.071...\n",
      "Step 53280 Training Accuracy 0.969... Training Loss 0.076...\n",
      "Step 53290 Training Accuracy 0.969... Training Loss 0.154...\n",
      "Step 53300 Training Accuracy 0.969... Training Loss 0.091...\n",
      "Step 53310 Training Accuracy 0.984... Training Loss 0.083...\n",
      "Step 53320 Training Accuracy 0.938... Training Loss 0.241...\n",
      "Step 53330 Training Accuracy 0.969... Training Loss 0.083...\n",
      "Step 53340 Training Accuracy 0.953... Training Loss 0.195...\n",
      "Step 53350 Training Accuracy 1.000... Training Loss 0.071...\n",
      "Step 53360 Training Accuracy 0.906... Training Loss 0.246...\n",
      "Step 53370 Training Accuracy 0.969... Training Loss 0.087...\n",
      "Step 53380 Training Accuracy 0.938... Training Loss 0.231...\n",
      "Step 53390 Training Accuracy 0.938... Training Loss 0.188...\n",
      "Step 53400 Training Accuracy 0.953... Training Loss 0.127...\n",
      "Step 53410 Training Accuracy 0.906... Training Loss 0.245...\n",
      "Step 53420 Training Accuracy 0.922... Training Loss 0.218...\n",
      "Step 53430 Training Accuracy 0.984... Training Loss 0.104...\n",
      "Step 53440 Training Accuracy 0.938... Training Loss 0.239...\n",
      "Step 53450 Training Accuracy 0.969... Training Loss 0.161...\n",
      "Step 53460 Training Accuracy 0.922... Training Loss 0.189...\n",
      "Step 53470 Training Accuracy 0.953... Training Loss 0.185...\n",
      "Step 53480 Training Accuracy 0.953... Training Loss 0.199...\n",
      "Step 53490 Training Accuracy 0.969... Training Loss 0.019...\n",
      "Step 53500 Training Accuracy 0.953... Training Loss 0.160...\n",
      "Step 53510 Training Accuracy 0.906... Training Loss 0.119...\n",
      "Step 53520 Training Accuracy 0.984... Training Loss 0.041...\n",
      "Step 53530 Training Accuracy 0.953... Training Loss 0.043...\n",
      "Step 53540 Training Accuracy 0.875... Training Loss 0.235...\n",
      "Step 53550 Training Accuracy 0.969... Training Loss 0.086...\n",
      "Step 53560 Training Accuracy 0.984... Training Loss 0.056...\n",
      "Step 53570 Training Accuracy 0.953... Training Loss 0.142...\n",
      "Step 53580 Training Accuracy 0.984... Training Loss 0.035...\n",
      "Step 53590 Training Accuracy 0.953... Training Loss 0.131...\n",
      "Step 53600 Training Accuracy 0.922... Training Loss 0.310...\n",
      "Step 53610 Training Accuracy 0.891... Training Loss 0.221...\n",
      "Step 53620 Training Accuracy 1.000... Training Loss 0.058...\n",
      "Step 53630 Training Accuracy 0.938... Training Loss 0.141...\n",
      "Step 53640 Training Accuracy 0.922... Training Loss 0.247...\n",
      "Step 53650 Training Accuracy 0.969... Training Loss 0.093...\n",
      "Step 53660 Training Accuracy 0.953... Training Loss 0.166...\n",
      "Step 53670 Training Accuracy 0.969... Training Loss 0.114...\n",
      "Step 53680 Training Accuracy 0.922... Training Loss 0.101...\n",
      "Step 53690 Training Accuracy 0.953... Training Loss 0.086...\n",
      "Step 53700 Training Accuracy 0.938... Training Loss 0.117...\n",
      "Step 53710 Training Accuracy 0.922... Training Loss 0.209...\n",
      "Step 53720 Training Accuracy 0.984... Training Loss 0.030...\n",
      "Step 53730 Training Accuracy 1.000... Training Loss 0.071...\n",
      "Step 53740 Training Accuracy 0.953... Training Loss 0.136...\n",
      "Step 53750 Training Accuracy 0.969... Training Loss 0.096...\n",
      "Step 53760 Training Accuracy 0.922... Training Loss 0.168...\n",
      "Step 53770 Training Accuracy 0.969... Training Loss 0.087...\n",
      "Step 53780 Training Accuracy 0.984... Training Loss 0.056...\n",
      "Step 53790 Training Accuracy 0.984... Training Loss 0.049...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 53800 Training Accuracy 0.953... Training Loss 0.103...\n",
      "Step 53810 Training Accuracy 0.984... Training Loss 0.120...\n",
      "Step 53820 Training Accuracy 0.969... Training Loss 0.128...\n",
      "Step 53830 Training Accuracy 1.000... Training Loss 0.060...\n",
      "Step 53840 Training Accuracy 0.969... Training Loss 0.130...\n",
      "Step 53850 Training Accuracy 0.953... Training Loss 0.151...\n",
      "Step 53860 Training Accuracy 0.953... Training Loss 0.165...\n",
      "Step 53870 Training Accuracy 0.953... Training Loss 0.098...\n",
      "Step 53880 Training Accuracy 0.938... Training Loss 0.126...\n",
      "Step 53890 Training Accuracy 0.969... Training Loss 0.128...\n",
      "Step 53900 Training Accuracy 0.875... Training Loss 0.432...\n",
      "Step 53910 Training Accuracy 1.000... Training Loss 0.082...\n",
      "Step 53920 Training Accuracy 0.953... Training Loss 0.166...\n",
      "Step 53930 Training Accuracy 0.969... Training Loss 0.092...\n",
      "Step 53940 Training Accuracy 1.000... Training Loss 0.043...\n",
      "Step 53950 Training Accuracy 0.984... Training Loss 0.111...\n",
      "Step 53960 Training Accuracy 0.969... Training Loss 0.136...\n",
      "Step 53970 Training Accuracy 1.000... Training Loss 0.070...\n",
      "Step 53980 Training Accuracy 0.828... Training Loss 0.321...\n",
      "Step 53990 Training Accuracy 0.984... Training Loss 0.193...\n",
      "Step 54000 Training Accuracy 0.969... Training Loss 0.129...\n",
      "Writing checkpoint at step 54000\n",
      "Step 54010 Training Accuracy 0.969... Training Loss 0.092...\n",
      "Step 54020 Training Accuracy 0.984... Training Loss 0.050...\n",
      "Step 54030 Training Accuracy 0.922... Training Loss 0.210...\n",
      "Step 54040 Training Accuracy 0.938... Training Loss 0.113...\n",
      "Step 54050 Training Accuracy 0.969... Training Loss 0.093...\n",
      "Step 54060 Training Accuracy 0.938... Training Loss 0.291...\n",
      "Step 54070 Training Accuracy 0.922... Training Loss 0.275...\n",
      "Step 54080 Training Accuracy 0.984... Training Loss 0.022...\n",
      "Step 54090 Training Accuracy 0.953... Training Loss 0.100...\n",
      "Step 54100 Training Accuracy 0.938... Training Loss 0.145...\n",
      "Step 54110 Training Accuracy 0.953... Training Loss 0.088...\n",
      "Step 54120 Training Accuracy 0.969... Training Loss 0.165...\n",
      "Step 54130 Training Accuracy 0.953... Training Loss 0.116...\n",
      "Step 54140 Training Accuracy 0.953... Training Loss 0.082...\n",
      "Step 54150 Training Accuracy 0.984... Training Loss 0.038...\n",
      "Step 54160 Training Accuracy 0.969... Training Loss 0.040...\n",
      "Step 54170 Training Accuracy 0.969... Training Loss 0.067...\n",
      "Step 54180 Training Accuracy 0.922... Training Loss 0.136...\n",
      "Step 54190 Training Accuracy 0.969... Training Loss 0.067...\n",
      "Step 54200 Training Accuracy 0.984... Training Loss 0.042...\n",
      "Step 54210 Training Accuracy 0.953... Training Loss 0.143...\n",
      "Step 54220 Training Accuracy 0.984... Training Loss 0.028...\n",
      "Step 54230 Training Accuracy 0.969... Training Loss 0.167...\n",
      "Step 54240 Training Accuracy 0.984... Training Loss 0.100...\n",
      "Step 54250 Training Accuracy 0.953... Training Loss 0.121...\n",
      "Step 54260 Training Accuracy 0.969... Training Loss 0.043...\n",
      "Step 54270 Training Accuracy 0.953... Training Loss 0.150...\n",
      "Step 54280 Training Accuracy 0.984... Training Loss 0.118...\n",
      "Step 54290 Training Accuracy 0.984... Training Loss 0.202...\n",
      "Step 54300 Training Accuracy 1.000... Training Loss 0.061...\n",
      "Step 54310 Training Accuracy 0.922... Training Loss 0.174...\n",
      "Step 54320 Training Accuracy 0.938... Training Loss 0.262...\n",
      "Step 54330 Training Accuracy 0.969... Training Loss 0.122...\n",
      "Step 54340 Training Accuracy 0.969... Training Loss 0.096...\n",
      "Step 54350 Training Accuracy 0.938... Training Loss 0.207...\n",
      "Step 54360 Training Accuracy 0.984... Training Loss 0.125...\n",
      "Step 54370 Training Accuracy 0.969... Training Loss 0.042...\n",
      "Step 54380 Training Accuracy 0.984... Training Loss 0.080...\n",
      "Step 54390 Training Accuracy 0.938... Training Loss 0.137...\n",
      "Step 54400 Training Accuracy 0.969... Training Loss 0.157...\n",
      "Step 54410 Training Accuracy 0.984... Training Loss 0.062...\n",
      "Step 54420 Training Accuracy 0.984... Training Loss 0.074...\n",
      "Step 54430 Training Accuracy 0.953... Training Loss 0.135...\n",
      "Step 54440 Training Accuracy 1.000... Training Loss 0.048...\n",
      "Step 54450 Training Accuracy 0.984... Training Loss 0.101...\n",
      "Step 54460 Training Accuracy 0.984... Training Loss 0.056...\n",
      "Step 54470 Training Accuracy 0.922... Training Loss 0.249...\n",
      "Step 54480 Training Accuracy 1.000... Training Loss 0.037...\n",
      "Step 54490 Training Accuracy 0.984... Training Loss 0.005...\n",
      "Step 54500 Training Accuracy 0.953... Training Loss 0.076...\n",
      "Step 54510 Training Accuracy 0.984... Training Loss 0.060...\n",
      "Step 54520 Training Accuracy 0.938... Training Loss 0.250...\n",
      "Step 54530 Training Accuracy 0.953... Training Loss 0.146...\n",
      "Step 54540 Training Accuracy 0.938... Training Loss 0.251...\n",
      "Step 54550 Training Accuracy 0.953... Training Loss 0.133...\n",
      "Step 54560 Training Accuracy 0.984... Training Loss 0.065...\n",
      "Step 54570 Training Accuracy 0.969... Training Loss 0.027...\n",
      "Step 54580 Training Accuracy 0.938... Training Loss 0.158...\n",
      "Step 54590 Training Accuracy 0.938... Training Loss 0.141...\n",
      "Step 54600 Training Accuracy 0.953... Training Loss 0.130...\n",
      "Step 54610 Training Accuracy 0.922... Training Loss 0.130...\n",
      "Step 54620 Training Accuracy 0.984... Training Loss 0.087...\n",
      "Step 54630 Training Accuracy 0.984... Training Loss 0.085...\n",
      "Step 54640 Training Accuracy 0.922... Training Loss 0.115...\n",
      "Step 54650 Training Accuracy 0.938... Training Loss 0.177...\n",
      "Step 54660 Training Accuracy 0.953... Training Loss 0.115...\n",
      "Step 54670 Training Accuracy 0.922... Training Loss 0.285...\n",
      "Step 54680 Training Accuracy 1.000... Training Loss 0.024...\n",
      "Step 54690 Training Accuracy 0.938... Training Loss 0.129...\n",
      "Step 54700 Training Accuracy 0.984... Training Loss 0.125...\n",
      "Step 54710 Training Accuracy 0.938... Training Loss 0.116...\n",
      "Step 54720 Training Accuracy 0.969... Training Loss 0.117...\n",
      "Step 54730 Training Accuracy 0.984... Training Loss 0.059...\n",
      "Step 54740 Training Accuracy 0.984... Training Loss 0.060...\n",
      "Step 54750 Training Accuracy 0.984... Training Loss 0.108...\n",
      "Step 54760 Training Accuracy 0.922... Training Loss 0.166...\n",
      "Step 54770 Training Accuracy 0.922... Training Loss 0.190...\n",
      "Step 54780 Training Accuracy 0.969... Training Loss 0.126...\n",
      "Step 54790 Training Accuracy 0.984... Training Loss 0.032...\n",
      "Step 54800 Training Accuracy 0.922... Training Loss 0.182...\n",
      "Step 54810 Training Accuracy 0.938... Training Loss 0.149...\n",
      "Step 54820 Training Accuracy 0.984... Training Loss 0.184...\n",
      "Step 54830 Training Accuracy 0.969... Training Loss 0.032...\n",
      "Step 54840 Training Accuracy 0.984... Training Loss 0.057...\n",
      "Step 54850 Training Accuracy 0.938... Training Loss 0.208...\n",
      "Step 54860 Training Accuracy 1.000... Training Loss 0.051...\n",
      "Step 54870 Training Accuracy 0.969... Training Loss 0.078...\n",
      "Step 54880 Training Accuracy 0.969... Training Loss 0.068...\n",
      "Step 54890 Training Accuracy 0.922... Training Loss 0.293...\n",
      "Step 54900 Training Accuracy 0.938... Training Loss 0.142...\n",
      "Step 54910 Training Accuracy 0.984... Training Loss 0.139...\n",
      "Step 54920 Training Accuracy 0.953... Training Loss 0.140...\n",
      "Step 54930 Training Accuracy 0.969... Training Loss 0.113...\n",
      "Step 54940 Training Accuracy 0.969... Training Loss 0.132...\n",
      "Step 54950 Training Accuracy 0.938... Training Loss 0.138...\n",
      "Step 54960 Training Accuracy 0.922... Training Loss 0.266...\n",
      "Step 54970 Training Accuracy 0.969... Training Loss 0.169...\n",
      "Step 54980 Training Accuracy 0.969... Training Loss 0.125...\n",
      "Step 54990 Training Accuracy 0.984... Training Loss 0.047...\n",
      "Step 55000 Training Accuracy 0.953... Training Loss 0.191...\n",
      "Writing checkpoint at step 55000\n",
      "Step 55010 Training Accuracy 0.953... Training Loss 0.070...\n",
      "Step 55020 Training Accuracy 0.969... Training Loss 0.087...\n",
      "Step 55030 Training Accuracy 0.938... Training Loss 0.064...\n",
      "Step 55040 Training Accuracy 0.953... Training Loss 0.122...\n",
      "Step 55050 Training Accuracy 0.953... Training Loss 0.100...\n",
      "Step 55060 Training Accuracy 0.984... Training Loss 0.087...\n",
      "Step 55070 Training Accuracy 0.938... Training Loss 0.064...\n",
      "Step 55080 Training Accuracy 0.969... Training Loss 0.194...\n",
      "Step 55090 Training Accuracy 0.984... Training Loss 0.081...\n",
      "Step 55100 Training Accuracy 0.938... Training Loss 0.115...\n",
      "Step 55110 Training Accuracy 0.953... Training Loss 0.209...\n",
      "Step 55120 Training Accuracy 0.984... Training Loss 0.175...\n",
      "Step 55130 Training Accuracy 0.984... Training Loss 0.084...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 55140 Training Accuracy 0.938... Training Loss 0.191...\n",
      "Step 55150 Training Accuracy 1.000... Training Loss 0.052...\n",
      "Step 55160 Training Accuracy 1.000... Training Loss 0.023...\n",
      "Step 55170 Training Accuracy 0.969... Training Loss 0.054...\n",
      "Step 55180 Training Accuracy 0.969... Training Loss 0.111...\n",
      "Step 55190 Training Accuracy 0.984... Training Loss 0.081...\n",
      "Step 55200 Training Accuracy 0.969... Training Loss 0.130...\n",
      "Step 55210 Training Accuracy 0.969... Training Loss 0.164...\n",
      "Step 55220 Training Accuracy 1.000... Training Loss 0.035...\n",
      "Step 55230 Training Accuracy 0.953... Training Loss 0.057...\n",
      "Step 55240 Training Accuracy 1.000... Training Loss 0.053...\n",
      "Step 55250 Training Accuracy 0.922... Training Loss 0.215...\n",
      "Step 55260 Training Accuracy 0.969... Training Loss 0.046...\n",
      "Step 55270 Training Accuracy 0.953... Training Loss 0.093...\n",
      "Step 55280 Training Accuracy 0.938... Training Loss 0.356...\n",
      "Step 55290 Training Accuracy 0.984... Training Loss 0.092...\n",
      "Step 55300 Training Accuracy 1.000... Training Loss 0.059...\n",
      "Step 55310 Training Accuracy 0.969... Training Loss 0.116...\n",
      "Step 55320 Training Accuracy 0.984... Training Loss 0.055...\n",
      "Step 55330 Training Accuracy 0.922... Training Loss 0.179...\n",
      "Step 55340 Training Accuracy 0.938... Training Loss 0.163...\n",
      "Step 55350 Training Accuracy 0.969... Training Loss 0.159...\n",
      "Step 55360 Training Accuracy 0.984... Training Loss 0.053...\n",
      "Step 55370 Training Accuracy 0.953... Training Loss 0.153...\n",
      "Step 55380 Training Accuracy 1.000... Training Loss 0.040...\n",
      "Step 55390 Training Accuracy 0.953... Training Loss 0.101...\n",
      "Step 55400 Training Accuracy 0.938... Training Loss 0.084...\n",
      "Step 55410 Training Accuracy 0.953... Training Loss 0.051...\n",
      "Step 55420 Training Accuracy 0.922... Training Loss 0.177...\n",
      "Step 55430 Training Accuracy 0.938... Training Loss 0.233...\n",
      "Step 55440 Training Accuracy 0.906... Training Loss 0.161...\n",
      "Step 55450 Training Accuracy 0.938... Training Loss 0.264...\n",
      "Step 55460 Training Accuracy 1.000... Training Loss 0.081...\n",
      "Step 55470 Training Accuracy 0.984... Training Loss 0.114...\n",
      "Step 55480 Training Accuracy 0.984... Training Loss 0.158...\n",
      "Step 55490 Training Accuracy 0.969... Training Loss 0.054...\n",
      "Step 55500 Training Accuracy 0.953... Training Loss 0.067...\n",
      "Step 55510 Training Accuracy 0.953... Training Loss 0.291...\n",
      "Step 55520 Training Accuracy 1.000... Training Loss 0.029...\n",
      "Step 55530 Training Accuracy 0.969... Training Loss 0.144...\n",
      "Step 55540 Training Accuracy 0.953... Training Loss 0.110...\n",
      "Step 55550 Training Accuracy 0.922... Training Loss 0.171...\n",
      "Step 55560 Training Accuracy 0.984... Training Loss 0.039...\n",
      "Step 55570 Training Accuracy 0.984... Training Loss 0.090...\n",
      "Step 55580 Training Accuracy 0.938... Training Loss 0.126...\n",
      "Step 55590 Training Accuracy 0.984... Training Loss 0.115...\n",
      "Step 55600 Training Accuracy 0.969... Training Loss 0.137...\n",
      "Step 55610 Training Accuracy 0.953... Training Loss 0.136...\n",
      "Step 55620 Training Accuracy 0.969... Training Loss 0.046...\n",
      "Step 55630 Training Accuracy 0.922... Training Loss 0.262...\n",
      "Step 55640 Training Accuracy 0.969... Training Loss 0.065...\n",
      "Step 55650 Training Accuracy 0.953... Training Loss 0.131...\n",
      "Step 55660 Training Accuracy 0.922... Training Loss 0.163...\n",
      "Step 55670 Training Accuracy 0.953... Training Loss 0.151...\n",
      "Step 55680 Training Accuracy 1.000... Training Loss 0.048...\n",
      "Step 55690 Training Accuracy 0.984... Training Loss 0.061...\n",
      "Step 55700 Training Accuracy 0.984... Training Loss 0.121...\n",
      "Step 55710 Training Accuracy 0.922... Training Loss 0.110...\n",
      "Step 55720 Training Accuracy 0.938... Training Loss 0.308...\n",
      "Step 55730 Training Accuracy 0.953... Training Loss 0.095...\n",
      "Step 55740 Training Accuracy 0.984... Training Loss 0.100...\n",
      "Step 55750 Training Accuracy 0.969... Training Loss 0.043...\n",
      "Step 55760 Training Accuracy 1.000... Training Loss 0.030...\n",
      "Step 55770 Training Accuracy 0.969... Training Loss 0.167...\n",
      "Step 55780 Training Accuracy 0.938... Training Loss 0.231...\n",
      "Step 55790 Training Accuracy 0.953... Training Loss 0.085...\n",
      "Step 55800 Training Accuracy 0.984... Training Loss 0.127...\n",
      "Step 55810 Training Accuracy 0.984... Training Loss 0.083...\n",
      "Step 55820 Training Accuracy 0.984... Training Loss 0.101...\n",
      "Step 55830 Training Accuracy 1.000... Training Loss 0.041...\n",
      "Step 55840 Training Accuracy 0.938... Training Loss 0.127...\n",
      "Step 55850 Training Accuracy 1.000... Training Loss 0.036...\n",
      "Step 55860 Training Accuracy 0.969... Training Loss 0.186...\n",
      "Step 55870 Training Accuracy 0.969... Training Loss 0.033...\n",
      "Step 55880 Training Accuracy 0.953... Training Loss 0.105...\n",
      "Step 55890 Training Accuracy 0.984... Training Loss 0.034...\n",
      "Step 55900 Training Accuracy 0.938... Training Loss 0.192...\n",
      "Step 55910 Training Accuracy 0.953... Training Loss 0.149...\n",
      "Step 55920 Training Accuracy 0.984... Training Loss 0.046...\n",
      "Step 55930 Training Accuracy 0.891... Training Loss 0.174...\n",
      "Step 55940 Training Accuracy 0.984... Training Loss 0.074...\n",
      "Step 55950 Training Accuracy 0.906... Training Loss 0.172...\n",
      "Step 55960 Training Accuracy 0.953... Training Loss 0.160...\n",
      "Step 55970 Training Accuracy 0.938... Training Loss 0.188...\n",
      "Step 55980 Training Accuracy 0.969... Training Loss 0.087...\n",
      "Step 55990 Training Accuracy 0.922... Training Loss 0.136...\n",
      "Step 56000 Training Accuracy 0.953... Training Loss 0.155...\n",
      "Writing checkpoint at step 56000\n",
      "Step 56010 Training Accuracy 0.922... Training Loss 0.164...\n",
      "Step 56020 Training Accuracy 0.953... Training Loss 0.117...\n",
      "Step 56030 Training Accuracy 0.938... Training Loss 0.096...\n",
      "Step 56040 Training Accuracy 0.984... Training Loss 0.050...\n",
      "Step 56050 Training Accuracy 1.000... Training Loss 0.028...\n",
      "Step 56060 Training Accuracy 0.953... Training Loss 0.095...\n",
      "Step 56070 Training Accuracy 0.938... Training Loss 0.097...\n",
      "Step 56080 Training Accuracy 0.969... Training Loss 0.093...\n",
      "Step 56090 Training Accuracy 0.969... Training Loss 0.104...\n",
      "Step 56100 Training Accuracy 0.922... Training Loss 0.102...\n",
      "Step 56110 Training Accuracy 0.969... Training Loss 0.060...\n",
      "Step 56120 Training Accuracy 0.969... Training Loss 0.115...\n",
      "Step 56130 Training Accuracy 1.000... Training Loss 0.058...\n",
      "Step 56140 Training Accuracy 0.984... Training Loss 0.070...\n",
      "Step 56150 Training Accuracy 0.969... Training Loss 0.140...\n",
      "Step 56160 Training Accuracy 0.969... Training Loss 0.095...\n",
      "Step 56170 Training Accuracy 0.953... Training Loss 0.148...\n",
      "Step 56180 Training Accuracy 0.984... Training Loss 0.033...\n",
      "Step 56190 Training Accuracy 0.969... Training Loss 0.213...\n",
      "Step 56200 Training Accuracy 0.938... Training Loss 0.155...\n",
      "Step 56210 Training Accuracy 0.984... Training Loss 0.057...\n",
      "Step 56220 Training Accuracy 0.953... Training Loss 0.149...\n",
      "Step 56230 Training Accuracy 0.953... Training Loss 0.138...\n",
      "Step 56240 Training Accuracy 0.938... Training Loss 0.096...\n",
      "Step 56250 Training Accuracy 0.969... Training Loss 0.113...\n",
      "Step 56260 Training Accuracy 0.953... Training Loss 0.077...\n",
      "Step 56270 Training Accuracy 1.000... Training Loss 0.088...\n",
      "Step 56280 Training Accuracy 0.984... Training Loss 0.030...\n",
      "Step 56290 Training Accuracy 0.984... Training Loss 0.082...\n",
      "Step 56300 Training Accuracy 0.969... Training Loss 0.140...\n",
      "Step 56310 Training Accuracy 0.969... Training Loss 0.149...\n",
      "Step 56320 Training Accuracy 0.922... Training Loss 0.149...\n",
      "Step 56330 Training Accuracy 0.891... Training Loss 0.305...\n",
      "Step 56340 Training Accuracy 0.969... Training Loss 0.156...\n",
      "Step 56350 Training Accuracy 0.969... Training Loss 0.028...\n",
      "Step 56360 Training Accuracy 0.969... Training Loss 0.170...\n",
      "Step 56370 Training Accuracy 0.906... Training Loss 0.363...\n",
      "Step 56380 Training Accuracy 0.984... Training Loss 0.071...\n",
      "Step 56390 Training Accuracy 0.969... Training Loss 0.211...\n",
      "Step 56400 Training Accuracy 0.891... Training Loss 0.340...\n",
      "Step 56410 Training Accuracy 0.953... Training Loss 0.076...\n",
      "Step 56420 Training Accuracy 1.000... Training Loss 0.057...\n",
      "Step 56430 Training Accuracy 0.969... Training Loss 0.059...\n",
      "Step 56440 Training Accuracy 1.000... Training Loss 0.067...\n",
      "Step 56450 Training Accuracy 0.969... Training Loss 0.031...\n",
      "Step 56460 Training Accuracy 0.953... Training Loss 0.219...\n",
      "Step 56470 Training Accuracy 1.000... Training Loss 0.043...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 56480 Training Accuracy 0.969... Training Loss 0.071...\n",
      "Step 56490 Training Accuracy 0.984... Training Loss 0.071...\n",
      "Step 56500 Training Accuracy 0.922... Training Loss 0.166...\n",
      "Step 56510 Training Accuracy 0.938... Training Loss 0.101...\n",
      "Step 56520 Training Accuracy 0.969... Training Loss 0.097...\n",
      "Step 56530 Training Accuracy 0.922... Training Loss 0.166...\n",
      "Step 56540 Training Accuracy 0.953... Training Loss 0.064...\n",
      "Step 56550 Training Accuracy 0.938... Training Loss 0.100...\n",
      "Step 56560 Training Accuracy 0.953... Training Loss 0.125...\n",
      "Step 56570 Training Accuracy 0.969... Training Loss 0.109...\n",
      "Step 56580 Training Accuracy 1.000... Training Loss 0.064...\n",
      "Step 56590 Training Accuracy 0.984... Training Loss 0.084...\n",
      "Step 56600 Training Accuracy 0.984... Training Loss 0.024...\n",
      "Step 56610 Training Accuracy 0.953... Training Loss 0.144...\n",
      "Step 56620 Training Accuracy 0.953... Training Loss 0.044...\n",
      "Step 56630 Training Accuracy 0.984... Training Loss 0.055...\n",
      "Step 56640 Training Accuracy 0.938... Training Loss 0.207...\n",
      "Step 56650 Training Accuracy 0.953... Training Loss 0.147...\n",
      "Step 56660 Training Accuracy 0.969... Training Loss 0.085...\n",
      "Step 56670 Training Accuracy 0.922... Training Loss 0.186...\n",
      "Step 56680 Training Accuracy 0.984... Training Loss 0.102...\n",
      "Step 56690 Training Accuracy 0.969... Training Loss 0.086...\n",
      "Step 56700 Training Accuracy 0.984... Training Loss 0.112...\n",
      "Step 56710 Training Accuracy 0.984... Training Loss 0.093...\n",
      "Step 56720 Training Accuracy 0.938... Training Loss 0.148...\n",
      "Step 56730 Training Accuracy 0.938... Training Loss 0.110...\n",
      "Step 56740 Training Accuracy 0.984... Training Loss 0.055...\n",
      "Step 56750 Training Accuracy 0.953... Training Loss 0.123...\n",
      "Step 56760 Training Accuracy 0.953... Training Loss 0.154...\n",
      "Step 56770 Training Accuracy 0.953... Training Loss 0.053...\n",
      "Step 56780 Training Accuracy 0.984... Training Loss 0.104...\n",
      "Step 56790 Training Accuracy 0.984... Training Loss 0.079...\n",
      "Step 56800 Training Accuracy 1.000... Training Loss 0.043...\n",
      "Step 56810 Training Accuracy 0.922... Training Loss 0.147...\n",
      "Step 56820 Training Accuracy 0.938... Training Loss 0.182...\n",
      "Step 56830 Training Accuracy 0.984... Training Loss 0.040...\n",
      "Step 56840 Training Accuracy 0.953... Training Loss 0.095...\n",
      "Step 56850 Training Accuracy 0.938... Training Loss 0.103...\n",
      "Step 56860 Training Accuracy 1.000... Training Loss 0.029...\n",
      "Step 56870 Training Accuracy 0.938... Training Loss 0.197...\n",
      "Step 56880 Training Accuracy 0.953... Training Loss 0.164...\n",
      "Step 56890 Training Accuracy 0.938... Training Loss 0.216...\n",
      "Step 56900 Training Accuracy 0.953... Training Loss 0.156...\n",
      "Step 56910 Training Accuracy 0.953... Training Loss 0.205...\n",
      "Step 56920 Training Accuracy 0.938... Training Loss 0.226...\n",
      "Step 56930 Training Accuracy 0.969... Training Loss 0.062...\n",
      "Step 56940 Training Accuracy 0.938... Training Loss 0.119...\n",
      "Step 56950 Training Accuracy 0.984... Training Loss 0.053...\n",
      "Step 56960 Training Accuracy 0.953... Training Loss 0.109...\n",
      "Step 56970 Training Accuracy 1.000... Training Loss 0.025...\n",
      "Step 56980 Training Accuracy 0.969... Training Loss 0.141...\n",
      "Step 56990 Training Accuracy 0.984... Training Loss 0.067...\n",
      "Step 57000 Training Accuracy 0.969... Training Loss 0.090...\n",
      "Writing checkpoint at step 57000\n",
      "Step 57010 Training Accuracy 0.969... Training Loss 0.073...\n",
      "Step 57020 Training Accuracy 1.000... Training Loss 0.028...\n",
      "Step 57030 Training Accuracy 0.984... Training Loss 0.165...\n",
      "Step 57040 Training Accuracy 0.953... Training Loss 0.189...\n",
      "Step 57050 Training Accuracy 0.953... Training Loss 0.126...\n",
      "Step 57060 Training Accuracy 0.953... Training Loss 0.211...\n",
      "Step 57070 Training Accuracy 0.984... Training Loss 0.028...\n",
      "Step 57080 Training Accuracy 0.984... Training Loss 0.016...\n",
      "Step 57090 Training Accuracy 0.969... Training Loss 0.099...\n",
      "Step 57100 Training Accuracy 0.938... Training Loss 0.090...\n",
      "Step 57110 Training Accuracy 0.969... Training Loss 0.092...\n",
      "Step 57120 Training Accuracy 0.953... Training Loss 0.162...\n",
      "Step 57130 Training Accuracy 0.938... Training Loss 0.191...\n",
      "Step 57140 Training Accuracy 0.969... Training Loss 0.116...\n",
      "Step 57150 Training Accuracy 0.938... Training Loss 0.189...\n",
      "Step 57160 Training Accuracy 0.953... Training Loss 0.081...\n",
      "Step 57170 Training Accuracy 0.938... Training Loss 0.088...\n",
      "Step 57180 Training Accuracy 0.938... Training Loss 0.179...\n",
      "Step 57190 Training Accuracy 0.938... Training Loss 0.223...\n",
      "Step 57200 Training Accuracy 0.969... Training Loss 0.107...\n",
      "Step 57210 Training Accuracy 1.000... Training Loss 0.046...\n",
      "Step 57220 Training Accuracy 0.984... Training Loss 0.032...\n",
      "Step 57230 Training Accuracy 0.953... Training Loss 0.155...\n",
      "Step 57240 Training Accuracy 0.969... Training Loss 0.080...\n",
      "Step 57250 Training Accuracy 0.922... Training Loss 0.104...\n",
      "Step 57260 Training Accuracy 0.984... Training Loss 0.030...\n",
      "Step 57270 Training Accuracy 0.922... Training Loss 0.223...\n",
      "Step 57280 Training Accuracy 0.938... Training Loss 0.127...\n",
      "Step 57290 Training Accuracy 0.953... Training Loss 0.124...\n",
      "Step 57300 Training Accuracy 0.984... Training Loss 0.136...\n",
      "Step 57310 Training Accuracy 0.953... Training Loss 0.220...\n",
      "Step 57320 Training Accuracy 0.953... Training Loss 0.131...\n",
      "Step 57330 Training Accuracy 0.938... Training Loss 0.101...\n",
      "Step 57340 Training Accuracy 0.984... Training Loss 0.077...\n",
      "Step 57350 Training Accuracy 0.953... Training Loss 0.135...\n",
      "Step 57360 Training Accuracy 0.984... Training Loss 0.097...\n",
      "Step 57370 Training Accuracy 0.969... Training Loss 0.111...\n",
      "Step 57380 Training Accuracy 0.922... Training Loss 0.247...\n",
      "Step 57390 Training Accuracy 0.906... Training Loss 0.287...\n",
      "Step 57400 Training Accuracy 0.953... Training Loss 0.194...\n",
      "Step 57410 Training Accuracy 0.984... Training Loss 0.062...\n",
      "Step 57420 Training Accuracy 0.969... Training Loss 0.059...\n",
      "Step 57430 Training Accuracy 0.969... Training Loss 0.198...\n",
      "Step 57440 Training Accuracy 0.984... Training Loss 0.041...\n",
      "Step 57450 Training Accuracy 0.969... Training Loss 0.129...\n",
      "Step 57460 Training Accuracy 0.938... Training Loss 0.071...\n",
      "Step 57470 Training Accuracy 0.984... Training Loss 0.084...\n",
      "Step 57480 Training Accuracy 0.969... Training Loss 0.031...\n",
      "Step 57490 Training Accuracy 0.969... Training Loss 0.096...\n",
      "Step 57500 Training Accuracy 0.922... Training Loss 0.199...\n",
      "Step 57510 Training Accuracy 1.000... Training Loss 0.040...\n",
      "Step 57520 Training Accuracy 0.969... Training Loss 0.199...\n",
      "Step 57530 Training Accuracy 1.000... Training Loss 0.018...\n",
      "Step 57540 Training Accuracy 0.906... Training Loss 0.273...\n",
      "Step 57550 Training Accuracy 0.953... Training Loss 0.091...\n",
      "Step 57560 Training Accuracy 1.000... Training Loss 0.046...\n",
      "Step 57570 Training Accuracy 0.969... Training Loss 0.109...\n",
      "Step 57580 Training Accuracy 0.953... Training Loss 0.145...\n",
      "Step 57590 Training Accuracy 0.984... Training Loss 0.064...\n",
      "Step 57600 Training Accuracy 0.938... Training Loss 0.134...\n",
      "Step 57610 Training Accuracy 1.000... Training Loss 0.073...\n",
      "Step 57620 Training Accuracy 0.984... Training Loss 0.028...\n",
      "Step 57630 Training Accuracy 0.969... Training Loss 0.085...\n",
      "Step 57640 Training Accuracy 0.969... Training Loss 0.159...\n",
      "Step 57650 Training Accuracy 0.984... Training Loss 0.086...\n",
      "Step 57660 Training Accuracy 0.938... Training Loss 0.222...\n",
      "Step 57670 Training Accuracy 1.000... Training Loss 0.038...\n",
      "Step 57680 Training Accuracy 0.969... Training Loss 0.058...\n",
      "Step 57690 Training Accuracy 0.984... Training Loss 0.063...\n",
      "Step 57700 Training Accuracy 0.969... Training Loss 0.053...\n",
      "Step 57710 Training Accuracy 0.984... Training Loss 0.042...\n",
      "Step 57720 Training Accuracy 0.938... Training Loss 0.163...\n",
      "Step 57730 Training Accuracy 0.984... Training Loss 0.163...\n",
      "Step 57740 Training Accuracy 0.984... Training Loss 0.128...\n",
      "Step 57750 Training Accuracy 0.953... Training Loss 0.147...\n",
      "Step 57760 Training Accuracy 0.984... Training Loss 0.047...\n",
      "Step 57770 Training Accuracy 0.969... Training Loss 0.163...\n",
      "Step 57780 Training Accuracy 0.938... Training Loss 0.127...\n",
      "Step 57790 Training Accuracy 1.000... Training Loss 0.062...\n",
      "Step 57800 Training Accuracy 0.969... Training Loss 0.033...\n",
      "Step 57810 Training Accuracy 0.953... Training Loss 0.091...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 57820 Training Accuracy 0.969... Training Loss 0.159...\n",
      "Step 57830 Training Accuracy 0.938... Training Loss 0.116...\n",
      "Step 57840 Training Accuracy 0.984... Training Loss 0.108...\n",
      "Step 57850 Training Accuracy 0.922... Training Loss 0.146...\n",
      "Step 57860 Training Accuracy 1.000... Training Loss 0.042...\n",
      "Step 57870 Training Accuracy 0.953... Training Loss 0.045...\n",
      "Step 57880 Training Accuracy 0.953... Training Loss 0.114...\n",
      "Step 57890 Training Accuracy 0.984... Training Loss 0.063...\n",
      "Step 57900 Training Accuracy 0.984... Training Loss 0.077...\n",
      "Step 57910 Training Accuracy 0.953... Training Loss 0.114...\n",
      "Step 57920 Training Accuracy 0.922... Training Loss 0.138...\n",
      "Step 57930 Training Accuracy 1.000... Training Loss 0.039...\n",
      "Step 57940 Training Accuracy 0.938... Training Loss 0.082...\n",
      "Step 57950 Training Accuracy 0.969... Training Loss 0.100...\n",
      "Step 57960 Training Accuracy 0.938... Training Loss 0.087...\n",
      "Step 57970 Training Accuracy 0.969... Training Loss 0.078...\n",
      "Step 57980 Training Accuracy 0.984... Training Loss 0.094...\n",
      "Step 57990 Training Accuracy 0.969... Training Loss 0.128...\n",
      "Step 58000 Training Accuracy 0.953... Training Loss 0.139...\n",
      "Writing checkpoint at step 58000\n",
      "Step 58010 Training Accuracy 0.938... Training Loss 0.059...\n",
      "Step 58020 Training Accuracy 0.938... Training Loss 0.252...\n",
      "Step 58030 Training Accuracy 0.953... Training Loss 0.075...\n",
      "Step 58040 Training Accuracy 0.938... Training Loss 0.170...\n",
      "Step 58050 Training Accuracy 0.984... Training Loss 0.036...\n",
      "Step 58060 Training Accuracy 0.984... Training Loss 0.026...\n",
      "Step 58070 Training Accuracy 0.953... Training Loss 0.138...\n",
      "Step 58080 Training Accuracy 0.953... Training Loss 0.117...\n",
      "Step 58090 Training Accuracy 0.938... Training Loss 0.185...\n",
      "Step 58100 Training Accuracy 0.969... Training Loss 0.132...\n",
      "Step 58110 Training Accuracy 0.922... Training Loss 0.190...\n",
      "Step 58120 Training Accuracy 0.969... Training Loss 0.098...\n",
      "Step 58130 Training Accuracy 0.953... Training Loss 0.166...\n",
      "Step 58140 Training Accuracy 0.984... Training Loss 0.037...\n",
      "Step 58150 Training Accuracy 0.953... Training Loss 0.151...\n",
      "Step 58160 Training Accuracy 0.906... Training Loss 0.114...\n",
      "Step 58170 Training Accuracy 0.984... Training Loss 0.126...\n",
      "Step 58180 Training Accuracy 0.953... Training Loss 0.090...\n",
      "Step 58190 Training Accuracy 0.984... Training Loss 0.083...\n",
      "Step 58200 Training Accuracy 0.953... Training Loss 0.081...\n",
      "Step 58210 Training Accuracy 0.984... Training Loss 0.088...\n",
      "Step 58220 Training Accuracy 1.000... Training Loss 0.041...\n",
      "Step 58230 Training Accuracy 0.953... Training Loss 0.121...\n",
      "Step 58240 Training Accuracy 0.984... Training Loss 0.072...\n",
      "Step 58250 Training Accuracy 0.984... Training Loss 0.041...\n",
      "Step 58260 Training Accuracy 1.000... Training Loss 0.013...\n",
      "Step 58270 Training Accuracy 0.938... Training Loss 0.125...\n",
      "Step 58280 Training Accuracy 0.953... Training Loss 0.204...\n",
      "Step 58290 Training Accuracy 1.000... Training Loss 0.040...\n",
      "Step 58300 Training Accuracy 0.984... Training Loss 0.077...\n",
      "Step 58310 Training Accuracy 0.938... Training Loss 0.136...\n",
      "Step 58320 Training Accuracy 0.938... Training Loss 0.152...\n",
      "Step 58330 Training Accuracy 0.953... Training Loss 0.137...\n",
      "Step 58340 Training Accuracy 0.875... Training Loss 0.408...\n",
      "Step 58350 Training Accuracy 0.953... Training Loss 0.146...\n",
      "Step 58360 Training Accuracy 0.969... Training Loss 0.103...\n",
      "Step 58370 Training Accuracy 0.953... Training Loss 0.121...\n",
      "Step 58380 Training Accuracy 0.969... Training Loss 0.045...\n",
      "Step 58390 Training Accuracy 0.969... Training Loss 0.075...\n",
      "Step 58400 Training Accuracy 0.969... Training Loss 0.186...\n",
      "Step 58410 Training Accuracy 0.969... Training Loss 0.135...\n",
      "Step 58420 Training Accuracy 0.969... Training Loss 0.078...\n",
      "Step 58430 Training Accuracy 0.969... Training Loss 0.099...\n",
      "Step 58440 Training Accuracy 0.891... Training Loss 0.340...\n",
      "Step 58450 Training Accuracy 0.938... Training Loss 0.195...\n",
      "Step 58460 Training Accuracy 0.938... Training Loss 0.072...\n",
      "Step 58470 Training Accuracy 0.984... Training Loss 0.042...\n",
      "Step 58480 Training Accuracy 0.922... Training Loss 0.198...\n",
      "Step 58490 Training Accuracy 0.969... Training Loss 0.135...\n",
      "Step 58500 Training Accuracy 0.953... Training Loss 0.031...\n",
      "Step 58510 Training Accuracy 1.000... Training Loss 0.077...\n",
      "Step 58520 Training Accuracy 0.953... Training Loss 0.092...\n",
      "Step 58530 Training Accuracy 0.969... Training Loss 0.099...\n",
      "Step 58540 Training Accuracy 0.906... Training Loss 0.209...\n",
      "Step 58550 Training Accuracy 0.984... Training Loss 0.073...\n",
      "Step 58560 Training Accuracy 0.969... Training Loss 0.145...\n",
      "Step 58570 Training Accuracy 0.969... Training Loss 0.109...\n",
      "Step 58580 Training Accuracy 0.969... Training Loss 0.050...\n",
      "Step 58590 Training Accuracy 0.984... Training Loss 0.157...\n",
      "Step 58600 Training Accuracy 1.000... Training Loss 0.026...\n",
      "Step 58610 Training Accuracy 0.969... Training Loss 0.098...\n",
      "Step 58620 Training Accuracy 0.906... Training Loss 0.251...\n",
      "Step 58630 Training Accuracy 0.969... Training Loss 0.093...\n",
      "Step 58640 Training Accuracy 0.953... Training Loss 0.079...\n",
      "Step 58650 Training Accuracy 0.984... Training Loss 0.054...\n",
      "Step 58660 Training Accuracy 0.922... Training Loss 0.099...\n",
      "Step 58670 Training Accuracy 0.984... Training Loss 0.076...\n",
      "Step 58680 Training Accuracy 0.984... Training Loss 0.022...\n",
      "Step 58690 Training Accuracy 0.969... Training Loss 0.123...\n",
      "Step 58700 Training Accuracy 0.938... Training Loss 0.099...\n",
      "Step 58710 Training Accuracy 0.953... Training Loss 0.080...\n",
      "Step 58720 Training Accuracy 0.984... Training Loss 0.083...\n",
      "Step 58730 Training Accuracy 0.969... Training Loss 0.035...\n",
      "Step 58740 Training Accuracy 0.969... Training Loss 0.066...\n",
      "Step 58750 Training Accuracy 0.969... Training Loss 0.186...\n",
      "Step 58760 Training Accuracy 0.969... Training Loss 0.070...\n",
      "Step 58770 Training Accuracy 0.938... Training Loss 0.052...\n",
      "Step 58780 Training Accuracy 0.984... Training Loss 0.085...\n",
      "Step 58790 Training Accuracy 0.953... Training Loss 0.129...\n",
      "Step 58800 Training Accuracy 0.922... Training Loss 0.110...\n",
      "Step 58810 Training Accuracy 0.969... Training Loss 0.048...\n",
      "Step 58820 Training Accuracy 0.922... Training Loss 0.236...\n",
      "Step 58830 Training Accuracy 0.969... Training Loss 0.076...\n",
      "Step 58840 Training Accuracy 0.953... Training Loss 0.147...\n",
      "Step 58850 Training Accuracy 0.922... Training Loss 0.242...\n",
      "Step 58860 Training Accuracy 0.969... Training Loss 0.084...\n",
      "Step 58870 Training Accuracy 0.953... Training Loss 0.086...\n",
      "Step 58880 Training Accuracy 0.969... Training Loss 0.093...\n",
      "Step 58890 Training Accuracy 0.969... Training Loss 0.093...\n",
      "Step 58900 Training Accuracy 0.969... Training Loss 0.122...\n",
      "Step 58910 Training Accuracy 0.969... Training Loss 0.050...\n",
      "Step 58920 Training Accuracy 0.938... Training Loss 0.107...\n",
      "Step 58930 Training Accuracy 0.953... Training Loss 0.180...\n",
      "Step 58940 Training Accuracy 0.922... Training Loss 0.217...\n",
      "Step 58950 Training Accuracy 0.953... Training Loss 0.160...\n",
      "Step 58960 Training Accuracy 0.953... Training Loss 0.109...\n",
      "Step 58970 Training Accuracy 0.984... Training Loss 0.054...\n",
      "Step 58980 Training Accuracy 0.969... Training Loss 0.043...\n",
      "Step 58990 Training Accuracy 0.953... Training Loss 0.081...\n",
      "Step 59000 Training Accuracy 0.953... Training Loss 0.096...\n",
      "Writing checkpoint at step 59000\n",
      "Step 59010 Training Accuracy 0.938... Training Loss 0.239...\n",
      "Step 59020 Training Accuracy 0.984... Training Loss 0.108...\n",
      "Step 59030 Training Accuracy 0.984... Training Loss 0.124...\n",
      "Step 59040 Training Accuracy 0.953... Training Loss 0.135...\n",
      "Step 59050 Training Accuracy 1.000... Training Loss 0.054...\n",
      "Step 59060 Training Accuracy 0.953... Training Loss 0.108...\n",
      "Step 59070 Training Accuracy 0.969... Training Loss 0.081...\n",
      "Step 59080 Training Accuracy 0.969... Training Loss 0.091...\n",
      "Step 59090 Training Accuracy 0.953... Training Loss 0.155...\n",
      "Step 59100 Training Accuracy 0.969... Training Loss 0.106...\n",
      "Step 59110 Training Accuracy 0.953... Training Loss 0.111...\n",
      "Step 59120 Training Accuracy 0.969... Training Loss 0.081...\n",
      "Step 59130 Training Accuracy 0.938... Training Loss 0.318...\n",
      "Step 59140 Training Accuracy 0.984... Training Loss 0.078...\n",
      "Step 59150 Training Accuracy 1.000... Training Loss 0.065...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 59160 Training Accuracy 0.953... Training Loss 0.214...\n",
      "Step 59170 Training Accuracy 0.984... Training Loss 0.109...\n",
      "Step 59180 Training Accuracy 0.984... Training Loss 0.046...\n",
      "Step 59190 Training Accuracy 0.953... Training Loss 0.111...\n",
      "Step 59200 Training Accuracy 0.953... Training Loss 0.297...\n",
      "Step 59210 Training Accuracy 0.953... Training Loss 0.119...\n",
      "Step 59220 Training Accuracy 0.938... Training Loss 0.096...\n",
      "Step 59230 Training Accuracy 1.000... Training Loss 0.026...\n",
      "Step 59240 Training Accuracy 0.938... Training Loss 0.184...\n",
      "Step 59250 Training Accuracy 0.969... Training Loss 0.090...\n",
      "Step 59260 Training Accuracy 0.984... Training Loss 0.068...\n",
      "Step 59270 Training Accuracy 0.969... Training Loss 0.084...\n",
      "Step 59280 Training Accuracy 0.984... Training Loss 0.032...\n",
      "Step 59290 Training Accuracy 0.906... Training Loss 0.247...\n",
      "Step 59300 Training Accuracy 0.984... Training Loss 0.089...\n",
      "Step 59310 Training Accuracy 0.953... Training Loss 0.128...\n",
      "Step 59320 Training Accuracy 0.969... Training Loss 0.062...\n",
      "Step 59330 Training Accuracy 0.922... Training Loss 0.280...\n",
      "Step 59340 Training Accuracy 0.984... Training Loss 0.081...\n",
      "Step 59350 Training Accuracy 0.922... Training Loss 0.134...\n",
      "Step 59360 Training Accuracy 0.984... Training Loss 0.097...\n",
      "Step 59370 Training Accuracy 0.969... Training Loss 0.050...\n",
      "Step 59380 Training Accuracy 0.969... Training Loss 0.167...\n",
      "Step 59390 Training Accuracy 0.984... Training Loss 0.091...\n",
      "Step 59400 Training Accuracy 0.953... Training Loss 0.145...\n",
      "Step 59410 Training Accuracy 1.000... Training Loss 0.028...\n",
      "Step 59420 Training Accuracy 0.938... Training Loss 0.151...\n",
      "Step 59430 Training Accuracy 0.922... Training Loss 0.223...\n",
      "Step 59440 Training Accuracy 0.984... Training Loss 0.090...\n",
      "Step 59450 Training Accuracy 0.953... Training Loss 0.116...\n",
      "Step 59460 Training Accuracy 1.000... Training Loss 0.017...\n",
      "Step 59470 Training Accuracy 0.891... Training Loss 0.239...\n",
      "Step 59480 Training Accuracy 0.938... Training Loss 0.064...\n",
      "Step 59490 Training Accuracy 0.922... Training Loss 0.176...\n",
      "Step 59500 Training Accuracy 0.953... Training Loss 0.193...\n",
      "Step 59510 Training Accuracy 0.969... Training Loss 0.132...\n",
      "Step 59520 Training Accuracy 0.969... Training Loss 0.063...\n",
      "Step 59530 Training Accuracy 0.938... Training Loss 0.180...\n",
      "Step 59540 Training Accuracy 0.953... Training Loss 0.187...\n",
      "Step 59550 Training Accuracy 0.984... Training Loss 0.042...\n",
      "Step 59560 Training Accuracy 0.969... Training Loss 0.095...\n",
      "Step 59570 Training Accuracy 0.984... Training Loss 0.041...\n",
      "Step 59580 Training Accuracy 1.000... Training Loss 0.052...\n",
      "Step 59590 Training Accuracy 0.953... Training Loss 0.136...\n",
      "Step 59600 Training Accuracy 0.984... Training Loss 0.081...\n",
      "Step 59610 Training Accuracy 0.953... Training Loss 0.300...\n",
      "Step 59620 Training Accuracy 0.953... Training Loss 0.082...\n",
      "Step 59630 Training Accuracy 0.953... Training Loss 0.208...\n",
      "Step 59640 Training Accuracy 0.906... Training Loss 0.346...\n",
      "Step 59650 Training Accuracy 0.906... Training Loss 0.244...\n",
      "Step 59660 Training Accuracy 1.000... Training Loss 0.044...\n",
      "Step 59670 Training Accuracy 0.969... Training Loss 0.099...\n",
      "Step 59680 Training Accuracy 0.969... Training Loss 0.029...\n",
      "Step 59690 Training Accuracy 0.938... Training Loss 0.122...\n",
      "Step 59700 Training Accuracy 0.922... Training Loss 0.133...\n",
      "Step 59710 Training Accuracy 0.969... Training Loss 0.169...\n",
      "Step 59720 Training Accuracy 0.922... Training Loss 0.245...\n",
      "Step 59730 Training Accuracy 0.953... Training Loss 0.136...\n",
      "Step 59740 Training Accuracy 0.984... Training Loss 0.178...\n",
      "Step 59750 Training Accuracy 0.984... Training Loss 0.042...\n",
      "Step 59760 Training Accuracy 0.938... Training Loss 0.108...\n",
      "Step 59770 Training Accuracy 0.938... Training Loss 0.119...\n",
      "Step 59780 Training Accuracy 0.984... Training Loss 0.078...\n",
      "Step 59790 Training Accuracy 0.953... Training Loss 0.148...\n",
      "Step 59800 Training Accuracy 0.984... Training Loss 0.056...\n",
      "Step 59810 Training Accuracy 0.969... Training Loss 0.145...\n",
      "Step 59820 Training Accuracy 0.953... Training Loss 0.126...\n",
      "Step 59830 Training Accuracy 0.953... Training Loss 0.124...\n",
      "Step 59840 Training Accuracy 0.984... Training Loss 0.077...\n",
      "Step 59850 Training Accuracy 0.984... Training Loss 0.039...\n",
      "Step 59860 Training Accuracy 1.000... Training Loss 0.111...\n",
      "Step 59870 Training Accuracy 0.938... Training Loss 0.117...\n",
      "Step 59880 Training Accuracy 0.969... Training Loss 0.045...\n",
      "Step 59890 Training Accuracy 0.969... Training Loss 0.067...\n",
      "Step 59900 Training Accuracy 0.984... Training Loss 0.059...\n",
      "Step 59910 Training Accuracy 0.969... Training Loss 0.120...\n",
      "Step 59920 Training Accuracy 0.953... Training Loss 0.095...\n",
      "Step 59930 Training Accuracy 0.953... Training Loss 0.179...\n",
      "Step 59940 Training Accuracy 0.984... Training Loss 0.053...\n",
      "Step 59950 Training Accuracy 1.000... Training Loss 0.070...\n",
      "Step 59960 Training Accuracy 1.000... Training Loss 0.037...\n",
      "Step 59970 Training Accuracy 0.969... Training Loss 0.101...\n",
      "Step 59980 Training Accuracy 0.969... Training Loss 0.071...\n",
      "Step 59990 Training Accuracy 0.969... Training Loss 0.170...\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "def train(train_feature_path, train_label_path, checkpoint_path, num_class, batch_size, image_size, max_step):\n",
    "    \n",
    "    train = initialize(train_feature_path, train_label_path)\n",
    "        \n",
    "    feature = tf.placeholder(tf.float32, shape=[None, image_size, image_size, 3], name='feature')\n",
    "    label = tf.placeholder(tf.float32, shape=[None], name='label')\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    one_hot_label = tf.one_hot(indices=tf.cast(label, tf.int32), depth=80)\n",
    "    is_training = tf.placeholder(tf.bool, name='is_training')\n",
    "    \n",
    "    logits, loss = conv_network(feature, one_hot_label, num_class, image_size, keep_prob, is_training)\n",
    "    \n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "        train_opt = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "        \n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_label, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "       \n",
    "    with tf.Session() as sess:\n",
    "        saver = tf.train.Saver()\n",
    "        ckpt = tf.train.get_checkpoint_state(checkpoint_path)\n",
    "        \n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            print('Restore the model from checkpoint {}.'.format(ckpt.model_checkpoint_path))\n",
    "            start_step = int(ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1])\n",
    "        else:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            start_step = 0\n",
    "            print('Start training from new start.')\n",
    "        \n",
    "        for steps in range(start_step, start_step + max_step):\n",
    "            train_feature_batch, train_label_batch = train.get_batch(batch_size, image_size)\n",
    "            #print(is_training, feature, label)\n",
    "            sess.run(train_opt, feed_dict={feature: train_feature_batch, label: train_label_batch, keep_prob: 0.5, is_training: True})\n",
    "                \n",
    "            if steps % 10 == 0:\n",
    "                train_accuracy = sess.run(accuracy, feed_dict={feature: train_feature_batch, label: train_label_batch, keep_prob: 0.5, is_training: False})\n",
    "                train_loss = sess.run(loss, feed_dict={feature: train_feature_batch, label: train_label_batch, keep_prob: 0.5, is_training: False})\n",
    "                print('Step {}'.format(steps),\n",
    "                      'Training Accuracy {:.3f}...'.format(train_accuracy),\n",
    "                      'Training Loss {:.3f}...'.format(train_loss),\n",
    "                     ) \n",
    "            if steps % 1000 == 0:\n",
    "                saver.save(sess, checkfile, global_step=steps)\n",
    "                print('Writing checkpoint at step {}'.format(steps))\n",
    "\n",
    "        print('Training completed.')\n",
    "\n",
    "# image pathes\n",
    "train_feature_path = r'E:\\ai_challenger\\scene classification\\dataset\\ai_challenger_scene_train_20170904\\scene_train_images_20170904'\n",
    "train_label_path = r'E:\\ai_challenger\\scene classification\\dataset\\ai_challenger_scene_train_20170904\\scene_train_annotations_20170904.json'\n",
    "checkpoint_path = './checkpoint/'\n",
    "checkfile = './checkpoint/model.ckpt'\n",
    "\n",
    "num_class = 80\n",
    "batch_size = 64\n",
    "image_size = 64\n",
    "max_step = 60000\n",
    "learning_rate =0.002\n",
    "\n",
    "train(train_feature_path, train_label_path, checkpoint_path, num_class, batch_size, image_size, max_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='step5'></a>\n",
    "## Step 5: Test model and write result into submit.json(image id, top 3 label id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(val_feature_path, val_label_path, checkpoint_dir, num_class, image_size):\n",
    "    test = initialize(val_feature_path, val_label_path)\n",
    "    test_images = os.listdir(val_feature_path)\n",
    "    \n",
    "    feature = tf.placeholder(tf.float32, shape=[None, image_size, image_size, 3], name='feature')\n",
    "    label = tf.placeholder(tf.float32, shape=[None], name='label')\n",
    "    one_hot_label = tf.one_hot(indices=tf.cast(label, tf.int32), depth=80)\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    is_training = tf.placeholder(tf.bool, name='is_training')\n",
    "    \n",
    "    logits, loss = conv_network(feature, label, num_class, image_size, keep_prob, is_training)\n",
    "    values, indices = tf.nn.top_k(logits, 3)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        saver = tf.train.Saver()\n",
    "        ckpt = tf.train.get_checkpoint_state(checkpoint_path)\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            print(\"Restore the model from checkpoint %s\" % ckpt.model_checkpoint_path)\n",
    "            saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "            start_step = int(ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1])\n",
    "        else:\n",
    "            raise Exception('No checkpoint found')\n",
    "        \n",
    "        result = []\n",
    "        for test_image in test_images:\n",
    "            temp_dict = {}\n",
    "            x = test.get_image(os.path.join(val_feature_path, test_image), image_size)\n",
    "            predictions = np.squeeze(sess.run(indices, feed_dict={feature: np.expand_dims(x, axis=0), keep_prob: 1}), axis=0)\n",
    "            temp_dict['image_id'] = test_image\n",
    "            temp_dict['label_id'] = predictions.tolist()\n",
    "            result.append(temp_dict)\n",
    "            print('image %s is %d, %d, %d' % (test_image, predictions[0], predictions[1], predictions[2]))\n",
    "            \n",
    "        with open('submit.json', 'w') as f:\n",
    "            json.dump(result, f)\n",
    "            print('Write result json file, num is %d' % len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restore the model from checkpoint ./checkpoint/model.ckpt-59000\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/model.ckpt-59000\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Key conv2d_21/bias not found in checkpoint\n\t [[Node: save_1/RestoreV2_270 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_1/Const_0, save_1/RestoreV2_270/tensor_names, save_1/RestoreV2_270/shape_and_slices)]]\n\t [[Node: save_1/RestoreV2_279/_97 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_1599_save_1/RestoreV2_279\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\nCaused by op 'save_1/RestoreV2_270', defined at:\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2808, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-10-acc5ad32efd6>\", line 7, in <module>\n    test(val_feature_path, val_label_path, checkpoint_dir, num_class, image_size)\n  File \"<ipython-input-9-e938efc69d85>\", line 15, in test\n    saver = tf.train.Saver()\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1056, in __init__\n    self.build()\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1086, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 691, in build\n    restore_sequentially, reshape)\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 407, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 247, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 669, in restore_v2\n    dtypes=dtypes, name=name)\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nNotFoundError (see above for traceback): Key conv2d_21/bias not found in checkpoint\n\t [[Node: save_1/RestoreV2_270 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_1/Const_0, save_1/RestoreV2_270/tensor_names, save_1/RestoreV2_270/shape_and_slices)]]\n\t [[Node: save_1/RestoreV2_279/_97 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_1599_save_1/RestoreV2_279\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mD:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1038\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Work\\Anaconda\\envs\\scene\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Key conv2d_21/bias not found in checkpoint\n\t [[Node: save_1/RestoreV2_270 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_1/Const_0, save_1/RestoreV2_270/tensor_names, save_1/RestoreV2_270/shape_and_slices)]]\n\t [[Node: save_1/RestoreV2_279/_97 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_1599_save_1/RestoreV2_279\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-acc5ad32efd6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mimage_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_feature_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_label_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-e938efc69d85>\u001b[0m in \u001b[0;36mtest\u001b[1;34m(val_feature_path, val_label_path, checkpoint_dir, num_class, image_size)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mckpt\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mckpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_checkpoint_path\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Restore the model from checkpoint %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mckpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_checkpoint_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m             \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mckpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_checkpoint_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m             \u001b[0mstart_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_checkpoint_path\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1455\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Restoring parameters from %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1456\u001b[0m     sess.run(self.saver_def.restore_op_name,\n\u001b[1;32m-> 1457\u001b[1;33m              {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[0;32m   1458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1459\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 778\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 982\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1032\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mD:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1050\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1052\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Key conv2d_21/bias not found in checkpoint\n\t [[Node: save_1/RestoreV2_270 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_1/Const_0, save_1/RestoreV2_270/tensor_names, save_1/RestoreV2_270/shape_and_slices)]]\n\t [[Node: save_1/RestoreV2_279/_97 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_1599_save_1/RestoreV2_279\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\nCaused by op 'save_1/RestoreV2_270', defined at:\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2808, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-10-acc5ad32efd6>\", line 7, in <module>\n    test(val_feature_path, val_label_path, checkpoint_dir, num_class, image_size)\n  File \"<ipython-input-9-e938efc69d85>\", line 15, in test\n    saver = tf.train.Saver()\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1056, in __init__\n    self.build()\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1086, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 691, in build\n    restore_sequentially, reshape)\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 407, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 247, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 669, in restore_v2\n    dtypes=dtypes, name=name)\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"D:\\Work\\Anaconda\\envs\\scene\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nNotFoundError (see above for traceback): Key conv2d_21/bias not found in checkpoint\n\t [[Node: save_1/RestoreV2_270 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_1/Const_0, save_1/RestoreV2_270/tensor_names, save_1/RestoreV2_270/shape_and_slices)]]\n\t [[Node: save_1/RestoreV2_279/_97 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_1599_save_1/RestoreV2_279\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "val_feature_path = r'E:\\ai_challenger\\scene classification\\dataset\\ai_challenger_scene_validation_20170908\\scene_validation_images_20170908'\n",
    "val_label_path = r'E:\\ai_challenger\\scene classification\\dataset\\ai_challenger_scene_validation_20170908\\scene_validation_annotations_20170908.json'\n",
    "checkpoint_dir = './checkpoint/'\n",
    "num_class = 80\n",
    "image_size = 64\n",
    "\n",
    "test(val_feature_path, val_label_path, checkpoint_dir, num_class, image_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step6'></a>\n",
    "## Step 6: Calculate accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
