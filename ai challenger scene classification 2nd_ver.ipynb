{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps for Building Network\n",
    "[Step 1](#step1): Unzip image dataset and check out train, validation and test files.\n",
    "\n",
    "[Step 2](#step2): Show image and json files in train & validation dataset.\n",
    "\n",
    "[Step 3](#step3): Initialize features(input) and labels(output) from images and json list.\n",
    "\n",
    "- read images from train/validation/test path.\n",
    "- read labels from train/validation json file.\n",
    "- resize and normalize images.\n",
    "- get batch and return feature_batch and label_batch.\n",
    "\n",
    "[Step 4](#step4): Build convolutional network, return training accuracy and training loss.\n",
    "\n",
    "[Step 5](#step5): Train on steps = 20000.\n",
    "\n",
    "[Step 6](#step6): Train on full dataset.\n",
    "- epoch x, batch x, training loss, validation accuracy, evluation accuracy\n",
    "\n",
    "[Step 7](#step7): Test and write json submit file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step1'></a>\n",
    "## Step 1: Unzip image dataset and check out train, validation and test files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found extraced dataset\n"
     ]
    }
   ],
   "source": [
    "import os, zipfile\n",
    "\n",
    "train_path = 'E:/ai_challenger/scene classification/dataset/ai_challenger_scene_train_20170904.zip'\n",
    "validation_path = 'E:/ai_challenger/scene classification/dataset/ai_challenger_scene_validation_20170908.zip'\n",
    "test_a_path = 'E:/ai_challenger/scene classification/dataset/ai_challenger_scene_test_a_20170922.zip'\n",
    "extract_path = 'E:/ai_challenger/scene classification/dataset'\n",
    "\n",
    "def unzip(zipfile_path, extract_path, zipfile_name):\n",
    "    zipfile = zipfile.ZipFile(zipfile_path, 'r')\n",
    "    print('Extracting {} ...'.format(zipfile_name))\n",
    "    zipfile.extractall()\n",
    "    zipfile.close()\n",
    "    print('{} has been extracted.'.format(zipfle_name))\n",
    "\n",
    "if os.path.exists(extract_path):\n",
    "    print('Found extraced dataset')\n",
    "else:\n",
    "    unzip(train_path, extract_path, 'training dataset')\n",
    "    unzip(validation_path, extract_path, 'validation dataset')\n",
    "    unzip(test_a_path, extract_path, 'test dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='step2'></a>\n",
    "## Step 2: Show image and json files in train & validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'image_url': 'https://n1-q.mafengwo.net/s1/M00/6B/72/wKgBm04Wc5WzFXU0AAHf09bdpiY84.jpeg?imageView2%2F2%2Fw%2F600%2Fq%2F90', 'image_id': '79f993ae0858ae238b22968c5934d1ddba585ae4.jpg', 'label_id': '66'}, {'image_url': 'http://news.sogou.com/', 'image_id': 'e963208fe9e90df0c385f7367bcdb6d0d5d0b165.jpg', 'label_id': '61'}, {'image_url': 'http://img2.fawan.com/2016/12/30/e967f93e7713c57cd2b00b832dd6091a_500x-_90.jpg', 'image_id': '02df5ecbf7c749ccc9d833f129bbd5d9837940ce.jpg', 'label_id': '64'}, {'image_url': 'https://b1-q.mafengwo.net/s1/M00/F2/C9/wKgBm04Wx3a-gk2FAAKbPKX7E9w91.jpeg?imageView2%2F2%2Fw%2F600%2Fq%2F90', 'image_id': '5620eb385b7567fb087813cf5233b5ceecdeeca3.jpg', 'label_id': '31'}, {'image_url': 'http://news.sogou.com/', 'image_id': 'f8b4d42001a562fc63b9b39c02531661c0e236ca.jpg', 'label_id': '19'}, {'image_url': 'http://www.user2.jqw.com/2014/01/06/1347666/product/b201401072000291460.JPG', 'image_id': '57e7eb438670a4519041dab1482f2594a92f8a09.jpg', 'label_id': '11'}, {'image_url': 'http://s16.sinaimg.cn/middle/67bde22dx929ff224e80f&690', 'image_id': 'addb2ef7e4aa1a160093e32ceec19bf900c05d2e.jpg', 'label_id': '22'}, {'image_url': 'http://imgsrc.baidu.com/imgad/pic/item/a686c9177f3e6709f65104d631c79f3df8dc5541.jpg', 'image_id': '84a5b79a7f8fe3ddb43355eaf010a3a432e457b4.jpg', 'label_id': '11'}, {'image_url': 'http://news.sogou.com/', 'image_id': '48f690ba20db3e6a0a0f7ab5b59480f7558b18fa.jpg', 'label_id': '47'}, {'image_url': 'http://news.sogou.com/', 'image_id': '3c53b82532f132da2727fad84ade044f364a1dba.jpg', 'label_id': '3'}]\n",
      "\n",
      "\n",
      "53879\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import glob\n",
    "from scipy.misc import imread, imresize, imsave\n",
    "import numpy as np\n",
    "\n",
    "train_features_path = r'E:\\ai_challenger\\scene classification\\dataset\\ai_challenger_scene_train_20170904\\scene_train_images_20170904'\n",
    "train_labels_path = r'E:\\ai_challenger\\scene classification\\dataset\\ai_challenger_scene_train_20170904\\scene_train_annotations_20170904.json'\n",
    "validation_features_path =r'E:\\ai_challenger\\scene classification\\dataset\\ai_challenger_scene_validation_20170908\\scene_validation_images_20170908'\n",
    "validation_labels_path =r'E:\\ai_challenger\\scene classification\\dataset\\ai_challenger_scene_validation_20170908\\scene_validation_images_20170908\\scene_validation_annotations_20170908.json'\n",
    "test_a_features_path = r'E:\\ai_challenger\\scene classification\\dataset\\ai_challenger_scene_test_a_20170922\\scene_test_a_images_20170922'\n",
    "\n",
    "# Show train label list\n",
    "with open(train_labels_path, 'r') as f:\n",
    "    train_label_list = json.load(f)\n",
    "    print(train_label_list[:10])\n",
    "    train_dict = {}\n",
    "    for image in train_label_list:\n",
    "        train_dict[image['image_id']] = int(image['label_id'])\n",
    "    print('\\n')\n",
    "    print(len(train_dict))     \n",
    "\n",
    "# Show train features list resulting out of memory..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='step3'></a>\n",
    "## Step 3: Initialize features(input) and labels(output) from images and json list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from scipy.misc import imread, imresize\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class initialize(object):\n",
    "    # Get image-label list for train and validation\n",
    "    def __init__(self, feature_path, label_path):\n",
    "        self.image_label_dict = {}\n",
    "        with open(label_path, 'r') as f:\n",
    "            label_list = json.load(f)\n",
    "        for image in label_list:\n",
    "            self.image_label_dict[image['image_id']] = int(image['label_id'])\n",
    "        self.start = 0\n",
    "        self.end = 0\n",
    "        self.length = len(self.image_label_dict) # number of feature images\n",
    "        self.image_name = list(self.image_label_dict.keys())\n",
    "        self.feature_path = feature_path\n",
    "    \n",
    "    # Read image in feature path, resize and normalize to [-1, 1]\n",
    "    def get_image(self, image_path, image_size):\n",
    "        image = imread(image_path)\n",
    "        image = imresize(image, [image_size, image_size])       \n",
    "        image = np.array(image).astype(np.float32)\n",
    "        image = 2 * (image - np.min(image)) / np.ptp(image) - 1\n",
    "        return image\n",
    "    \n",
    "    # Get feature and label batch\n",
    "    def get_batch(self, batch_size, image_size):\n",
    "        self.start = self.end\n",
    "        if self.start >= self.length:\n",
    "            self.start = 0\n",
    "        batch_feature = []\n",
    "        batch_label = []\n",
    "        index = self.start\n",
    "        while len(batch_feature) < batch_size:\n",
    "            if index >= self.length:\n",
    "                index = 0\n",
    "            i_image_path = os.path.join(self.feature_path, self.image_name[index])\n",
    "            i_image = self.get_image(i_image_path, image_size)\n",
    "            i_label = self.image_label_dict[self.image_name[index]]\n",
    "            batch_feature.append(i_image)\n",
    "            batch_label.append(i_label)\n",
    "            index += 1\n",
    "        self.end = index\n",
    "        return batch_feature, batch_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='step4'></a>\n",
    "## Step 4: 16 convolutional layers with batch normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def conv_layer(input_layer, filters, strides, is_training):\n",
    "    layer = tf.layers.conv2d(\n",
    "        inputs=input_layer, \n",
    "        filters=filters, \n",
    "        kernel_size=3,\n",
    "        strides=strides, \n",
    "        padding='same', \n",
    "        activation=None,\n",
    "        kernel_initializer=tf.truncated_normal_initializer()\n",
    "    )\n",
    "    \n",
    "    layer = tf.layers.batch_normalization(\n",
    "        inputs=layer, \n",
    "        axis=-1,\n",
    "        momentum=0.9,\n",
    "        epsilon=0.001,\n",
    "        center=True,\n",
    "        scale=True,\n",
    "        training=is_training\n",
    "    )\n",
    "    \n",
    "    layer = tf.nn.relu(layer)\n",
    "    return layer\n",
    "\n",
    "def fully_connected(input_layer, num_units, is_training):\n",
    "    layer = tf.layers.dense(input_layer, num_units, use_bias=False, activation=None)\n",
    "    layer = tf.layers.batch_normalization(layer, training=is_training)\n",
    "    layer = tf.nn.relu(layer)\n",
    "    return layer\n",
    "\n",
    "def conv_network(feature, label, num_class, image_size, keep_prob, is_training):\n",
    "    input_layer = tf.reshape(feature, [-1, image_size, image_size, 3])\n",
    "    \n",
    "    # 16 conv layers with 64, 128, 256, 512 filters.\n",
    "    layer = conv_layer(input_layer, 64, 1, is_training)\n",
    "    layer = conv_layer(layer, 64, 1, is_training)\n",
    "    layer = tf.layers.max_pooling2d(layer, pool_size=[2, 2], strides=2, padding='same')\n",
    "    \n",
    "    layer = conv_layer(layer, 128, 1, is_training)\n",
    "    layer = conv_layer(layer, 128, 1, is_training)\n",
    "    layer = tf.layers.max_pooling2d(layer, pool_size=[2, 2], strides=2, padding='same')\n",
    "    \n",
    "    layer = conv_layer(layer, 256, 2, is_training)\n",
    "    layer = conv_layer(layer, 256, 2, is_training)\n",
    "    layer = conv_layer(layer, 256, 2, is_training)\n",
    "    layer = conv_layer(layer, 256, 2, is_training)\n",
    "    layer = tf.layers.max_pooling2d(layer, pool_size=[2, 2], strides=2, padding='same')\n",
    "    \n",
    "    layer = conv_layer(layer, 512, 2, is_training)\n",
    "    layer = conv_layer(layer, 512, 2, is_training)\n",
    "    layer = conv_layer(layer, 512, 2, is_training)\n",
    "    layer = conv_layer(layer, 512, 2, is_training)\n",
    "    layer = tf.layers.max_pooling2d(layer, pool_size=[2, 2], strides=2, padding='same')\n",
    "    \n",
    "    layer = conv_layer(layer, 512, 2, is_training)\n",
    "    layer = conv_layer(layer, 512, 2, is_training)\n",
    "    layer = conv_layer(layer, 512, 2, is_training)\n",
    "    layer = conv_layer(layer, 512, 2, is_training)\n",
    "    layer = tf.layers.max_pooling2d(layer, pool_size=[2, 2], strides=2, padding='same')\n",
    "    \n",
    "    shape = layer.get_shape().as_list()\n",
    "    layer = tf.reshape(layer, shape=[-1, shape[1]*shape[2]*shape[3]])\n",
    "    layer = fully_connected(layer, 800, is_training)\n",
    "    layer = tf.nn.dropout(layer, keep_prob)\n",
    "    logits = tf.layers.dense(layer, 80)\n",
    "    output = tf.sigmoid(logits)\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=label))\n",
    "    \n",
    "    return logits, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training from new start.\n",
      "Step 0 Training Accuracy 0.016... Training Loss 792491200.000...\n",
      "Writing checkpoing at step 0\n",
      "Step 10 Training Accuracy 0.000... Training Loss 379.534...\n",
      "Step 20 Training Accuracy 0.016... Training Loss 24.364...\n",
      "Step 30 Training Accuracy 0.016... Training Loss 7.035...\n",
      "Step 40 Training Accuracy 0.000... Training Loss 5.493...\n",
      "Step 50 Training Accuracy 0.031... Training Loss 5.455...\n",
      "Step 60 Training Accuracy 0.000... Training Loss 5.235...\n",
      "Step 70 Training Accuracy 0.016... Training Loss 4.674...\n",
      "Step 80 Training Accuracy 0.031... Training Loss 5.072...\n",
      "Step 90 Training Accuracy 0.062... Training Loss 4.950...\n",
      "Step 100 Training Accuracy 0.016... Training Loss 5.491...\n",
      "Step 110 Training Accuracy 0.016... Training Loss 5.201...\n",
      "Step 120 Training Accuracy 0.016... Training Loss 4.916...\n",
      "Step 130 Training Accuracy 0.031... Training Loss 6.100...\n",
      "Step 140 Training Accuracy 0.062... Training Loss 4.790...\n",
      "Step 150 Training Accuracy 0.047... Training Loss 4.273...\n",
      "Step 160 Training Accuracy 0.016... Training Loss 5.261...\n",
      "Step 170 Training Accuracy 0.031... Training Loss 4.477...\n",
      "Step 180 Training Accuracy 0.062... Training Loss 4.799...\n",
      "Step 190 Training Accuracy 0.031... Training Loss 4.494...\n",
      "Step 200 Training Accuracy 0.047... Training Loss 4.879...\n",
      "Step 210 Training Accuracy 0.047... Training Loss 4.714...\n",
      "Step 220 Training Accuracy 0.031... Training Loss 4.431...\n",
      "Step 230 Training Accuracy 0.047... Training Loss 4.346...\n",
      "Step 240 Training Accuracy 0.031... Training Loss 4.776...\n",
      "Step 250 Training Accuracy 0.016... Training Loss 4.742...\n",
      "Step 260 Training Accuracy 0.031... Training Loss 4.488...\n",
      "Step 270 Training Accuracy 0.094... Training Loss 4.372...\n",
      "Step 280 Training Accuracy 0.047... Training Loss 4.432...\n",
      "Step 290 Training Accuracy 0.047... Training Loss 4.212...\n",
      "Step 300 Training Accuracy 0.062... Training Loss 4.345...\n",
      "Step 310 Training Accuracy 0.062... Training Loss 4.229...\n",
      "Step 320 Training Accuracy 0.016... Training Loss 4.316...\n",
      "Step 330 Training Accuracy 0.047... Training Loss 4.130...\n",
      "Step 340 Training Accuracy 0.125... Training Loss 4.107...\n",
      "Step 350 Training Accuracy 0.125... Training Loss 3.931...\n",
      "Step 360 Training Accuracy 0.016... Training Loss 4.211...\n",
      "Step 370 Training Accuracy 0.078... Training Loss 4.196...\n",
      "Step 380 Training Accuracy 0.062... Training Loss 4.008...\n",
      "Step 390 Training Accuracy 0.062... Training Loss 4.316...\n",
      "Step 400 Training Accuracy 0.031... Training Loss 4.195...\n",
      "Step 410 Training Accuracy 0.031... Training Loss 4.151...\n",
      "Step 420 Training Accuracy 0.078... Training Loss 3.835...\n",
      "Step 430 Training Accuracy 0.047... Training Loss 4.196...\n",
      "Step 440 Training Accuracy 0.031... Training Loss 4.062...\n",
      "Step 450 Training Accuracy 0.078... Training Loss 3.818...\n",
      "Step 460 Training Accuracy 0.047... Training Loss 3.993...\n",
      "Step 470 Training Accuracy 0.062... Training Loss 4.034...\n",
      "Step 480 Training Accuracy 0.078... Training Loss 3.947...\n",
      "Step 490 Training Accuracy 0.094... Training Loss 4.071...\n",
      "Step 500 Training Accuracy 0.078... Training Loss 4.182...\n",
      "Step 510 Training Accuracy 0.062... Training Loss 4.313...\n",
      "Step 520 Training Accuracy 0.141... Training Loss 3.830...\n",
      "Step 530 Training Accuracy 0.031... Training Loss 4.054...\n",
      "Step 540 Training Accuracy 0.078... Training Loss 3.995...\n",
      "Step 550 Training Accuracy 0.047... Training Loss 4.329...\n",
      "Step 560 Training Accuracy 0.094... Training Loss 3.913...\n",
      "Step 570 Training Accuracy 0.031... Training Loss 4.009...\n",
      "Step 580 Training Accuracy 0.078... Training Loss 4.045...\n",
      "Step 590 Training Accuracy 0.078... Training Loss 3.630...\n",
      "Step 600 Training Accuracy 0.109... Training Loss 3.958...\n",
      "Step 610 Training Accuracy 0.078... Training Loss 3.994...\n",
      "Step 620 Training Accuracy 0.141... Training Loss 3.904...\n",
      "Step 630 Training Accuracy 0.141... Training Loss 3.999...\n",
      "Step 640 Training Accuracy 0.047... Training Loss 3.945...\n",
      "Step 650 Training Accuracy 0.125... Training Loss 4.011...\n",
      "Step 660 Training Accuracy 0.141... Training Loss 3.933...\n",
      "Step 670 Training Accuracy 0.094... Training Loss 3.697...\n",
      "Step 680 Training Accuracy 0.094... Training Loss 3.910...\n",
      "Step 690 Training Accuracy 0.078... Training Loss 3.932...\n",
      "Step 700 Training Accuracy 0.047... Training Loss 4.017...\n",
      "Step 710 Training Accuracy 0.125... Training Loss 3.957...\n",
      "Step 720 Training Accuracy 0.078... Training Loss 3.873...\n",
      "Step 730 Training Accuracy 0.125... Training Loss 3.682...\n",
      "Step 740 Training Accuracy 0.172... Training Loss 3.705...\n",
      "Step 750 Training Accuracy 0.141... Training Loss 3.741...\n",
      "Step 760 Training Accuracy 0.109... Training Loss 3.798...\n",
      "Step 770 Training Accuracy 0.062... Training Loss 3.820...\n",
      "Step 780 Training Accuracy 0.109... Training Loss 3.842...\n",
      "Step 790 Training Accuracy 0.109... Training Loss 3.813...\n",
      "Step 800 Training Accuracy 0.047... Training Loss 3.894...\n",
      "Step 810 Training Accuracy 0.172... Training Loss 3.657...\n",
      "Step 820 Training Accuracy 0.141... Training Loss 3.866...\n",
      "Step 830 Training Accuracy 0.109... Training Loss 3.854...\n",
      "Step 840 Training Accuracy 0.109... Training Loss 3.904...\n",
      "Step 850 Training Accuracy 0.234... Training Loss 3.427...\n",
      "Step 860 Training Accuracy 0.062... Training Loss 3.743...\n",
      "Step 870 Training Accuracy 0.078... Training Loss 3.860...\n",
      "Step 880 Training Accuracy 0.188... Training Loss 3.580...\n",
      "Step 890 Training Accuracy 0.078... Training Loss 3.777...\n",
      "Step 900 Training Accuracy 0.078... Training Loss 3.891...\n",
      "Step 910 Training Accuracy 0.047... Training Loss 3.782...\n",
      "Step 920 Training Accuracy 0.125... Training Loss 3.465...\n",
      "Step 930 Training Accuracy 0.156... Training Loss 3.730...\n",
      "Step 940 Training Accuracy 0.188... Training Loss 3.484...\n",
      "Step 950 Training Accuracy 0.047... Training Loss 3.668...\n",
      "Step 960 Training Accuracy 0.109... Training Loss 3.870...\n",
      "Step 970 Training Accuracy 0.156... Training Loss 3.476...\n",
      "Step 980 Training Accuracy 0.094... Training Loss 3.908...\n",
      "Step 990 Training Accuracy 0.141... Training Loss 3.682...\n",
      "Step 1000 Training Accuracy 0.047... Training Loss 3.706...\n",
      "Writing checkpoing at step 1000\n",
      "Step 1010 Training Accuracy 0.078... Training Loss 3.689...\n",
      "Step 1020 Training Accuracy 0.125... Training Loss 3.497...\n",
      "Step 1030 Training Accuracy 0.125... Training Loss 3.494...\n",
      "Step 1040 Training Accuracy 0.156... Training Loss 3.812...\n",
      "Step 1050 Training Accuracy 0.141... Training Loss 3.347...\n",
      "Step 1060 Training Accuracy 0.078... Training Loss 3.834...\n",
      "Step 1070 Training Accuracy 0.172... Training Loss 3.421...\n",
      "Step 1080 Training Accuracy 0.125... Training Loss 3.384...\n",
      "Step 1090 Training Accuracy 0.141... Training Loss 3.450...\n",
      "Step 1100 Training Accuracy 0.188... Training Loss 3.527...\n",
      "Step 1110 Training Accuracy 0.172... Training Loss 3.822...\n",
      "Step 1120 Training Accuracy 0.109... Training Loss 3.598...\n",
      "Step 1130 Training Accuracy 0.141... Training Loss 3.562...\n",
      "Step 1140 Training Accuracy 0.078... Training Loss 3.769...\n",
      "Step 1150 Training Accuracy 0.109... Training Loss 3.421...\n",
      "Step 1160 Training Accuracy 0.297... Training Loss 3.156...\n",
      "Step 1170 Training Accuracy 0.062... Training Loss 3.702...\n",
      "Step 1180 Training Accuracy 0.109... Training Loss 3.560...\n",
      "Step 1190 Training Accuracy 0.188... Training Loss 3.417...\n",
      "Step 1200 Training Accuracy 0.125... Training Loss 3.544...\n",
      "Step 1210 Training Accuracy 0.125... Training Loss 3.320...\n",
      "Step 1220 Training Accuracy 0.094... Training Loss 3.551...\n",
      "Step 1230 Training Accuracy 0.078... Training Loss 3.755...\n",
      "Step 1240 Training Accuracy 0.156... Training Loss 3.397...\n",
      "Step 1250 Training Accuracy 0.125... Training Loss 3.370...\n",
      "Step 1260 Training Accuracy 0.109... Training Loss 3.444...\n",
      "Step 1270 Training Accuracy 0.125... Training Loss 3.641...\n",
      "Step 1280 Training Accuracy 0.125... Training Loss 3.515...\n",
      "Step 1290 Training Accuracy 0.141... Training Loss 3.404...\n",
      "Step 1300 Training Accuracy 0.125... Training Loss 3.310...\n",
      "Step 1310 Training Accuracy 0.125... Training Loss 3.391...\n",
      "Step 1320 Training Accuracy 0.141... Training Loss 3.652...\n",
      "Step 1330 Training Accuracy 0.156... Training Loss 3.351...\n",
      "Step 1340 Training Accuracy 0.250... Training Loss 3.195...\n",
      "Step 1350 Training Accuracy 0.203... Training Loss 3.163...\n",
      "Step 1360 Training Accuracy 0.125... Training Loss 3.550...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1370 Training Accuracy 0.188... Training Loss 3.181...\n",
      "Step 1380 Training Accuracy 0.125... Training Loss 3.536...\n",
      "Step 1390 Training Accuracy 0.219... Training Loss 3.283...\n",
      "Step 1400 Training Accuracy 0.125... Training Loss 3.369...\n",
      "Step 1410 Training Accuracy 0.203... Training Loss 3.192...\n",
      "Step 1420 Training Accuracy 0.156... Training Loss 3.543...\n",
      "Step 1430 Training Accuracy 0.141... Training Loss 3.913...\n",
      "Step 1440 Training Accuracy 0.188... Training Loss 3.329...\n",
      "Step 1450 Training Accuracy 0.125... Training Loss 3.430...\n",
      "Step 1460 Training Accuracy 0.219... Training Loss 3.477...\n",
      "Step 1470 Training Accuracy 0.141... Training Loss 3.524...\n",
      "Step 1480 Training Accuracy 0.172... Training Loss 3.301...\n",
      "Step 1490 Training Accuracy 0.250... Training Loss 3.220...\n",
      "Step 1500 Training Accuracy 0.109... Training Loss 3.549...\n",
      "Step 1510 Training Accuracy 0.203... Training Loss 3.212...\n",
      "Step 1520 Training Accuracy 0.219... Training Loss 3.327...\n",
      "Step 1530 Training Accuracy 0.094... Training Loss 3.412...\n",
      "Step 1540 Training Accuracy 0.141... Training Loss 3.521...\n",
      "Step 1550 Training Accuracy 0.141... Training Loss 3.422...\n",
      "Step 1560 Training Accuracy 0.172... Training Loss 3.271...\n",
      "Step 1570 Training Accuracy 0.281... Training Loss 3.349...\n",
      "Step 1580 Training Accuracy 0.156... Training Loss 3.418...\n",
      "Step 1590 Training Accuracy 0.188... Training Loss 3.382...\n",
      "Step 1600 Training Accuracy 0.188... Training Loss 3.395...\n",
      "Step 1610 Training Accuracy 0.141... Training Loss 3.167...\n",
      "Step 1620 Training Accuracy 0.203... Training Loss 3.106...\n",
      "Step 1630 Training Accuracy 0.250... Training Loss 2.992...\n",
      "Step 1640 Training Accuracy 0.234... Training Loss 3.467...\n",
      "Step 1650 Training Accuracy 0.141... Training Loss 3.213...\n",
      "Step 1660 Training Accuracy 0.188... Training Loss 3.333...\n",
      "Step 1670 Training Accuracy 0.141... Training Loss 3.365...\n",
      "Step 1680 Training Accuracy 0.375... Training Loss 2.966...\n",
      "Step 1690 Training Accuracy 0.125... Training Loss 3.328...\n",
      "Step 1700 Training Accuracy 0.141... Training Loss 3.561...\n",
      "Step 1710 Training Accuracy 0.062... Training Loss 3.602...\n",
      "Step 1720 Training Accuracy 0.219... Training Loss 3.202...\n",
      "Step 1730 Training Accuracy 0.125... Training Loss 3.360...\n",
      "Step 1740 Training Accuracy 0.219... Training Loss 3.252...\n",
      "Step 1750 Training Accuracy 0.250... Training Loss 3.190...\n",
      "Step 1760 Training Accuracy 0.188... Training Loss 3.001...\n",
      "Step 1770 Training Accuracy 0.125... Training Loss 3.592...\n",
      "Step 1780 Training Accuracy 0.141... Training Loss 3.269...\n",
      "Step 1790 Training Accuracy 0.203... Training Loss 3.051...\n",
      "Step 1800 Training Accuracy 0.094... Training Loss 3.261...\n",
      "Step 1810 Training Accuracy 0.156... Training Loss 3.606...\n",
      "Step 1820 Training Accuracy 0.172... Training Loss 3.401...\n",
      "Step 1830 Training Accuracy 0.172... Training Loss 3.277...\n",
      "Step 1840 Training Accuracy 0.188... Training Loss 3.149...\n",
      "Step 1850 Training Accuracy 0.047... Training Loss 3.510...\n",
      "Step 1860 Training Accuracy 0.172... Training Loss 3.215...\n",
      "Step 1870 Training Accuracy 0.203... Training Loss 3.190...\n",
      "Step 1880 Training Accuracy 0.266... Training Loss 3.093...\n",
      "Step 1890 Training Accuracy 0.094... Training Loss 3.500...\n",
      "Step 1900 Training Accuracy 0.203... Training Loss 3.180...\n",
      "Step 1910 Training Accuracy 0.203... Training Loss 3.121...\n",
      "Step 1920 Training Accuracy 0.219... Training Loss 3.139...\n",
      "Step 1930 Training Accuracy 0.188... Training Loss 3.192...\n",
      "Step 1940 Training Accuracy 0.125... Training Loss 3.472...\n",
      "Step 1950 Training Accuracy 0.172... Training Loss 3.380...\n",
      "Step 1960 Training Accuracy 0.172... Training Loss 3.520...\n",
      "Step 1970 Training Accuracy 0.203... Training Loss 3.353...\n",
      "Step 1980 Training Accuracy 0.125... Training Loss 3.382...\n",
      "Step 1990 Training Accuracy 0.141... Training Loss 3.152...\n",
      "Step 2000 Training Accuracy 0.266... Training Loss 2.961...\n",
      "Writing checkpoing at step 2000\n",
      "Step 2010 Training Accuracy 0.156... Training Loss 3.443...\n",
      "Step 2020 Training Accuracy 0.188... Training Loss 3.289...\n",
      "Step 2030 Training Accuracy 0.234... Training Loss 3.093...\n",
      "Step 2040 Training Accuracy 0.188... Training Loss 3.155...\n",
      "Step 2050 Training Accuracy 0.281... Training Loss 2.963...\n",
      "Step 2060 Training Accuracy 0.219... Training Loss 3.114...\n",
      "Step 2070 Training Accuracy 0.203... Training Loss 3.231...\n",
      "Step 2080 Training Accuracy 0.250... Training Loss 2.961...\n",
      "Step 2090 Training Accuracy 0.250... Training Loss 3.007...\n",
      "Step 2100 Training Accuracy 0.234... Training Loss 3.328...\n",
      "Step 2110 Training Accuracy 0.250... Training Loss 3.004...\n",
      "Step 2120 Training Accuracy 0.172... Training Loss 3.223...\n",
      "Step 2130 Training Accuracy 0.203... Training Loss 2.997...\n",
      "Step 2140 Training Accuracy 0.203... Training Loss 3.168...\n",
      "Step 2150 Training Accuracy 0.234... Training Loss 3.302...\n",
      "Step 2160 Training Accuracy 0.266... Training Loss 2.832...\n",
      "Step 2170 Training Accuracy 0.297... Training Loss 3.106...\n",
      "Step 2180 Training Accuracy 0.250... Training Loss 2.962...\n",
      "Step 2190 Training Accuracy 0.234... Training Loss 3.031...\n",
      "Step 2200 Training Accuracy 0.188... Training Loss 3.256...\n",
      "Step 2210 Training Accuracy 0.250... Training Loss 2.907...\n",
      "Step 2220 Training Accuracy 0.172... Training Loss 3.081...\n",
      "Step 2230 Training Accuracy 0.125... Training Loss 3.317...\n",
      "Step 2240 Training Accuracy 0.297... Training Loss 2.684...\n",
      "Step 2250 Training Accuracy 0.188... Training Loss 3.118...\n",
      "Step 2260 Training Accuracy 0.281... Training Loss 2.940...\n",
      "Step 2270 Training Accuracy 0.172... Training Loss 3.245...\n",
      "Step 2280 Training Accuracy 0.234... Training Loss 2.964...\n",
      "Step 2290 Training Accuracy 0.203... Training Loss 2.974...\n",
      "Step 2300 Training Accuracy 0.203... Training Loss 3.141...\n",
      "Step 2310 Training Accuracy 0.188... Training Loss 2.910...\n",
      "Step 2320 Training Accuracy 0.188... Training Loss 3.014...\n",
      "Step 2330 Training Accuracy 0.188... Training Loss 3.178...\n",
      "Step 2340 Training Accuracy 0.172... Training Loss 3.247...\n",
      "Step 2350 Training Accuracy 0.141... Training Loss 3.155...\n",
      "Step 2360 Training Accuracy 0.266... Training Loss 2.938...\n",
      "Step 2370 Training Accuracy 0.250... Training Loss 2.835...\n",
      "Step 2380 Training Accuracy 0.188... Training Loss 3.401...\n",
      "Step 2390 Training Accuracy 0.219... Training Loss 3.108...\n",
      "Step 2400 Training Accuracy 0.156... Training Loss 3.116...\n",
      "Step 2410 Training Accuracy 0.203... Training Loss 3.121...\n",
      "Step 2420 Training Accuracy 0.250... Training Loss 2.754...\n",
      "Step 2430 Training Accuracy 0.109... Training Loss 3.113...\n",
      "Step 2440 Training Accuracy 0.250... Training Loss 2.985...\n",
      "Step 2450 Training Accuracy 0.250... Training Loss 2.878...\n",
      "Step 2460 Training Accuracy 0.234... Training Loss 2.825...\n",
      "Step 2470 Training Accuracy 0.266... Training Loss 2.839...\n",
      "Step 2480 Training Accuracy 0.219... Training Loss 3.079...\n",
      "Step 2490 Training Accuracy 0.203... Training Loss 3.099...\n",
      "Step 2500 Training Accuracy 0.234... Training Loss 3.027...\n",
      "Step 2510 Training Accuracy 0.250... Training Loss 3.056...\n",
      "Step 2520 Training Accuracy 0.141... Training Loss 3.331...\n",
      "Step 2530 Training Accuracy 0.219... Training Loss 3.246...\n",
      "Step 2540 Training Accuracy 0.266... Training Loss 3.133...\n",
      "Step 2550 Training Accuracy 0.203... Training Loss 3.207...\n",
      "Step 2560 Training Accuracy 0.219... Training Loss 2.971...\n",
      "Step 2570 Training Accuracy 0.219... Training Loss 2.982...\n",
      "Step 2580 Training Accuracy 0.250... Training Loss 3.000...\n",
      "Step 2590 Training Accuracy 0.141... Training Loss 3.255...\n",
      "Step 2600 Training Accuracy 0.188... Training Loss 3.001...\n",
      "Step 2610 Training Accuracy 0.266... Training Loss 2.984...\n",
      "Step 2620 Training Accuracy 0.234... Training Loss 2.976...\n",
      "Step 2630 Training Accuracy 0.266... Training Loss 3.342...\n",
      "Step 2640 Training Accuracy 0.297... Training Loss 2.752...\n",
      "Step 2650 Training Accuracy 0.234... Training Loss 3.175...\n",
      "Step 2660 Training Accuracy 0.188... Training Loss 3.224...\n",
      "Step 2670 Training Accuracy 0.188... Training Loss 3.200...\n",
      "Step 2680 Training Accuracy 0.203... Training Loss 3.002...\n",
      "Step 2690 Training Accuracy 0.219... Training Loss 3.000...\n",
      "Step 2700 Training Accuracy 0.266... Training Loss 2.915...\n",
      "Step 2710 Training Accuracy 0.312... Training Loss 2.910...\n",
      "Step 2720 Training Accuracy 0.109... Training Loss 3.178...\n",
      "Step 2730 Training Accuracy 0.328... Training Loss 2.871...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2740 Training Accuracy 0.188... Training Loss 3.131...\n",
      "Step 2750 Training Accuracy 0.250... Training Loss 3.130...\n",
      "Step 2760 Training Accuracy 0.234... Training Loss 3.135...\n",
      "Step 2770 Training Accuracy 0.203... Training Loss 2.904...\n",
      "Step 2780 Training Accuracy 0.266... Training Loss 2.922...\n",
      "Step 2790 Training Accuracy 0.281... Training Loss 2.834...\n",
      "Step 2800 Training Accuracy 0.281... Training Loss 2.615...\n",
      "Step 2810 Training Accuracy 0.234... Training Loss 3.364...\n",
      "Step 2820 Training Accuracy 0.297... Training Loss 2.876...\n",
      "Step 2830 Training Accuracy 0.250... Training Loss 2.864...\n",
      "Step 2840 Training Accuracy 0.297... Training Loss 2.863...\n",
      "Step 2850 Training Accuracy 0.250... Training Loss 2.902...\n",
      "Step 2860 Training Accuracy 0.188... Training Loss 3.096...\n",
      "Step 2870 Training Accuracy 0.328... Training Loss 2.480...\n",
      "Step 2880 Training Accuracy 0.328... Training Loss 2.774...\n",
      "Step 2890 Training Accuracy 0.188... Training Loss 2.915...\n",
      "Step 2900 Training Accuracy 0.250... Training Loss 2.927...\n",
      "Step 2910 Training Accuracy 0.328... Training Loss 2.700...\n",
      "Step 2920 Training Accuracy 0.250... Training Loss 2.781...\n",
      "Step 2930 Training Accuracy 0.172... Training Loss 3.201...\n",
      "Step 2940 Training Accuracy 0.250... Training Loss 3.038...\n",
      "Step 2950 Training Accuracy 0.203... Training Loss 3.140...\n",
      "Step 2960 Training Accuracy 0.234... Training Loss 3.095...\n",
      "Step 2970 Training Accuracy 0.219... Training Loss 3.026...\n",
      "Step 2980 Training Accuracy 0.250... Training Loss 2.773...\n",
      "Step 2990 Training Accuracy 0.281... Training Loss 2.698...\n",
      "Step 3000 Training Accuracy 0.344... Training Loss 2.892...\n",
      "Writing checkpoing at step 3000\n",
      "Step 3010 Training Accuracy 0.203... Training Loss 3.207...\n",
      "Step 3020 Training Accuracy 0.219... Training Loss 2.979...\n",
      "Step 3030 Training Accuracy 0.328... Training Loss 2.670...\n",
      "Step 3040 Training Accuracy 0.281... Training Loss 2.707...\n",
      "Step 3050 Training Accuracy 0.188... Training Loss 3.297...\n",
      "Step 3060 Training Accuracy 0.234... Training Loss 3.312...\n",
      "Step 3070 Training Accuracy 0.234... Training Loss 2.997...\n",
      "Step 3080 Training Accuracy 0.234... Training Loss 3.026...\n",
      "Step 3090 Training Accuracy 0.281... Training Loss 3.027...\n",
      "Step 3100 Training Accuracy 0.281... Training Loss 2.613...\n",
      "Step 3110 Training Accuracy 0.219... Training Loss 2.967...\n",
      "Step 3120 Training Accuracy 0.250... Training Loss 3.051...\n",
      "Step 3130 Training Accuracy 0.250... Training Loss 2.941...\n",
      "Step 3140 Training Accuracy 0.344... Training Loss 2.593...\n",
      "Step 3150 Training Accuracy 0.312... Training Loss 2.797...\n",
      "Step 3160 Training Accuracy 0.328... Training Loss 2.680...\n",
      "Step 3170 Training Accuracy 0.297... Training Loss 2.931...\n",
      "Step 3180 Training Accuracy 0.203... Training Loss 2.791...\n",
      "Step 3190 Training Accuracy 0.312... Training Loss 2.744...\n",
      "Step 3200 Training Accuracy 0.297... Training Loss 3.033...\n",
      "Step 3210 Training Accuracy 0.328... Training Loss 2.704...\n",
      "Step 3220 Training Accuracy 0.406... Training Loss 2.641...\n",
      "Step 3230 Training Accuracy 0.156... Training Loss 2.832...\n",
      "Step 3240 Training Accuracy 0.328... Training Loss 2.758...\n",
      "Step 3250 Training Accuracy 0.219... Training Loss 2.750...\n",
      "Step 3260 Training Accuracy 0.328... Training Loss 2.847...\n",
      "Step 3270 Training Accuracy 0.266... Training Loss 2.805...\n",
      "Step 3280 Training Accuracy 0.344... Training Loss 2.794...\n",
      "Step 3290 Training Accuracy 0.266... Training Loss 2.906...\n",
      "Step 3300 Training Accuracy 0.188... Training Loss 3.048...\n",
      "Step 3310 Training Accuracy 0.250... Training Loss 2.709...\n",
      "Step 3320 Training Accuracy 0.234... Training Loss 3.095...\n",
      "Step 3330 Training Accuracy 0.312... Training Loss 2.815...\n",
      "Step 3340 Training Accuracy 0.281... Training Loss 2.750...\n",
      "Step 3350 Training Accuracy 0.422... Training Loss 2.411...\n",
      "Step 3360 Training Accuracy 0.266... Training Loss 3.057...\n",
      "Step 3370 Training Accuracy 0.250... Training Loss 2.936...\n",
      "Step 3380 Training Accuracy 0.312... Training Loss 2.816...\n",
      "Step 3390 Training Accuracy 0.312... Training Loss 2.730...\n",
      "Step 3400 Training Accuracy 0.266... Training Loss 2.902...\n",
      "Step 3410 Training Accuracy 0.328... Training Loss 2.927...\n",
      "Step 3420 Training Accuracy 0.281... Training Loss 2.986...\n",
      "Step 3430 Training Accuracy 0.328... Training Loss 2.659...\n",
      "Step 3440 Training Accuracy 0.281... Training Loss 2.749...\n",
      "Step 3450 Training Accuracy 0.266... Training Loss 2.573...\n",
      "Step 3460 Training Accuracy 0.312... Training Loss 2.771...\n",
      "Step 3470 Training Accuracy 0.281... Training Loss 2.727...\n",
      "Step 3480 Training Accuracy 0.234... Training Loss 2.886...\n",
      "Step 3490 Training Accuracy 0.328... Training Loss 2.673...\n",
      "Step 3500 Training Accuracy 0.266... Training Loss 2.941...\n",
      "Step 3510 Training Accuracy 0.312... Training Loss 2.567...\n",
      "Step 3520 Training Accuracy 0.375... Training Loss 2.678...\n",
      "Step 3530 Training Accuracy 0.328... Training Loss 2.416...\n",
      "Step 3540 Training Accuracy 0.250... Training Loss 2.920...\n",
      "Step 3550 Training Accuracy 0.250... Training Loss 2.774...\n",
      "Step 3560 Training Accuracy 0.312... Training Loss 2.891...\n",
      "Step 3570 Training Accuracy 0.281... Training Loss 2.624...\n",
      "Step 3580 Training Accuracy 0.250... Training Loss 3.055...\n",
      "Step 3590 Training Accuracy 0.266... Training Loss 2.779...\n",
      "Step 3600 Training Accuracy 0.359... Training Loss 2.679...\n",
      "Step 3610 Training Accuracy 0.328... Training Loss 2.592...\n",
      "Step 3620 Training Accuracy 0.297... Training Loss 2.815...\n",
      "Step 3630 Training Accuracy 0.250... Training Loss 2.891...\n",
      "Step 3640 Training Accuracy 0.328... Training Loss 2.917...\n",
      "Step 3650 Training Accuracy 0.328... Training Loss 2.626...\n",
      "Step 3660 Training Accuracy 0.188... Training Loss 3.142...\n",
      "Step 3670 Training Accuracy 0.297... Training Loss 2.808...\n",
      "Step 3680 Training Accuracy 0.359... Training Loss 2.674...\n",
      "Step 3690 Training Accuracy 0.297... Training Loss 2.729...\n",
      "Step 3700 Training Accuracy 0.359... Training Loss 2.422...\n",
      "Step 3710 Training Accuracy 0.219... Training Loss 2.907...\n",
      "Step 3720 Training Accuracy 0.234... Training Loss 2.788...\n",
      "Step 3730 Training Accuracy 0.375... Training Loss 2.589...\n",
      "Step 3740 Training Accuracy 0.375... Training Loss 2.619...\n",
      "Step 3750 Training Accuracy 0.281... Training Loss 2.640...\n",
      "Step 3760 Training Accuracy 0.391... Training Loss 2.413...\n",
      "Step 3770 Training Accuracy 0.344... Training Loss 2.629...\n",
      "Step 3780 Training Accuracy 0.281... Training Loss 2.926...\n",
      "Step 3790 Training Accuracy 0.250... Training Loss 2.927...\n",
      "Step 3800 Training Accuracy 0.328... Training Loss 2.674...\n",
      "Step 3810 Training Accuracy 0.281... Training Loss 2.578...\n",
      "Step 3820 Training Accuracy 0.391... Training Loss 2.704...\n",
      "Step 3830 Training Accuracy 0.234... Training Loss 3.322...\n",
      "Step 3840 Training Accuracy 0.188... Training Loss 2.883...\n",
      "Step 3850 Training Accuracy 0.219... Training Loss 2.784...\n",
      "Step 3860 Training Accuracy 0.312... Training Loss 2.660...\n",
      "Step 3870 Training Accuracy 0.328... Training Loss 2.600...\n",
      "Step 3880 Training Accuracy 0.250... Training Loss 2.768...\n",
      "Step 3890 Training Accuracy 0.266... Training Loss 2.783...\n",
      "Step 3900 Training Accuracy 0.172... Training Loss 2.967...\n",
      "Step 3910 Training Accuracy 0.406... Training Loss 2.805...\n",
      "Step 3920 Training Accuracy 0.391... Training Loss 2.737...\n",
      "Step 3930 Training Accuracy 0.328... Training Loss 2.554...\n",
      "Step 3940 Training Accuracy 0.328... Training Loss 2.598...\n",
      "Step 3950 Training Accuracy 0.344... Training Loss 2.580...\n",
      "Step 3960 Training Accuracy 0.297... Training Loss 2.748...\n",
      "Step 3970 Training Accuracy 0.250... Training Loss 2.598...\n",
      "Step 3980 Training Accuracy 0.422... Training Loss 2.723...\n",
      "Step 3990 Training Accuracy 0.297... Training Loss 2.524...\n",
      "Step 4000 Training Accuracy 0.250... Training Loss 3.043...\n",
      "Writing checkpoing at step 4000\n",
      "Step 4010 Training Accuracy 0.281... Training Loss 2.840...\n",
      "Step 4020 Training Accuracy 0.281... Training Loss 2.567...\n",
      "Step 4030 Training Accuracy 0.297... Training Loss 2.594...\n",
      "Step 4040 Training Accuracy 0.297... Training Loss 2.670...\n",
      "Step 4050 Training Accuracy 0.391... Training Loss 2.401...\n",
      "Step 4060 Training Accuracy 0.328... Training Loss 2.812...\n",
      "Step 4070 Training Accuracy 0.359... Training Loss 2.539...\n",
      "Step 4080 Training Accuracy 0.203... Training Loss 2.919...\n",
      "Step 4090 Training Accuracy 0.297... Training Loss 2.544...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4100 Training Accuracy 0.328... Training Loss 2.377...\n",
      "Step 4110 Training Accuracy 0.406... Training Loss 2.315...\n",
      "Step 4120 Training Accuracy 0.328... Training Loss 2.680...\n",
      "Step 4130 Training Accuracy 0.297... Training Loss 2.538...\n",
      "Step 4140 Training Accuracy 0.172... Training Loss 3.289...\n",
      "Step 4150 Training Accuracy 0.312... Training Loss 2.801...\n",
      "Step 4160 Training Accuracy 0.297... Training Loss 2.498...\n",
      "Step 4170 Training Accuracy 0.312... Training Loss 2.651...\n",
      "Step 4180 Training Accuracy 0.375... Training Loss 2.597...\n",
      "Step 4190 Training Accuracy 0.266... Training Loss 2.599...\n",
      "Step 4200 Training Accuracy 0.297... Training Loss 2.569...\n",
      "Step 4210 Training Accuracy 0.312... Training Loss 2.867...\n",
      "Step 4220 Training Accuracy 0.250... Training Loss 2.718...\n",
      "Step 4230 Training Accuracy 0.422... Training Loss 1.996...\n",
      "Step 4240 Training Accuracy 0.234... Training Loss 2.903...\n",
      "Step 4250 Training Accuracy 0.297... Training Loss 2.940...\n",
      "Step 4260 Training Accuracy 0.438... Training Loss 2.646...\n",
      "Step 4270 Training Accuracy 0.234... Training Loss 2.777...\n",
      "Step 4280 Training Accuracy 0.312... Training Loss 2.597...\n",
      "Step 4290 Training Accuracy 0.344... Training Loss 2.315...\n",
      "Step 4300 Training Accuracy 0.219... Training Loss 3.054...\n",
      "Step 4310 Training Accuracy 0.266... Training Loss 2.971...\n",
      "Step 4320 Training Accuracy 0.203... Training Loss 2.796...\n",
      "Step 4330 Training Accuracy 0.266... Training Loss 2.749...\n",
      "Step 4340 Training Accuracy 0.297... Training Loss 2.626...\n",
      "Step 4350 Training Accuracy 0.281... Training Loss 2.660...\n",
      "Step 4360 Training Accuracy 0.359... Training Loss 2.305...\n",
      "Step 4370 Training Accuracy 0.266... Training Loss 2.961...\n",
      "Step 4380 Training Accuracy 0.344... Training Loss 2.768...\n",
      "Step 4390 Training Accuracy 0.328... Training Loss 2.658...\n",
      "Step 4400 Training Accuracy 0.281... Training Loss 2.733...\n",
      "Step 4410 Training Accuracy 0.344... Training Loss 2.403...\n",
      "Step 4420 Training Accuracy 0.297... Training Loss 2.779...\n",
      "Step 4430 Training Accuracy 0.312... Training Loss 2.526...\n",
      "Step 4440 Training Accuracy 0.375... Training Loss 2.276...\n",
      "Step 4450 Training Accuracy 0.328... Training Loss 2.989...\n",
      "Step 4460 Training Accuracy 0.453... Training Loss 2.321...\n",
      "Step 4470 Training Accuracy 0.328... Training Loss 2.505...\n",
      "Step 4480 Training Accuracy 0.375... Training Loss 2.582...\n",
      "Step 4490 Training Accuracy 0.406... Training Loss 2.413...\n",
      "Step 4500 Training Accuracy 0.297... Training Loss 2.410...\n",
      "Step 4510 Training Accuracy 0.328... Training Loss 2.718...\n",
      "Step 4520 Training Accuracy 0.375... Training Loss 2.794...\n",
      "Step 4530 Training Accuracy 0.312... Training Loss 2.763...\n",
      "Step 4540 Training Accuracy 0.422... Training Loss 2.291...\n",
      "Step 4550 Training Accuracy 0.359... Training Loss 2.550...\n",
      "Step 4560 Training Accuracy 0.391... Training Loss 2.424...\n",
      "Step 4570 Training Accuracy 0.297... Training Loss 2.776...\n",
      "Step 4580 Training Accuracy 0.312... Training Loss 2.580...\n",
      "Step 4590 Training Accuracy 0.344... Training Loss 2.526...\n",
      "Step 4600 Training Accuracy 0.344... Training Loss 2.465...\n",
      "Step 4610 Training Accuracy 0.375... Training Loss 2.433...\n",
      "Step 4620 Training Accuracy 0.281... Training Loss 2.409...\n",
      "Step 4630 Training Accuracy 0.344... Training Loss 2.417...\n",
      "Step 4640 Training Accuracy 0.344... Training Loss 2.454...\n",
      "Step 4650 Training Accuracy 0.328... Training Loss 2.618...\n",
      "Step 4660 Training Accuracy 0.281... Training Loss 2.923...\n",
      "Step 4670 Training Accuracy 0.328... Training Loss 2.634...\n",
      "Step 4680 Training Accuracy 0.328... Training Loss 2.672...\n",
      "Step 4690 Training Accuracy 0.312... Training Loss 2.568...\n",
      "Step 4700 Training Accuracy 0.359... Training Loss 2.674...\n",
      "Step 4710 Training Accuracy 0.344... Training Loss 2.222...\n",
      "Step 4720 Training Accuracy 0.312... Training Loss 2.542...\n",
      "Step 4730 Training Accuracy 0.406... Training Loss 2.433...\n",
      "Step 4740 Training Accuracy 0.344... Training Loss 2.602...\n",
      "Step 4750 Training Accuracy 0.281... Training Loss 2.570...\n",
      "Step 4760 Training Accuracy 0.281... Training Loss 2.772...\n",
      "Step 4770 Training Accuracy 0.281... Training Loss 2.379...\n",
      "Step 4780 Training Accuracy 0.391... Training Loss 2.348...\n",
      "Step 4790 Training Accuracy 0.312... Training Loss 2.539...\n",
      "Step 4800 Training Accuracy 0.359... Training Loss 2.342...\n",
      "Step 4810 Training Accuracy 0.328... Training Loss 2.666...\n",
      "Step 4820 Training Accuracy 0.391... Training Loss 2.385...\n",
      "Step 4830 Training Accuracy 0.312... Training Loss 2.660...\n",
      "Step 4840 Training Accuracy 0.328... Training Loss 2.362...\n",
      "Step 4850 Training Accuracy 0.359... Training Loss 2.406...\n",
      "Step 4860 Training Accuracy 0.344... Training Loss 2.551...\n",
      "Step 4870 Training Accuracy 0.406... Training Loss 2.569...\n",
      "Step 4880 Training Accuracy 0.281... Training Loss 2.540...\n",
      "Step 4890 Training Accuracy 0.312... Training Loss 2.983...\n",
      "Step 4900 Training Accuracy 0.484... Training Loss 2.086...\n",
      "Step 4910 Training Accuracy 0.344... Training Loss 2.521...\n",
      "Step 4920 Training Accuracy 0.375... Training Loss 2.268...\n",
      "Step 4930 Training Accuracy 0.391... Training Loss 2.385...\n",
      "Step 4940 Training Accuracy 0.328... Training Loss 2.667...\n",
      "Step 4950 Training Accuracy 0.359... Training Loss 2.049...\n",
      "Step 4960 Training Accuracy 0.312... Training Loss 2.403...\n",
      "Step 4970 Training Accuracy 0.297... Training Loss 2.422...\n",
      "Step 4980 Training Accuracy 0.328... Training Loss 2.560...\n",
      "Step 4990 Training Accuracy 0.422... Training Loss 1.976...\n",
      "Step 5000 Training Accuracy 0.438... Training Loss 2.445...\n",
      "Writing checkpoing at step 5000\n",
      "Step 5010 Training Accuracy 0.359... Training Loss 2.613...\n",
      "Step 5020 Training Accuracy 0.312... Training Loss 2.468...\n",
      "Step 5030 Training Accuracy 0.250... Training Loss 2.522...\n",
      "Step 5040 Training Accuracy 0.453... Training Loss 2.188...\n",
      "Step 5050 Training Accuracy 0.359... Training Loss 2.330...\n",
      "Step 5060 Training Accuracy 0.422... Training Loss 2.183...\n",
      "Step 5070 Training Accuracy 0.266... Training Loss 2.742...\n",
      "Step 5080 Training Accuracy 0.328... Training Loss 2.571...\n",
      "Step 5090 Training Accuracy 0.297... Training Loss 2.611...\n",
      "Step 5100 Training Accuracy 0.391... Training Loss 2.408...\n",
      "Step 5110 Training Accuracy 0.312... Training Loss 2.686...\n",
      "Step 5120 Training Accuracy 0.328... Training Loss 2.468...\n",
      "Step 5130 Training Accuracy 0.453... Training Loss 2.200...\n",
      "Step 5140 Training Accuracy 0.344... Training Loss 2.468...\n",
      "Step 5150 Training Accuracy 0.312... Training Loss 2.729...\n",
      "Step 5160 Training Accuracy 0.375... Training Loss 2.431...\n",
      "Step 5170 Training Accuracy 0.281... Training Loss 2.492...\n",
      "Step 5180 Training Accuracy 0.391... Training Loss 2.562...\n",
      "Step 5190 Training Accuracy 0.438... Training Loss 1.969...\n",
      "Step 5200 Training Accuracy 0.312... Training Loss 2.459...\n",
      "Step 5210 Training Accuracy 0.328... Training Loss 2.404...\n",
      "Step 5220 Training Accuracy 0.422... Training Loss 2.069...\n",
      "Step 5230 Training Accuracy 0.328... Training Loss 2.544...\n",
      "Step 5240 Training Accuracy 0.438... Training Loss 2.434...\n",
      "Step 5250 Training Accuracy 0.375... Training Loss 2.373...\n",
      "Step 5260 Training Accuracy 0.375... Training Loss 2.250...\n",
      "Step 5270 Training Accuracy 0.344... Training Loss 2.590...\n",
      "Step 5280 Training Accuracy 0.469... Training Loss 2.219...\n",
      "Step 5290 Training Accuracy 0.297... Training Loss 2.440...\n",
      "Step 5300 Training Accuracy 0.375... Training Loss 2.367...\n",
      "Step 5310 Training Accuracy 0.422... Training Loss 2.129...\n",
      "Step 5320 Training Accuracy 0.438... Training Loss 2.162...\n",
      "Step 5330 Training Accuracy 0.328... Training Loss 2.508...\n",
      "Step 5340 Training Accuracy 0.391... Training Loss 2.221...\n",
      "Step 5350 Training Accuracy 0.375... Training Loss 2.204...\n",
      "Step 5360 Training Accuracy 0.344... Training Loss 2.472...\n",
      "Step 5370 Training Accuracy 0.422... Training Loss 2.185...\n",
      "Step 5380 Training Accuracy 0.328... Training Loss 2.309...\n",
      "Step 5390 Training Accuracy 0.391... Training Loss 2.358...\n",
      "Step 5400 Training Accuracy 0.469... Training Loss 2.129...\n",
      "Step 5410 Training Accuracy 0.328... Training Loss 2.429...\n",
      "Step 5420 Training Accuracy 0.469... Training Loss 2.056...\n",
      "Step 5430 Training Accuracy 0.344... Training Loss 2.551...\n",
      "Step 5440 Training Accuracy 0.391... Training Loss 2.533...\n",
      "Step 5450 Training Accuracy 0.422... Training Loss 2.584...\n",
      "Step 5460 Training Accuracy 0.375... Training Loss 2.467...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5470 Training Accuracy 0.469... Training Loss 2.080...\n",
      "Step 5480 Training Accuracy 0.453... Training Loss 2.037...\n",
      "Step 5490 Training Accuracy 0.375... Training Loss 2.241...\n",
      "Step 5500 Training Accuracy 0.406... Training Loss 2.218...\n",
      "Step 5510 Training Accuracy 0.297... Training Loss 2.428...\n",
      "Step 5520 Training Accuracy 0.328... Training Loss 2.561...\n",
      "Step 5530 Training Accuracy 0.297... Training Loss 2.690...\n",
      "Step 5540 Training Accuracy 0.391... Training Loss 2.476...\n",
      "Step 5550 Training Accuracy 0.484... Training Loss 1.928...\n",
      "Step 5560 Training Accuracy 0.500... Training Loss 2.073...\n",
      "Step 5570 Training Accuracy 0.406... Training Loss 2.244...\n",
      "Step 5580 Training Accuracy 0.438... Training Loss 2.275...\n",
      "Step 5590 Training Accuracy 0.328... Training Loss 2.669...\n",
      "Step 5600 Training Accuracy 0.359... Training Loss 2.196...\n",
      "Step 5610 Training Accuracy 0.391... Training Loss 2.279...\n",
      "Step 5620 Training Accuracy 0.375... Training Loss 2.299...\n",
      "Step 5630 Training Accuracy 0.375... Training Loss 2.374...\n",
      "Step 5640 Training Accuracy 0.344... Training Loss 2.166...\n",
      "Step 5650 Training Accuracy 0.312... Training Loss 2.624...\n",
      "Step 5660 Training Accuracy 0.500... Training Loss 2.182...\n",
      "Step 5670 Training Accuracy 0.266... Training Loss 2.798...\n",
      "Step 5680 Training Accuracy 0.422... Training Loss 2.240...\n",
      "Step 5690 Training Accuracy 0.469... Training Loss 2.273...\n",
      "Step 5700 Training Accuracy 0.391... Training Loss 2.301...\n",
      "Step 5710 Training Accuracy 0.375... Training Loss 2.544...\n",
      "Step 5720 Training Accuracy 0.391... Training Loss 2.203...\n",
      "Step 5730 Training Accuracy 0.406... Training Loss 2.228...\n",
      "Step 5740 Training Accuracy 0.312... Training Loss 2.463...\n",
      "Step 5750 Training Accuracy 0.422... Training Loss 1.921...\n",
      "Step 5760 Training Accuracy 0.281... Training Loss 2.860...\n",
      "Step 5770 Training Accuracy 0.328... Training Loss 2.397...\n",
      "Step 5780 Training Accuracy 0.438... Training Loss 2.243...\n",
      "Step 5790 Training Accuracy 0.438... Training Loss 2.504...\n",
      "Step 5800 Training Accuracy 0.422... Training Loss 1.984...\n",
      "Step 5810 Training Accuracy 0.484... Training Loss 1.952...\n",
      "Step 5820 Training Accuracy 0.422... Training Loss 1.983...\n",
      "Step 5830 Training Accuracy 0.500... Training Loss 1.836...\n",
      "Step 5840 Training Accuracy 0.422... Training Loss 2.061...\n",
      "Step 5850 Training Accuracy 0.391... Training Loss 2.371...\n",
      "Step 5860 Training Accuracy 0.422... Training Loss 2.192...\n",
      "Step 5870 Training Accuracy 0.547... Training Loss 2.065...\n",
      "Step 5880 Training Accuracy 0.469... Training Loss 1.861...\n",
      "Step 5890 Training Accuracy 0.375... Training Loss 2.389...\n",
      "Step 5900 Training Accuracy 0.344... Training Loss 2.343...\n",
      "Step 5910 Training Accuracy 0.344... Training Loss 2.336...\n",
      "Step 5920 Training Accuracy 0.375... Training Loss 2.560...\n",
      "Step 5930 Training Accuracy 0.406... Training Loss 2.138...\n",
      "Step 5940 Training Accuracy 0.344... Training Loss 2.399...\n",
      "Step 5950 Training Accuracy 0.312... Training Loss 2.433...\n",
      "Step 5960 Training Accuracy 0.406... Training Loss 2.162...\n",
      "Step 5970 Training Accuracy 0.531... Training Loss 1.735...\n",
      "Step 5980 Training Accuracy 0.453... Training Loss 2.118...\n",
      "Step 5990 Training Accuracy 0.328... Training Loss 2.183...\n",
      "Step 6000 Training Accuracy 0.406... Training Loss 2.030...\n",
      "Writing checkpoing at step 6000\n",
      "Step 6010 Training Accuracy 0.391... Training Loss 2.498...\n",
      "Step 6020 Training Accuracy 0.328... Training Loss 2.354...\n",
      "Step 6030 Training Accuracy 0.406... Training Loss 2.378...\n",
      "Step 6040 Training Accuracy 0.406... Training Loss 2.227...\n",
      "Step 6050 Training Accuracy 0.391... Training Loss 2.139...\n",
      "Step 6060 Training Accuracy 0.297... Training Loss 2.429...\n",
      "Step 6070 Training Accuracy 0.500... Training Loss 1.873...\n",
      "Step 6080 Training Accuracy 0.500... Training Loss 1.908...\n",
      "Step 6090 Training Accuracy 0.438... Training Loss 2.094...\n",
      "Step 6100 Training Accuracy 0.406... Training Loss 2.310...\n",
      "Step 6110 Training Accuracy 0.453... Training Loss 2.136...\n",
      "Step 6120 Training Accuracy 0.438... Training Loss 1.957...\n",
      "Step 6130 Training Accuracy 0.500... Training Loss 1.908...\n",
      "Step 6140 Training Accuracy 0.375... Training Loss 2.410...\n",
      "Step 6150 Training Accuracy 0.359... Training Loss 2.217...\n",
      "Step 6160 Training Accuracy 0.500... Training Loss 2.039...\n",
      "Step 6170 Training Accuracy 0.391... Training Loss 2.325...\n",
      "Step 6180 Training Accuracy 0.344... Training Loss 2.731...\n",
      "Step 6190 Training Accuracy 0.344... Training Loss 2.405...\n",
      "Step 6200 Training Accuracy 0.359... Training Loss 2.286...\n",
      "Step 6210 Training Accuracy 0.469... Training Loss 2.010...\n",
      "Step 6220 Training Accuracy 0.328... Training Loss 2.099...\n",
      "Step 6230 Training Accuracy 0.406... Training Loss 2.429...\n",
      "Step 6240 Training Accuracy 0.453... Training Loss 1.932...\n",
      "Step 6250 Training Accuracy 0.438... Training Loss 2.030...\n",
      "Step 6260 Training Accuracy 0.391... Training Loss 2.222...\n",
      "Step 6270 Training Accuracy 0.375... Training Loss 2.272...\n",
      "Step 6280 Training Accuracy 0.422... Training Loss 2.219...\n",
      "Step 6290 Training Accuracy 0.484... Training Loss 2.201...\n",
      "Step 6300 Training Accuracy 0.516... Training Loss 1.977...\n",
      "Step 6310 Training Accuracy 0.406... Training Loss 2.003...\n",
      "Step 6320 Training Accuracy 0.328... Training Loss 2.398...\n",
      "Step 6330 Training Accuracy 0.375... Training Loss 2.493...\n",
      "Step 6340 Training Accuracy 0.344... Training Loss 2.156...\n",
      "Step 6350 Training Accuracy 0.359... Training Loss 2.484...\n",
      "Step 6360 Training Accuracy 0.422... Training Loss 2.113...\n",
      "Step 6370 Training Accuracy 0.453... Training Loss 1.886...\n",
      "Step 6380 Training Accuracy 0.547... Training Loss 1.752...\n",
      "Step 6390 Training Accuracy 0.406... Training Loss 1.989...\n",
      "Step 6400 Training Accuracy 0.391... Training Loss 2.284...\n",
      "Step 6410 Training Accuracy 0.312... Training Loss 2.761...\n",
      "Step 6420 Training Accuracy 0.531... Training Loss 1.791...\n",
      "Step 6430 Training Accuracy 0.469... Training Loss 1.980...\n",
      "Step 6440 Training Accuracy 0.391... Training Loss 2.147...\n",
      "Step 6450 Training Accuracy 0.484... Training Loss 2.066...\n",
      "Step 6460 Training Accuracy 0.453... Training Loss 1.993...\n",
      "Step 6470 Training Accuracy 0.484... Training Loss 2.178...\n",
      "Step 6480 Training Accuracy 0.438... Training Loss 2.121...\n",
      "Step 6490 Training Accuracy 0.391... Training Loss 2.167...\n",
      "Step 6500 Training Accuracy 0.328... Training Loss 2.374...\n",
      "Step 6510 Training Accuracy 0.359... Training Loss 2.206...\n",
      "Step 6520 Training Accuracy 0.500... Training Loss 2.079...\n",
      "Step 6530 Training Accuracy 0.406... Training Loss 2.211...\n",
      "Step 6540 Training Accuracy 0.516... Training Loss 1.980...\n",
      "Step 6550 Training Accuracy 0.391... Training Loss 2.077...\n",
      "Step 6560 Training Accuracy 0.359... Training Loss 2.016...\n",
      "Step 6570 Training Accuracy 0.359... Training Loss 2.131...\n",
      "Step 6580 Training Accuracy 0.422... Training Loss 2.183...\n",
      "Step 6590 Training Accuracy 0.312... Training Loss 2.455...\n",
      "Step 6600 Training Accuracy 0.500... Training Loss 1.946...\n",
      "Step 6610 Training Accuracy 0.469... Training Loss 2.074...\n",
      "Step 6620 Training Accuracy 0.531... Training Loss 1.970...\n",
      "Step 6630 Training Accuracy 0.359... Training Loss 2.237...\n",
      "Step 6640 Training Accuracy 0.531... Training Loss 2.095...\n",
      "Step 6650 Training Accuracy 0.531... Training Loss 1.585...\n",
      "Step 6660 Training Accuracy 0.578... Training Loss 1.970...\n",
      "Step 6670 Training Accuracy 0.578... Training Loss 1.609...\n",
      "Step 6680 Training Accuracy 0.469... Training Loss 1.781...\n",
      "Step 6690 Training Accuracy 0.531... Training Loss 1.740...\n",
      "Step 6700 Training Accuracy 0.359... Training Loss 2.186...\n",
      "Step 6710 Training Accuracy 0.406... Training Loss 2.325...\n",
      "Step 6720 Training Accuracy 0.531... Training Loss 2.006...\n",
      "Step 6730 Training Accuracy 0.375... Training Loss 2.422...\n",
      "Step 6740 Training Accuracy 0.469... Training Loss 2.211...\n",
      "Step 6750 Training Accuracy 0.438... Training Loss 2.361...\n",
      "Step 6760 Training Accuracy 0.516... Training Loss 2.082...\n",
      "Step 6770 Training Accuracy 0.344... Training Loss 2.470...\n",
      "Step 6780 Training Accuracy 0.359... Training Loss 2.171...\n",
      "Step 6790 Training Accuracy 0.438... Training Loss 2.150...\n",
      "Step 6800 Training Accuracy 0.391... Training Loss 1.957...\n",
      "Step 6810 Training Accuracy 0.484... Training Loss 1.878...\n",
      "Step 6820 Training Accuracy 0.438... Training Loss 2.085...\n",
      "Step 6830 Training Accuracy 0.359... Training Loss 2.168...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6840 Training Accuracy 0.344... Training Loss 2.421...\n",
      "Step 6850 Training Accuracy 0.359... Training Loss 2.128...\n",
      "Step 6860 Training Accuracy 0.500... Training Loss 1.946...\n",
      "Step 6870 Training Accuracy 0.359... Training Loss 2.323...\n",
      "Step 6880 Training Accuracy 0.469... Training Loss 2.054...\n",
      "Step 6890 Training Accuracy 0.484... Training Loss 2.076...\n",
      "Step 6900 Training Accuracy 0.531... Training Loss 1.846...\n",
      "Step 6910 Training Accuracy 0.500... Training Loss 1.575...\n",
      "Step 6920 Training Accuracy 0.406... Training Loss 1.988...\n",
      "Step 6930 Training Accuracy 0.375... Training Loss 2.135...\n",
      "Step 6940 Training Accuracy 0.438... Training Loss 2.086...\n",
      "Step 6950 Training Accuracy 0.469... Training Loss 2.102...\n",
      "Step 6960 Training Accuracy 0.406... Training Loss 2.154...\n",
      "Step 6970 Training Accuracy 0.469... Training Loss 1.865...\n",
      "Step 6980 Training Accuracy 0.438... Training Loss 1.778...\n",
      "Step 6990 Training Accuracy 0.484... Training Loss 1.863...\n",
      "Step 7000 Training Accuracy 0.453... Training Loss 2.183...\n",
      "Writing checkpoing at step 7000\n",
      "Step 7010 Training Accuracy 0.484... Training Loss 1.843...\n",
      "Step 7020 Training Accuracy 0.484... Training Loss 1.867...\n",
      "Step 7030 Training Accuracy 0.328... Training Loss 2.348...\n",
      "Step 7040 Training Accuracy 0.469... Training Loss 1.786...\n",
      "Step 7050 Training Accuracy 0.453... Training Loss 2.058...\n",
      "Step 7060 Training Accuracy 0.562... Training Loss 1.783...\n",
      "Step 7070 Training Accuracy 0.391... Training Loss 2.242...\n",
      "Step 7080 Training Accuracy 0.359... Training Loss 2.077...\n",
      "Step 7090 Training Accuracy 0.453... Training Loss 1.858...\n",
      "Step 7100 Training Accuracy 0.438... Training Loss 2.039...\n",
      "Step 7110 Training Accuracy 0.438... Training Loss 1.960...\n",
      "Step 7120 Training Accuracy 0.484... Training Loss 2.071...\n",
      "Step 7130 Training Accuracy 0.516... Training Loss 1.904...\n",
      "Step 7140 Training Accuracy 0.500... Training Loss 1.783...\n",
      "Step 7150 Training Accuracy 0.438... Training Loss 1.753...\n",
      "Step 7160 Training Accuracy 0.516... Training Loss 1.740...\n",
      "Step 7170 Training Accuracy 0.469... Training Loss 1.906...\n",
      "Step 7180 Training Accuracy 0.484... Training Loss 2.143...\n",
      "Step 7190 Training Accuracy 0.500... Training Loss 1.791...\n",
      "Step 7200 Training Accuracy 0.375... Training Loss 1.882...\n",
      "Step 7210 Training Accuracy 0.484... Training Loss 1.860...\n",
      "Step 7220 Training Accuracy 0.438... Training Loss 2.333...\n",
      "Step 7230 Training Accuracy 0.422... Training Loss 2.096...\n",
      "Step 7240 Training Accuracy 0.516... Training Loss 1.890...\n",
      "Step 7250 Training Accuracy 0.453... Training Loss 1.938...\n",
      "Step 7260 Training Accuracy 0.391... Training Loss 2.181...\n",
      "Step 7270 Training Accuracy 0.531... Training Loss 2.095...\n",
      "Step 7280 Training Accuracy 0.484... Training Loss 1.958...\n",
      "Step 7290 Training Accuracy 0.500... Training Loss 1.748...\n",
      "Step 7300 Training Accuracy 0.328... Training Loss 2.504...\n",
      "Step 7310 Training Accuracy 0.500... Training Loss 1.706...\n",
      "Step 7320 Training Accuracy 0.531... Training Loss 1.807...\n",
      "Step 7330 Training Accuracy 0.562... Training Loss 1.690...\n",
      "Step 7340 Training Accuracy 0.328... Training Loss 2.142...\n",
      "Step 7350 Training Accuracy 0.438... Training Loss 2.042...\n",
      "Step 7360 Training Accuracy 0.500... Training Loss 1.851...\n",
      "Step 7370 Training Accuracy 0.578... Training Loss 1.762...\n",
      "Step 7380 Training Accuracy 0.547... Training Loss 1.582...\n",
      "Step 7390 Training Accuracy 0.578... Training Loss 1.682...\n",
      "Step 7400 Training Accuracy 0.406... Training Loss 2.157...\n",
      "Step 7410 Training Accuracy 0.438... Training Loss 1.964...\n",
      "Step 7420 Training Accuracy 0.500... Training Loss 1.847...\n",
      "Step 7430 Training Accuracy 0.438... Training Loss 1.843...\n",
      "Step 7440 Training Accuracy 0.453... Training Loss 2.069...\n",
      "Step 7450 Training Accuracy 0.438... Training Loss 1.970...\n",
      "Step 7460 Training Accuracy 0.594... Training Loss 1.619...\n",
      "Step 7470 Training Accuracy 0.375... Training Loss 2.019...\n",
      "Step 7480 Training Accuracy 0.484... Training Loss 1.883...\n",
      "Step 7490 Training Accuracy 0.422... Training Loss 1.968...\n",
      "Step 7500 Training Accuracy 0.453... Training Loss 2.148...\n",
      "Step 7510 Training Accuracy 0.469... Training Loss 1.968...\n",
      "Step 7520 Training Accuracy 0.484... Training Loss 1.804...\n",
      "Step 7530 Training Accuracy 0.453... Training Loss 1.917...\n",
      "Step 7540 Training Accuracy 0.406... Training Loss 2.085...\n",
      "Step 7550 Training Accuracy 0.469... Training Loss 1.956...\n",
      "Step 7560 Training Accuracy 0.547... Training Loss 1.848...\n",
      "Step 7570 Training Accuracy 0.375... Training Loss 2.131...\n",
      "Step 7580 Training Accuracy 0.562... Training Loss 1.582...\n",
      "Step 7590 Training Accuracy 0.500... Training Loss 1.847...\n",
      "Step 7600 Training Accuracy 0.391... Training Loss 2.107...\n",
      "Step 7610 Training Accuracy 0.422... Training Loss 1.982...\n",
      "Step 7620 Training Accuracy 0.531... Training Loss 1.850...\n",
      "Step 7630 Training Accuracy 0.406... Training Loss 2.317...\n",
      "Step 7640 Training Accuracy 0.500... Training Loss 1.802...\n",
      "Step 7650 Training Accuracy 0.500... Training Loss 1.830...\n",
      "Step 7660 Training Accuracy 0.609... Training Loss 1.735...\n",
      "Step 7670 Training Accuracy 0.406... Training Loss 2.010...\n",
      "Step 7680 Training Accuracy 0.422... Training Loss 1.803...\n",
      "Step 7690 Training Accuracy 0.500... Training Loss 1.677...\n",
      "Step 7700 Training Accuracy 0.438... Training Loss 1.949...\n",
      "Step 7710 Training Accuracy 0.453... Training Loss 1.998...\n",
      "Step 7720 Training Accuracy 0.516... Training Loss 1.928...\n",
      "Step 7730 Training Accuracy 0.359... Training Loss 2.085...\n",
      "Step 7740 Training Accuracy 0.516... Training Loss 1.775...\n",
      "Step 7750 Training Accuracy 0.516... Training Loss 1.805...\n",
      "Step 7760 Training Accuracy 0.422... Training Loss 1.782...\n",
      "Step 7770 Training Accuracy 0.594... Training Loss 1.509...\n",
      "Step 7780 Training Accuracy 0.406... Training Loss 2.124...\n",
      "Step 7790 Training Accuracy 0.562... Training Loss 1.898...\n",
      "Step 7800 Training Accuracy 0.438... Training Loss 2.038...\n",
      "Step 7810 Training Accuracy 0.422... Training Loss 1.916...\n",
      "Step 7820 Training Accuracy 0.469... Training Loss 1.993...\n",
      "Step 7830 Training Accuracy 0.516... Training Loss 1.731...\n",
      "Step 7840 Training Accuracy 0.469... Training Loss 2.028...\n",
      "Step 7850 Training Accuracy 0.391... Training Loss 1.768...\n",
      "Step 7860 Training Accuracy 0.484... Training Loss 1.879...\n",
      "Step 7870 Training Accuracy 0.391... Training Loss 2.033...\n",
      "Step 7880 Training Accuracy 0.453... Training Loss 2.016...\n",
      "Step 7890 Training Accuracy 0.531... Training Loss 1.666...\n",
      "Step 7900 Training Accuracy 0.547... Training Loss 1.473...\n",
      "Step 7910 Training Accuracy 0.547... Training Loss 1.664...\n",
      "Step 7920 Training Accuracy 0.469... Training Loss 1.835...\n",
      "Step 7930 Training Accuracy 0.484... Training Loss 1.869...\n",
      "Step 7940 Training Accuracy 0.547... Training Loss 1.980...\n",
      "Step 7950 Training Accuracy 0.547... Training Loss 1.669...\n",
      "Step 7960 Training Accuracy 0.578... Training Loss 1.448...\n",
      "Step 7970 Training Accuracy 0.469... Training Loss 2.000...\n",
      "Step 7980 Training Accuracy 0.469... Training Loss 1.866...\n",
      "Step 7990 Training Accuracy 0.453... Training Loss 1.983...\n",
      "Step 8000 Training Accuracy 0.406... Training Loss 1.817...\n",
      "Writing checkpoing at step 8000\n",
      "Step 8010 Training Accuracy 0.500... Training Loss 1.634...\n",
      "Step 8020 Training Accuracy 0.469... Training Loss 1.640...\n",
      "Step 8030 Training Accuracy 0.594... Training Loss 1.422...\n",
      "Step 8040 Training Accuracy 0.484... Training Loss 1.993...\n",
      "Step 8050 Training Accuracy 0.547... Training Loss 1.624...\n",
      "Step 8060 Training Accuracy 0.438... Training Loss 1.934...\n",
      "Step 8070 Training Accuracy 0.344... Training Loss 2.060...\n",
      "Step 8080 Training Accuracy 0.484... Training Loss 1.654...\n",
      "Step 8090 Training Accuracy 0.531... Training Loss 1.642...\n",
      "Step 8100 Training Accuracy 0.500... Training Loss 1.537...\n",
      "Step 8110 Training Accuracy 0.453... Training Loss 2.032...\n",
      "Step 8120 Training Accuracy 0.516... Training Loss 1.584...\n",
      "Step 8130 Training Accuracy 0.453... Training Loss 1.941...\n",
      "Step 8140 Training Accuracy 0.500... Training Loss 1.788...\n",
      "Step 8150 Training Accuracy 0.656... Training Loss 1.402...\n",
      "Step 8160 Training Accuracy 0.672... Training Loss 1.207...\n",
      "Step 8170 Training Accuracy 0.391... Training Loss 2.047...\n",
      "Step 8180 Training Accuracy 0.609... Training Loss 1.480...\n",
      "Step 8190 Training Accuracy 0.422... Training Loss 1.887...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8200 Training Accuracy 0.531... Training Loss 1.575...\n",
      "Step 8210 Training Accuracy 0.516... Training Loss 1.833...\n",
      "Step 8220 Training Accuracy 0.469... Training Loss 1.774...\n",
      "Step 8230 Training Accuracy 0.484... Training Loss 1.781...\n",
      "Step 8240 Training Accuracy 0.578... Training Loss 1.741...\n",
      "Step 8250 Training Accuracy 0.562... Training Loss 1.685...\n",
      "Step 8260 Training Accuracy 0.484... Training Loss 1.744...\n",
      "Step 8270 Training Accuracy 0.391... Training Loss 2.015...\n",
      "Step 8280 Training Accuracy 0.453... Training Loss 1.865...\n",
      "Step 8290 Training Accuracy 0.578... Training Loss 1.579...\n",
      "Step 8300 Training Accuracy 0.547... Training Loss 1.703...\n",
      "Step 8310 Training Accuracy 0.453... Training Loss 1.647...\n",
      "Step 8320 Training Accuracy 0.469... Training Loss 2.164...\n",
      "Step 8330 Training Accuracy 0.453... Training Loss 1.518...\n",
      "Step 8340 Training Accuracy 0.516... Training Loss 1.366...\n",
      "Step 8350 Training Accuracy 0.547... Training Loss 1.589...\n",
      "Step 8360 Training Accuracy 0.547... Training Loss 1.540...\n",
      "Step 8370 Training Accuracy 0.531... Training Loss 1.683...\n",
      "Step 8380 Training Accuracy 0.547... Training Loss 1.528...\n",
      "Step 8390 Training Accuracy 0.562... Training Loss 1.461...\n",
      "Step 8400 Training Accuracy 0.547... Training Loss 1.701...\n",
      "Step 8410 Training Accuracy 0.531... Training Loss 1.715...\n",
      "Step 8420 Training Accuracy 0.594... Training Loss 1.479...\n",
      "Step 8430 Training Accuracy 0.562... Training Loss 1.780...\n",
      "Step 8440 Training Accuracy 0.578... Training Loss 1.369...\n",
      "Step 8450 Training Accuracy 0.438... Training Loss 1.740...\n",
      "Step 8460 Training Accuracy 0.469... Training Loss 1.756...\n",
      "Step 8470 Training Accuracy 0.547... Training Loss 1.613...\n",
      "Step 8480 Training Accuracy 0.578... Training Loss 1.670...\n",
      "Step 8490 Training Accuracy 0.516... Training Loss 1.671...\n",
      "Step 8500 Training Accuracy 0.562... Training Loss 1.694...\n",
      "Step 8510 Training Accuracy 0.578... Training Loss 1.494...\n",
      "Step 8520 Training Accuracy 0.500... Training Loss 1.815...\n",
      "Step 8530 Training Accuracy 0.469... Training Loss 1.637...\n",
      "Step 8540 Training Accuracy 0.578... Training Loss 1.502...\n",
      "Step 8550 Training Accuracy 0.547... Training Loss 1.557...\n",
      "Step 8560 Training Accuracy 0.500... Training Loss 1.691...\n",
      "Step 8570 Training Accuracy 0.578... Training Loss 1.695...\n",
      "Step 8580 Training Accuracy 0.484... Training Loss 1.630...\n",
      "Step 8590 Training Accuracy 0.453... Training Loss 1.777...\n",
      "Step 8600 Training Accuracy 0.484... Training Loss 1.686...\n",
      "Step 8610 Training Accuracy 0.656... Training Loss 1.328...\n",
      "Step 8620 Training Accuracy 0.453... Training Loss 1.920...\n",
      "Step 8630 Training Accuracy 0.641... Training Loss 1.307...\n",
      "Step 8640 Training Accuracy 0.547... Training Loss 1.504...\n",
      "Step 8650 Training Accuracy 0.500... Training Loss 1.702...\n",
      "Step 8660 Training Accuracy 0.609... Training Loss 1.563...\n",
      "Step 8670 Training Accuracy 0.547... Training Loss 1.889...\n",
      "Step 8680 Training Accuracy 0.531... Training Loss 1.675...\n",
      "Step 8690 Training Accuracy 0.531... Training Loss 1.539...\n",
      "Step 8700 Training Accuracy 0.531... Training Loss 1.758...\n",
      "Step 8710 Training Accuracy 0.516... Training Loss 1.911...\n",
      "Step 8720 Training Accuracy 0.484... Training Loss 1.790...\n",
      "Step 8730 Training Accuracy 0.500... Training Loss 2.044...\n",
      "Step 8740 Training Accuracy 0.641... Training Loss 1.382...\n",
      "Step 8750 Training Accuracy 0.625... Training Loss 1.473...\n",
      "Step 8760 Training Accuracy 0.750... Training Loss 1.164...\n",
      "Step 8770 Training Accuracy 0.484... Training Loss 1.698...\n",
      "Step 8780 Training Accuracy 0.516... Training Loss 1.606...\n",
      "Step 8790 Training Accuracy 0.672... Training Loss 1.420...\n",
      "Step 8800 Training Accuracy 0.453... Training Loss 1.827...\n",
      "Step 8810 Training Accuracy 0.578... Training Loss 1.588...\n",
      "Step 8820 Training Accuracy 0.484... Training Loss 1.937...\n",
      "Step 8830 Training Accuracy 0.547... Training Loss 1.607...\n",
      "Step 8840 Training Accuracy 0.531... Training Loss 1.653...\n",
      "Step 8850 Training Accuracy 0.562... Training Loss 1.460...\n",
      "Step 8860 Training Accuracy 0.641... Training Loss 1.463...\n",
      "Step 8870 Training Accuracy 0.516... Training Loss 1.809...\n",
      "Step 8880 Training Accuracy 0.422... Training Loss 1.924...\n",
      "Step 8890 Training Accuracy 0.469... Training Loss 1.672...\n",
      "Step 8900 Training Accuracy 0.672... Training Loss 1.396...\n",
      "Step 8910 Training Accuracy 0.562... Training Loss 1.625...\n",
      "Step 8920 Training Accuracy 0.531... Training Loss 1.669...\n",
      "Step 8930 Training Accuracy 0.438... Training Loss 1.774...\n",
      "Step 8940 Training Accuracy 0.594... Training Loss 1.455...\n",
      "Step 8950 Training Accuracy 0.516... Training Loss 1.710...\n",
      "Step 8960 Training Accuracy 0.641... Training Loss 1.271...\n",
      "Step 8970 Training Accuracy 0.406... Training Loss 2.136...\n",
      "Step 8980 Training Accuracy 0.578... Training Loss 1.574...\n",
      "Step 8990 Training Accuracy 0.625... Training Loss 1.444...\n",
      "Step 9000 Training Accuracy 0.484... Training Loss 1.870...\n",
      "Writing checkpoing at step 9000\n",
      "Step 9010 Training Accuracy 0.594... Training Loss 1.279...\n",
      "Step 9020 Training Accuracy 0.484... Training Loss 1.759...\n",
      "Step 9030 Training Accuracy 0.578... Training Loss 1.523...\n",
      "Step 9040 Training Accuracy 0.500... Training Loss 1.661...\n",
      "Step 9050 Training Accuracy 0.609... Training Loss 1.439...\n",
      "Step 9060 Training Accuracy 0.469... Training Loss 1.487...\n",
      "Step 9070 Training Accuracy 0.547... Training Loss 1.315...\n",
      "Step 9080 Training Accuracy 0.594... Training Loss 1.540...\n",
      "Step 9090 Training Accuracy 0.609... Training Loss 1.391...\n",
      "Step 9100 Training Accuracy 0.531... Training Loss 1.490...\n",
      "Step 9110 Training Accuracy 0.547... Training Loss 1.370...\n",
      "Step 9120 Training Accuracy 0.594... Training Loss 1.293...\n",
      "Step 9130 Training Accuracy 0.562... Training Loss 1.603...\n",
      "Step 9140 Training Accuracy 0.562... Training Loss 1.365...\n",
      "Step 9150 Training Accuracy 0.531... Training Loss 1.710...\n",
      "Step 9160 Training Accuracy 0.562... Training Loss 1.334...\n",
      "Step 9170 Training Accuracy 0.688... Training Loss 1.390...\n",
      "Step 9180 Training Accuracy 0.594... Training Loss 1.248...\n",
      "Step 9190 Training Accuracy 0.578... Training Loss 1.508...\n",
      "Step 9200 Training Accuracy 0.531... Training Loss 1.663...\n",
      "Step 9210 Training Accuracy 0.594... Training Loss 1.430...\n",
      "Step 9220 Training Accuracy 0.625... Training Loss 1.379...\n",
      "Step 9230 Training Accuracy 0.594... Training Loss 1.339...\n",
      "Step 9240 Training Accuracy 0.531... Training Loss 1.605...\n",
      "Step 9250 Training Accuracy 0.562... Training Loss 1.443...\n",
      "Step 9260 Training Accuracy 0.531... Training Loss 1.888...\n",
      "Step 9270 Training Accuracy 0.547... Training Loss 1.605...\n",
      "Step 9280 Training Accuracy 0.609... Training Loss 1.325...\n",
      "Step 9290 Training Accuracy 0.500... Training Loss 1.841...\n",
      "Step 9300 Training Accuracy 0.500... Training Loss 1.571...\n",
      "Step 9310 Training Accuracy 0.531... Training Loss 1.628...\n",
      "Step 9320 Training Accuracy 0.594... Training Loss 1.405...\n",
      "Step 9330 Training Accuracy 0.625... Training Loss 1.329...\n",
      "Step 9340 Training Accuracy 0.594... Training Loss 1.260...\n",
      "Step 9350 Training Accuracy 0.656... Training Loss 1.167...\n",
      "Step 9360 Training Accuracy 0.484... Training Loss 1.838...\n",
      "Step 9370 Training Accuracy 0.625... Training Loss 1.355...\n",
      "Step 9380 Training Accuracy 0.547... Training Loss 1.704...\n",
      "Step 9390 Training Accuracy 0.516... Training Loss 1.695...\n",
      "Step 9400 Training Accuracy 0.641... Training Loss 1.339...\n",
      "Step 9410 Training Accuracy 0.562... Training Loss 1.520...\n",
      "Step 9420 Training Accuracy 0.578... Training Loss 1.425...\n",
      "Step 9430 Training Accuracy 0.734... Training Loss 1.010...\n",
      "Step 9440 Training Accuracy 0.562... Training Loss 1.534...\n",
      "Step 9450 Training Accuracy 0.531... Training Loss 1.610...\n",
      "Step 9460 Training Accuracy 0.719... Training Loss 1.206...\n",
      "Step 9470 Training Accuracy 0.578... Training Loss 1.270...\n",
      "Step 9480 Training Accuracy 0.562... Training Loss 1.628...\n",
      "Step 9490 Training Accuracy 0.641... Training Loss 1.439...\n",
      "Step 9500 Training Accuracy 0.609... Training Loss 1.414...\n",
      "Step 9510 Training Accuracy 0.516... Training Loss 1.628...\n",
      "Step 9520 Training Accuracy 0.781... Training Loss 0.887...\n",
      "Step 9530 Training Accuracy 0.609... Training Loss 1.180...\n",
      "Step 9540 Training Accuracy 0.594... Training Loss 1.404...\n",
      "Step 9550 Training Accuracy 0.562... Training Loss 1.628...\n",
      "Step 9560 Training Accuracy 0.516... Training Loss 1.602...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9570 Training Accuracy 0.547... Training Loss 1.639...\n",
      "Step 9580 Training Accuracy 0.516... Training Loss 1.335...\n",
      "Step 9590 Training Accuracy 0.547... Training Loss 1.605...\n",
      "Step 9600 Training Accuracy 0.625... Training Loss 1.317...\n",
      "Step 9610 Training Accuracy 0.703... Training Loss 1.051...\n",
      "Step 9620 Training Accuracy 0.469... Training Loss 1.618...\n",
      "Step 9630 Training Accuracy 0.750... Training Loss 1.049...\n",
      "Step 9640 Training Accuracy 0.484... Training Loss 1.409...\n",
      "Step 9650 Training Accuracy 0.500... Training Loss 1.644...\n",
      "Step 9660 Training Accuracy 0.625... Training Loss 1.274...\n",
      "Step 9670 Training Accuracy 0.656... Training Loss 1.159...\n",
      "Step 9680 Training Accuracy 0.562... Training Loss 1.625...\n",
      "Step 9690 Training Accuracy 0.609... Training Loss 1.376...\n",
      "Step 9700 Training Accuracy 0.703... Training Loss 1.169...\n",
      "Step 9710 Training Accuracy 0.500... Training Loss 1.420...\n",
      "Step 9720 Training Accuracy 0.578... Training Loss 1.420...\n",
      "Step 9730 Training Accuracy 0.641... Training Loss 1.366...\n",
      "Step 9740 Training Accuracy 0.500... Training Loss 1.612...\n",
      "Step 9750 Training Accuracy 0.578... Training Loss 1.470...\n",
      "Step 9760 Training Accuracy 0.625... Training Loss 1.319...\n",
      "Step 9770 Training Accuracy 0.641... Training Loss 1.325...\n",
      "Step 9780 Training Accuracy 0.500... Training Loss 1.385...\n",
      "Step 9790 Training Accuracy 0.578... Training Loss 1.509...\n",
      "Step 9800 Training Accuracy 0.547... Training Loss 1.422...\n",
      "Step 9810 Training Accuracy 0.594... Training Loss 1.376...\n",
      "Step 9820 Training Accuracy 0.609... Training Loss 1.356...\n",
      "Step 9830 Training Accuracy 0.609... Training Loss 1.426...\n",
      "Step 9840 Training Accuracy 0.531... Training Loss 1.459...\n",
      "Step 9850 Training Accuracy 0.609... Training Loss 1.393...\n",
      "Step 9860 Training Accuracy 0.609... Training Loss 1.450...\n",
      "Step 9870 Training Accuracy 0.500... Training Loss 1.683...\n",
      "Step 9880 Training Accuracy 0.625... Training Loss 1.427...\n",
      "Step 9890 Training Accuracy 0.609... Training Loss 1.201...\n",
      "Step 9900 Training Accuracy 0.484... Training Loss 1.761...\n",
      "Step 9910 Training Accuracy 0.500... Training Loss 1.837...\n",
      "Step 9920 Training Accuracy 0.438... Training Loss 1.736...\n",
      "Step 9930 Training Accuracy 0.672... Training Loss 1.223...\n",
      "Step 9940 Training Accuracy 0.594... Training Loss 1.390...\n",
      "Step 9950 Training Accuracy 0.656... Training Loss 1.291...\n",
      "Step 9960 Training Accuracy 0.625... Training Loss 1.397...\n",
      "Step 9970 Training Accuracy 0.547... Training Loss 1.600...\n",
      "Step 9980 Training Accuracy 0.594... Training Loss 1.191...\n",
      "Step 9990 Training Accuracy 0.609... Training Loss 1.289...\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "def train(train_feature_path, train_label_path, checkpoint_path, num_class, batch_size, image_size, max_step):\n",
    "    \n",
    "    train = initialize(train_feature_path, train_label_path)\n",
    "        \n",
    "    feature = tf.placeholder(tf.float32, shape=[None, image_size, image_size, 3], name='feature')\n",
    "    label = tf.placeholder(tf.float32, shape=[None], name='label')\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    one_hot_label = tf.one_hot(indices=tf.cast(label, tf.int32), depth=80)\n",
    "    is_training = tf.placeholder(tf.bool, name='is_training')\n",
    "    \n",
    "    logits, loss = conv_network(feature, one_hot_label, num_class, image_size, keep_prob, is_training)\n",
    "    \n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "        train_opt = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "        \n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_label, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "       \n",
    "    with tf.Session() as sess:\n",
    "        saver = tf.train.Saver()\n",
    "        ckpt = tf.train.get_checkpoint_state(checkpoint_path)\n",
    "        \n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            print('Restore the model from checkpoint {}.'.format(ckpt.model_checkpoint_path))\n",
    "            start_step = int(ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1])\n",
    "        else:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            start_step = 0\n",
    "            print('Start training from new start.')\n",
    "        \n",
    "        for steps in range(start_step, start_step + max_step):\n",
    "            train_feature_batch, train_label_batch = train.get_batch(batch_size, image_size)\n",
    "            #print(is_training, feature, label)\n",
    "            sess.run(train_opt, feed_dict={feature: train_feature_batch, label: train_label_batch, keep_prob: 0.5, is_training: True})\n",
    "                \n",
    "            if steps % 10 == 0:\n",
    "                train_accuracy = sess.run(accuracy, feed_dict={feature: train_feature_batch, label: train_label_batch, keep_prob: 0.5, is_training: False})\n",
    "                train_loss = sess.run(loss, feed_dict={feature: train_feature_batch, label: train_label_batch, keep_prob: 0.5, is_training: False})\n",
    "                print('Step {}'.format(steps),\n",
    "                      'Training Accuracy {:.3f}...'.format(train_accuracy),\n",
    "                      'Training Loss {:.3f}...'.format(train_loss),\n",
    "                     ) \n",
    "            if steps % 1000 == 0:\n",
    "                saver.save(sess, checkfile, global_step=steps)\n",
    "                print('Writing checkpoing at step {}'.format(steps))\n",
    "\n",
    "        print('Training completed.')\n",
    "\n",
    "# image pathes\n",
    "train_feature_path = r'E:\\ai_challenger\\scene classification\\dataset\\ai_challenger_scene_train_20170904\\scene_train_images_20170904'\n",
    "train_label_path = r'E:\\ai_challenger\\scene classification\\dataset\\ai_challenger_scene_train_20170904\\scene_train_annotations_20170904.json'\n",
    "checkpoint_path = './checkpoint/'\n",
    "checkfile = './checkpoint/model.ckpt'\n",
    "\n",
    "num_class = 80\n",
    "batch_size = 64\n",
    "image_size = 64\n",
    "max_step = 10000\n",
    "learning_rate =0.002\n",
    "\n",
    "train(train_feature_path, train_label_path, checkpoint_path, num_class, batch_size, image_size, max_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='step5'></a>\n",
    "## Step 5: With Xavier initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step6'></a>\n",
    "## Step 6: Train on full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
